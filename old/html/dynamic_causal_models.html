
<!DOCTYPE html
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   <!--
This HTML was auto-generated from MATLAB code.
To make changes, update the MATLAB code and republish this document.
      --><title>Variational Gradient Matching for Dynamical Systems: Dynamic Causal Models</title><meta name="generator" content="MATLAB 9.2"><link rel="schema.DC" href="http://purl.org/dc/elements/1.1/"><meta name="DC.date" content="2018-04-11"><meta name="DC.source" content="dynamic_causal_models.m"><style type="text/css">
html,body,div,span,applet,object,iframe,h1,h2,h3,h4,h5,h6,p,blockquote,pre,a,abbr,acronym,address,big,cite,code,del,dfn,em,font,img,ins,kbd,q,s,samp,small,strike,strong,sub,sup,tt,var,b,u,i,center,dl,dt,dd,ol,ul,li,fieldset,form,label,legend,table,caption,tbody,tfoot,thead,tr,th,td{margin:0;padding:0;border:0;outline:0;font-size:100%;vertical-align:baseline;background:transparent}body{line-height:1}ol,ul{list-style:none}blockquote,q{quotes:none}blockquote:before,blockquote:after,q:before,q:after{content:'';content:none}:focus{outine:0}ins{text-decoration:none}del{text-decoration:line-through}table{border-collapse:collapse;border-spacing:0}

html { min-height:100%; margin-bottom:1px; }
html body { height:100%; margin:0px; font-family:Arial, Helvetica, sans-serif; font-size:10px; color:#000; line-height:140%; background:#fff none; overflow-y:scroll; }
html body td { vertical-align:top; text-align:left; }

h1 { padding:0px; margin:0px 0px 25px; font-family:Arial, Helvetica, sans-serif; font-size:1.5em; color:#d55000; line-height:100%; font-weight:normal; }
h2 { padding:0px; margin:0px 0px 8px; font-family:Arial, Helvetica, sans-serif; font-size:1.2em; color:#000; font-weight:bold; line-height:140%; border-bottom:1px solid #d6d4d4; display:block; }
h3 { padding:0px; margin:0px 0px 5px; font-family:Arial, Helvetica, sans-serif; font-size:1.1em; color:#000; font-weight:bold; line-height:140%; }

a { color:#005fce; text-decoration:none; }
a:hover { color:#005fce; text-decoration:underline; }
a:visited { color:#004aa0; text-decoration:none; }

p { padding:0px; margin:0px 0px 20px; }
img { padding:0px; margin:0px 0px 20px; border:none; }
p img, pre img, tt img, li img, h1 img, h2 img { margin-bottom:0px; } 

ul { padding:0px; margin:0px 0px 20px 23px; list-style:square; }
ul li { padding:0px; margin:0px 0px 7px 0px; }
ul li ul { padding:5px 0px 0px; margin:0px 0px 7px 23px; }
ul li ol li { list-style:decimal; }
ol { padding:0px; margin:0px 0px 20px 0px; list-style:decimal; }
ol li { padding:0px; margin:0px 0px 7px 23px; list-style-type:decimal; }
ol li ol { padding:5px 0px 0px; margin:0px 0px 7px 0px; }
ol li ol li { list-style-type:lower-alpha; }
ol li ul { padding-top:7px; }
ol li ul li { list-style:square; }

.content { font-size:1.2em; line-height:140%; padding: 20px; }

pre, code { font-size:12px; }
tt { font-size: 1.2em; }
pre { margin:0px 0px 20px; }
pre.codeinput { padding:10px; border:1px solid #d3d3d3; background:#f7f7f7; }
pre.codeoutput { padding:10px 11px; margin:0px 0px 20px; color:#4c4c4c; }
pre.error { color:red; }

@media print { pre.codeinput, pre.codeoutput { word-wrap:break-word; width:100%; } }

span.keyword { color:#0000FF }
span.comment { color:#228B22 }
span.string { color:#A020F0 }
span.untermstring { color:#B20000 }
span.syscmd { color:#B28C00 }

.footer { width:auto; padding:10px 0px; margin:25px 0px 0px; border-top:1px dotted #878787; font-size:0.8em; line-height:140%; font-style:italic; color:#878787; text-align:left; float:none; }
.footer p { margin:0px; }
.footer a { color:#878787; }
.footer a:hover { color:#878787; text-decoration:underline; }
.footer a:visited { color:#878787; }

table th { padding:7px 5px; text-align:left; vertical-align:middle; border: 1px solid #d6d4d4; font-weight:bold; }
table td { padding:7px 5px; text-align:left; vertical-align:top; border:1px solid #d6d4d4; }





  </style></head><body><div class="content"><h1>Variational Gradient Matching for Dynamical Systems: Dynamic Causal Models</h1><!--introduction--><p><img vspace="5" hspace="5" src="cover_pic.png" alt=""> </p><p>Authors: <b>Nico Stephan Gorbach</b> and <b>Stefan Bauer</b>, email: <a href="mailto:nico.gorbach@gmail.com">nico.gorbach@gmail.com</a></p><p>Instructional code for the NIPS (2018) paper " <b>Scalable Variational Inference for Dynamical Systems</b> " by Nico S. Gorbach, Stefan Bauer and Joachim M. Buhmann. The paper is available at <a href="https://papers.nips.cc/paper/7066-scalable-variational-inference-for-dynamical-systems.pdf">https://papers.nips.cc/paper/7066-scalable-variational-inference-for-dynamical-systems.pdf</a>. Please cite our paper if you use our program for a further publication. Part of the derivation below is described in Wenk et al. (2018).</p><p>Example dynamical system used in this code: Lotka-Volterra system with <b>half</b> of the time points <b>unobserved</b>. The ODE parameters are also unobserved.</p><!--/introduction--><h2>Contents</h2><div><ul><li><a href="#1">Advantages of Variational Gradient Matching</a></li><li><a href="#4">Simulation Settings</a></li><li><a href="#5">User Input</a></li><li><a href="#13">Import ODEs</a></li><li><a href="#15">Mass Action Dynamical Systems</a></li><li><a href="#16">Simulate Trajectory Observations</a></li><li><a href="#22">Prior on ODE parameters</a></li><li><a href="#23">Confounding effects</a></li><li><a href="#25">Prior on States and State Derivatives</a></li><li><a href="#26">Matching Gradients</a></li><li><a href="#27">State Couplings in ODEs</a></li><li><a href="#28">Rewrite ODEs as Linear Combination in Parameters</a></li><li><a href="#29">Posterior over ODE Parameters</a></li><li><a href="#30">Rewrite ODEs as Linear Combination in (monotonic functions of) Individual States</a></li><li><a href="#31">Posterior over Individual States</a></li><li><a href="#32">Mean-field Variational Inference</a></li><li><a href="#33">GP Regression for Observations</a></li><li><a href="#34">Coordinate Ascent Variational Gradient Matching</a></li><li><a href="#35">Numerical integration with parameters estimated by variational gradient matching</a></li><li><a href="#37">Time Taken</a></li><li><a href="#38">References</a></li><li><a href="#39">Subroutines</a></li></ul></div><h2 id="1">Advantages of Variational Gradient Matching</h2><p>The essential idea of gradient matching (Calderhead et al., 2002) is to match the gradient governed by the ODEs with that inferred from the observations. In contrast to previous approaches gradient matching introduces a prior over states instead of a prior over ODE parameters. The advantages of gradients matching is two-fold:</p><div><ol><li>A prior over the functional form of state dynamics as opposed to ODE parameters facilitates a more expert-aware estimation of ODE parameters since experts can provide a better <i>a priori</i> description of state dynamics than ODE parameters.</li><li>Gradient matching yields a global gradient as opposed to a local one which offers significant computational advantages and provides access to a rich source of sophisticated optimization tools.</li></ol></div><p>Clear workspace and close figures</p><pre class="codeinput">clear <span class="string">all</span>; close <span class="string">all</span>;
</pre><h2 id="4">Simulation Settings</h2><pre class="codeinput">simulation.odes = <span class="string">'fwd_mod_driving'</span>;
simulation.state_obs_variance = @(mean)(bsxfun(@times,[0.5^2,0.5^2],<span class="keyword">...</span>
    ones(size(mean))));                                                    <span class="comment">% observation noise</span>
simulation.ode_param = -0.8 + (0.8-(-0.8)) * rand(1,11);                   <span class="comment">% true non-selfinhibitory neuronal couplings (sampled uniformily in the interval [-0.8,0.8];</span>
simulation.ode_param(end-4:end) = -1;                                      <span class="comment">% self-inhibotory neuronal couplings set to -1.</span>
simulation.final_time = 359*3.22;                                          <span class="comment">% end time for integration</span>
simulation.int_interval = 0.01;                                            <span class="comment">% integration interval</span>
simulation.time_samp = 0:0.1:simulation.final_time;                        <span class="comment">% sample times for observations</span>
simulation.init_val = [5 3];                                               <span class="comment">% state values at first time point</span>
simulation.observed_states = {};                                           <span class="comment">% indices of states that are directly observed (Boolean)</span>
</pre><h2 id="5">User Input</h2><p><h4> Candidate mechanism </h4></p><pre class="codeinput">candidate_odes = <span class="string">'fwd_mod_driving'</span>;
</pre><p><h4> Signal-to-noise-ratio of BOLD response </h4></p><pre class="codeinput">bold_response.SNR = 5;
</pre><p><h4> Prior variance on non-selfinhibitory neuronal couplings </h4></p><pre class="codeinput">param_prior_variance = realmax;
</pre><p><h4> Kernel </h4></p><p>Kernel parameters <img src="dynamic_causal_models_eq06401276552089372917.png" alt="$\phi$" style="width:6px;height:10px;">:</p><pre class="codeinput">kernel.param = [2,10];                                                     <span class="comment">% set values of rbf kernel parameters</span>
</pre><p>Error variance on state derivatives (i.e. <img src="dynamic_causal_models_eq17096441642737911057.png" alt="$\gamma$" style="width:6px;height:8px;">):</p><pre class="codeinput">state.derivative_variance = 6.*ones(11-3,1);                               <span class="comment">%% $\gamma$ for gradient matching model</span>
</pre><p><h4> Estimation </h4></p><pre class="codeinput">time.est= 0:3.22:359*3.22;                                                 <span class="comment">% estimation times</span>
coord_ascent_numb_iter = 200;                                              <span class="comment">% number of coordinate ascent iterations</span>
clamp_obs_state_to_GP_regression = true;                                   <span class="comment">% The observed state trajectories are clamped to the trajectories determined by standard GP regression (Boolean)</span>
</pre><p><h4> External input </h4></p><pre class="codeinput">state.ext_input = importdata(<span class="string">'dcm/external_input.txt'</span>);                    <span class="comment">% importing external inputs</span>
time.samp = state.ext_input(:,1)';                                         <span class="comment">% unpack sampling time</span>
</pre><p><h4> Symbols </h4></p><pre class="codeinput">symbols = generate_generic_DCM_odes2(candidate_odes,<span class="string">'dcm/candidate_odes.txt'</span>); <span class="comment">% symbols of parameters and states and in 'ODEs.txt' file</span>
</pre><h2 id="13">Import ODEs</h2><pre class="codeinput">ode = import_odes(symbols);
</pre><pre class="codeinput">disp(<span class="string">'candidate ODEs:'</span>); disp(ode.raw)
</pre><pre class="codeoutput">candidate ODEs:
    '-(5.*exp((17.*[v_{1}])./8))./8-(25.*exp(-[q_{1}]).*exp([f_{1}]).*((3./5).^exp(-[f_{1}])-1))./16'
    '-(5.*exp((17.*[v_{3}])./8))./8-(25.*exp(-[q_{3}]).*exp([f_{3}]).*((3./5).^exp(-[f_{3}])-1))./16'
    '-(5.*exp((17.*[v_{2}])./8))./8-(25.*exp(-[q_{2}]).*exp([f_{2}]).*((3./5).^exp(-[f_{2}])-1))./16'
    '(5.*exp(-[v_{1}]).*exp([f_{1}]))./8-(5.*exp((17.*[v_{1}])./8))./8'
    '(5.*exp(-[v_{3}]).*exp([f_{3}]))./8-(5.*exp((17.*[v_{3}])./8))./8'
    '(5.*exp(-[v_{2}]).*exp([f_{2}]))./8-(5.*exp((17.*[v_{2}])./8))./8'
    '[s_{1}].*exp(-[f_{1}])'
    '[s_{3}].*exp(-[f_{3}])'
    '[s_{2}].*exp(-[f_{2}])'
    '[x_1]-(3.*[s_{1}])./5-(8.*exp([f_{1}]))./25+8./25'
    '[x_3]-(3.*[s_{3}])./5-(8.*exp([f_{3}]))./25+8./25'
    '[x_2]-(3.*[s_{2}])./5-(8.*exp([f_{2}]))./25+8./25'
    '[c_{11}].*[u_{1}]+[a_{11}].*[x_1]+[a_{12}].*[x_2]'
    '[c_{33}].*[u_{3}]+[a_{32}].*[x_2]+[a_{33}].*[x_3]'
    '[x_1].*([a_{21}]+[b_{212}].*[u_{2}]+[b_{213}].*[u_{3}])+[a_{22}].*[x_2]+[a_{23}].*[x_3]'

</pre><h2 id="15">Mass Action Dynamical Systems</h2><p>A deterministic dynamical system is represented by a set of <img src="dynamic_causal_models_eq03845174387838694102.png" alt="$K$" style="width:10px;height:8px;"> ordinary differential equations (ODEs) with model parameters <img src="dynamic_causal_models_eq06597877416883810229.png" alt="$\theta \in R^d$" style="width:32px;height:10px;"> that describe the evolution of <img src="dynamic_causal_models_eq03845174387838694102.png" alt="$K$" style="width:10px;height:8px;"> states <img src="dynamic_causal_models_eq16690292594929342180.png" alt="$\mathbf{x}(t) = [x_1(t),\ldots, x_K(t)]^T$" style="width:120px;height:13px;"> such that:</p><p><img src="dynamic_causal_models_eq14568623149868123203.png" alt="$\dot{\mathbf{x}}(t) = \frac{d \mathbf{x}(t)}{d t} = \mathbf{f}(\mathbf{x}(t),\theta) \qquad (1)$" style="width:147px;height:16px;">.</p><p>A sequence of observations, <img src="dynamic_causal_models_eq17565748849429239454.png" alt="$\mathbf{y}(t)$" style="width:19px;height:11px;">, is usually contaminated by measurement error which we assume to be normally distributed with zero mean and variance for each of the <img src="dynamic_causal_models_eq03845174387838694102.png" alt="$K$" style="width:10px;height:8px;"> states, i.e. <img src="dynamic_causal_models_eq13983079546768783123.png" alt="$\mathbf{E}\sim \mathcal{N}(\mathbf{E};\mathbf{0},\mathbf{D})$" style="width:75px;height:12px;">, with <img src="dynamic_causal_models_eq02125912780065424198.png" alt="$\mathbf{D}_{ik}=\sigma_k ^2 \delta_{ik}$" style="width:55px;height:13px;">. For <img src="dynamic_causal_models_eq03672095713503266041.png" alt="$N$" style="width:10px;height:8px;"> distinct time points the overall system may therefore be summarized as:</p><p><img src="dynamic_causal_models_eq05988414051423361030.png" alt="$\mathbf{Y} = \mathbf{X} + \mathbf{E}$" style="width:56px;height:9px;">,</p><p>where</p><p><img src="dynamic_causal_models_eq15195809455161680973.png" alt="$\mathbf{X} = [\mathbf{x}(t_1),\ldots,\mathbf{x}(t_N)] = [\mathbf{x}_1,\ldots,\mathbf{x}_K]^T$" style="width:181px;height:13px;">,</p><p><img src="dynamic_causal_models_eq07638385370877036024.png" alt="$\mathbf{Y} = [\mathbf{y}(t_1),\ldots,\mathbf{y}(t_N)] = [\mathbf{y}_1,\ldots,\mathbf{y}_K]^T$" style="width:182px;height:13px;">,</p><p>and <img src="dynamic_causal_models_eq15380491105506292187.png" alt="$\mathbf{x}_k = [x_k(t_1),\ldots,x_k(t_N)]^T$" style="width:122px;height:13px;"> is the <img src="dynamic_causal_models_eq15636846968047188835.png" alt="$k$" style="width:6px;height:8px;">'th state sequence and <img src="dynamic_causal_models_eq10667114650506665719.png" alt="$\mathbf{y}_k = [y_k(t_1),$" style="width:59px;height:11px;"> <img src="dynamic_causal_models_eq11698417834938640281.png" alt="$\ldots,y_k(t_N)]^T$" style="width:58px;height:13px;"> are the observations. Given the observations <img src="dynamic_causal_models_eq00013651220649516337.png" alt="$\mathbf{Y}$" style="width:10px;height:8px;"> and the description of the dynamical system (1), the aim is to estimate both state variables <img src="dynamic_causal_models_eq03397130480831257552.png" alt="$\mathbf{X}$" style="width:9px;height:8px;"> and parameters <img src="dynamic_causal_models_eq08288499342375314727.png" alt="$\theta$" style="width:5px;height:8px;">.</p><p>We consider only dynamical systems that are locally linear with respect to ODE parameters <img src="dynamic_causal_models_eq07852716426910655037.png" alt="$\boldmath\theta$" style="width:5px;height:8px;"> and individual states <img src="dynamic_causal_models_eq00398522576481313565.png" alt="$\mathbf{x}_u$" style="width:11px;height:7px;">. Such ODEs include mass-action kinetics and are given by:</p><p><img src="dynamic_causal_models_eq14747913945217368606.png" alt="$f_{k}(\mathbf{x}(t),\boldmath\theta) = \sum_{i=1} \theta_{ki} \prod_{j \in \mathcal{M}_{ki}} x_j \qquad (2)$" style="width:185px;height:13px;">,</p><p>with <img src="dynamic_causal_models_eq10975547451157895511.png" alt="$\mathcal{M}_{ki} \subseteq \{ 1, \dots, K\}$" style="width:86px;height:11px;"> describing the state variables in each factor of the equation (i.e. the functions are linear in parameters and contain arbitrary large products of monomials of the states).</p><h2 id="16">Simulate Trajectory Observations</h2><p><h4> Write ODEs symbolically </h4></p><pre class="codeinput">[ode,state_sym,param_sym] = write_ODEs_symbolically(symbols,ode);          <span class="comment">% symbolic computations</span>
</pre><p><h4> Simulate state trajectories by numerical integration </h4></p><pre class="codeinput">non_diverging_trajectories = false;
<span class="keyword">while</span> ~non_diverging_trajectories

simulation.ode_param = -0.8 + (0.8-(-0.8)) * rand(1,length(symbols.param));<span class="comment">% true non-selfinhibitory neuronal couplings (sampled uniformily in the interval [-0.8,0.8];</span>
simulation.ode_param(end-2:end) = -1;                                      <span class="comment">% self-inhibitory neuronal couplings set to -1.</span>

state_orig = state;
[state,time,bold_response] = simulate_dynamics_by_numerical_integration(state,state_sym,param_sym,<span class="keyword">...</span>
            time,ode,simulation.ode_param,bold_response,symbols);

<span class="keyword">if</span> ~any(any(isnan(state.true))) &amp;&amp; time.samp(end) &gt; 1000; non_diverging_trajectories = 1; <span class="keyword">end</span>

<span class="keyword">end</span>
</pre><p><h4> Generate state observations </h4></p><pre class="codeinput">tmp = cellfun(@(x) {strcmp(x(2),simulation.observed_states)},symbols.state);
state.obs_idx = cellfun(@(x) any(x),tmp);
state.obs_idx(cellfun(@(x) strcmp(x(2),<span class="string">'u'</span>),symbols.state)) = [];
state.obs = state.true(:,state.obs_idx) +  sqrt(var(state.true(:,state.obs_idx)) ./ bold_response.SNR) .* randn(size(state.true(:,state.obs_idx)));

<span class="comment">% mean correction</span>
bold_response.obs = bsxfun(@minus,bold_response.obs,mean(bold_response.obs,1));
</pre><p><h4> Symbols </h4></p><pre class="codeinput">state.sym.mean = sym(<span class="string">'x%d%d'</span>,[length(time.est),length(ode.system)]);
state.sym.variance = sym(<span class="string">'sigma%d%d'</span>,[length(time.est),length(ode.system)]);
ode_param.sym.mean = sym(<span class="string">'param%d'</span>,[length(symbols.param),1]); assume(ode_param.sym.mean,<span class="string">'real'</span>);
</pre><p><h4> Setup plots </h4></p><pre class="codeinput"><span class="comment">%[h_states,h_param] = setup_plots(state,time,simulation,symbols);</span>
h = setup_plots(state,time,symbols,bold_response,[1,2],candidate_odes,simulation);
</pre><img vspace="5" hspace="5" src="dynamic_causal_models_01.png" style="width:1200px;height:600px;" alt=""> <img vspace="5" hspace="5" src="dynamic_causal_models_02.png" style="width:1600px;height:800px;" alt=""> <h2 id="22">Prior on ODE parameters</h2><p>Constuct prior on ODE parameters.</p><pre class="codeinput">ode_param = prior_on_ODE_param(ode_param,param_prior_variance,symbols.param);<span class="comment">% prior on ODE parameters</span>
</pre><h2 id="23">Confounding effects</h2><p>BOLD response observations are given by the signal change equation plus an intercept due to confounding effects:</p><p><img src="dynamic_causal_models_eq07691485036324224235.png" alt="$$\mathbf{y} = \mathbf{h}(\mathbf{q},\mathbf{v},\mathbf{u}) + \mathbf{X} \beta + \epsilon$$" style="width:115px;height:11px;"></p><pre class="codeinput">bold_response = confounding_effects(bold_response);

tic; <span class="comment">%start timer</span>
</pre><h2 id="25">Prior on States and State Derivatives</h2><p>Gradient matching with Gaussian processes assumes a joint Gaussian process prior on states and their derivatives:</p><p><img src="dynamic_causal_models_eq01057761807000221839.png" alt="$\left(\begin{array}{c} \mathbf{X} \\ \dot{\mathbf{X}} \end{array}\right)  \sim \mathcal{N} \left( \begin{array}{c} \mathbf{X} \\ \dot{\mathbf{X}} \end{array}; \begin{array}{c}  \mathbf{0} \\ \mathbf{0}  \end{array}, \begin{array}{cc}  \mathbf{C}_{\phi} &amp; \mathbf{C}_{\phi}' \\  '\mathbf{C}_{\phi} &amp; \mathbf{C}_{\phi}''  \end{array}  \right) \qquad (3)$" style="width:216px;height:28px;">,</p><p><img src="dynamic_causal_models_eq15132385546029468189.png" alt="$\mathrm{cov}(x_k(t), x_k(t)) = C_{\phi_k}(t,t')$" style="width:131px;height:12px;"></p><p><img src="dynamic_causal_models_eq17058345339069568247.png" alt="$\mathrm{cov}(\dot{x}_k(t), x_k(t)) = \frac{\partial C_{\phi_k}(t,t') }{\partial t} =: C_{\phi_k}'(t,t')$" style="width:185px;height:18px;"></p><p><img src="dynamic_causal_models_eq08196297352138716370.png" alt="$\mathrm{cov}(x_k(t), \dot{x}_k(t)) = \frac{\partial C_{\phi_k}(t,t') }{\partial t'} =: {'C_{\phi_k}(t,t')}$" style="width:187px;height:17px;"></p><p><img src="dynamic_causal_models_eq02914213731374756582.png" alt="$\mathrm{cov}(\dot{x}_k(t), \dot{x}_k(t)) = \frac{\partial C_{\phi_k}(t,t') }{\partial t \partial t'} =: C_{\phi_k}''(t,t')$" style="width:185px;height:18px;">.</p><h2 id="26">Matching Gradients</h2><p>Given the joint distribution over states and their derivatives (3) as well as the ODEs (2), we therefore have two expressions for the state derivatives:</p><p><img src="dynamic_causal_models_eq06786540181160975064.png" alt="$\dot{\mathbf{X}} = \mathbf{F} + \epsilon_1, \epsilon_1 \sim \mathcal{N}\left(\epsilon_1;\mathbf{0}, \mathbf{I}\gamma \right)$" style="width:139px;height:13px;"></p><p><img src="dynamic_causal_models_eq00641387202370649337.png" alt="$\dot{\mathbf{X}} = {'\mathbf{C}_{\phi}} \mathbf{C}_{\phi}^{-1} ~\mathbf{X} + \epsilon_2, \epsilon_2 \sim \mathcal{N}\left(\epsilon_2;\mathbf{0}, \mathbf{A} \right)$" style="width:179px;height:16px;"></p><p>where <img src="dynamic_causal_models_eq15438906814634469781.png" alt="$\mathbf{F} := \mathbf{f}(\mathbf{X},\theta)$" style="width:58px;height:11px;">, <img src="dynamic_causal_models_eq02616189247499740046.png" alt="$\mathbf{A} := \mathbf{C}_{\phi}'' -  {'\mathbf{C}_{\phi}} \mathbf{C}_{\phi}^{-1} \mathbf{C}_{\phi}'$" style="width:105px;height:15px;"> and <img src="dynamic_causal_models_eq17096441642737911057.png" alt="$\gamma$" style="width:6px;height:8px;"> is the error variance in the ODEs. Note that, in a deterministic system, the output of the ODEs <img src="dynamic_causal_models_eq10805855639155619100.png" alt="$\mathbf{F}$" style="width:8px;height:8px;"> should equal the state derivatives <img src="dynamic_causal_models_eq07315144976585928416.png" alt="$\dot{\mathbf{X}}$" style="width:9px;height:11px;">. However, in the first equation above we relax this contraint by adding stochasticity to the state derivatives <img src="dynamic_causal_models_eq07315144976585928416.png" alt="$\dot{\mathbf{X}}$" style="width:9px;height:11px;"> in order to compensate for a potential model mismatch. The second equation above is obtained by deriving the conditional distribution for <img src="dynamic_causal_models_eq07315144976585928416.png" alt="$\dot{\mathbf{X}}$" style="width:9px;height:11px;"> from the joint distribution in equation (3). Equating the two expressions in the equations above we can eliminate the unknown state derivatives <img src="dynamic_causal_models_eq07315144976585928416.png" alt="$\dot{\mathbf{X}}$" style="width:9px;height:11px;">:</p><p><img src="dynamic_causal_models_eq16675609090530047740.png" alt="$\mathbf{F} = {'\mathbf{C}_{\phi}} \mathbf{C}_{\phi}^{-1} ~\mathbf{X} + \epsilon_0 \qquad (4)$" style="width:130px;height:15px;">,</p><p>with <img src="dynamic_causal_models_eq08944609086354323641.png" alt="$\epsilon_0 := \epsilon_2 - \epsilon_1$" style="width:57px;height:7px;">.</p><pre class="codeinput">[dC_times_invC,inv_C,A_plus_gamma] = kernel_function(kernel,state,time.est);
</pre><img vspace="5" hspace="5" src="dynamic_causal_models_03.png" style="width:560px;height:420px;" alt=""> <h2 id="27">State Couplings in ODEs</h2><pre class="codeinput">coupling_idx = find_couplings_in_odes(ode,symbols);
</pre><h2 id="28">Rewrite ODEs as Linear Combination in Parameters</h2><p>We rewrite the ODEs in equation (2) as a linear combination in the parameters:</p><p><img src="dynamic_causal_models_eq00386987092348617262.png" alt="$\mathbf{B}_{\boldmath\theta} \boldmath\theta + \mathbf{b}_{\boldmath\theta} \stackrel{!}{=} \mathbf{f}(\mathbf{X},\boldmath\theta) \qquad (5)$" style="width:139px;height:15px;">,</p><p>where matrices <img src="dynamic_causal_models_eq12395521263852684086.png" alt="$\mathbf{B}_{\boldmath\theta}$" style="width:13px;height:10px;"> and <img src="dynamic_causal_models_eq14370145166438995955.png" alt="$\mathbf{b}_{\boldmath\theta}$" style="width:11px;height:10px;"> are defined such that the ODEs <img src="dynamic_causal_models_eq12466937249580769582.png" alt="$\mathbf{f}(\mathbf{X},\boldmath\theta)$" style="width:33px;height:11px;"> are expressed as a linear combination in <img src="dynamic_causal_models_eq07852716426910655037.png" alt="$\boldmath\theta$" style="width:5px;height:8px;">.</p><pre class="codeinput">[ode_param.lin_comb.B,ode_param.lin_comb.b] = rewrite_odes_as_linear_combination_in_parameters(ode,symbols);
</pre><h2 id="29">Posterior over ODE Parameters</h2><p>Inserting (5) into (4) and solving for <img src="dynamic_causal_models_eq07852716426910655037.png" alt="$\boldmath\theta$" style="width:5px;height:8px;"> yields:</p><p><img src="dynamic_causal_models_eq12167863208124688271.png" alt="$\boldmath\theta = \mathbf{B}_{\boldmath\theta}^+ \left( {'\mathbf{C}_{\boldmath\phi}} \mathbf{C}_{\boldmath\phi}^{-1} \mathbf{X} - \mathbf{b}_{\boldmath\theta} + \boldmath\epsilon_0 \right)$" style="width:156px;height:20px;">,</p><p>where <img src="dynamic_causal_models_eq03085143088627778722.png" alt="$\mathbf{B}_{\boldmath\theta}^+$" style="width:15px;height:13px;"> denotes the pseudo-inverse of <img src="dynamic_causal_models_eq12395521263852684086.png" alt="$\mathbf{B}_{\boldmath\theta}$" style="width:13px;height:10px;">. We can therefore derive the posterior distribution over ODE parameters:</p><p><img src="dynamic_causal_models_eq05340185771765804682.png" alt="$p(\boldmath\theta \mid \mathbf{X}, \boldmath\phi, \gamma) = \mathcal{N}\left(\boldmath\theta ; \mathbf{B}_{\boldmath\theta}^+ ~ \left( {'\mathbf{C}_{\boldmath\phi}} \mathbf{C}_{\boldmath\phi}^{-1} \mathbf{X} - \mathbf{b}_{\boldmath\theta} \right), ~ \mathbf{B}_{\boldmath\theta}^+ ~ (\mathbf{A} + \mathbf{I}\gamma) ~ \mathbf{B}_{\boldmath\theta}^{+T} \right) \qquad (6)$" style="width:382px;height:20px;">.</p><h2 id="30">Rewrite ODEs as Linear Combination in (monotonic functions of) Individual States</h2><p>We rewrite the expression <img src="dynamic_causal_models_eq08371510633112951161.png" alt="$\mathbf{f}(\mathbf{X},\boldmath\theta) - {'\mathbf{C}}_{\boldmath\phi} \mathbf{C}_{\boldmath\phi}^{-1} \mathbf{X}$" style="width:101px;height:15px;"> in equation (4) as a linear combination in the individual state <img src="dynamic_causal_models_eq00398522576481313565.png" alt="$\mathbf{x}_u$" style="width:11px;height:7px;">:</p><p><img src="dynamic_causal_models_eq14929961689828671708.png" alt="$\mathbf{B}_{u} \mathbf{x}_u + \mathbf{b}_{u} \stackrel{!}{=} \mathbf{f}(\mathbf{X},\boldmath\theta) - {'\mathbf{C}}_{\boldmath\phi} \mathbf{C}_{\boldmath\phi}^{-1} \mathbf{X} \qquad (7)$" style="width:211px;height:17px;">.</p><p>where matrices <img src="dynamic_causal_models_eq11780124863314593273.png" alt="$\mathbf{B}_u$" style="width:13px;height:10px;"> and <img src="dynamic_causal_models_eq15590211095018081680.png" alt="$\mathbf{b}_u$" style="width:11px;height:10px;"> are defined such that the expression <img src="dynamic_causal_models_eq08371510633112951161.png" alt="$\mathbf{f}(\mathbf{X},\boldmath\theta) - {'\mathbf{C}}_{\boldmath\phi} \mathbf{C}_{\boldmath\phi}^{-1} \mathbf{X}$" style="width:101px;height:15px;"> is rewritten as a linear combination in the individual state <img src="dynamic_causal_models_eq00398522576481313565.png" alt="$\mathbf{x}_u$" style="width:11px;height:7px;">.</p><pre class="codeinput">state_enumeration = {<span class="string">'q'</span>,<span class="string">'v'</span>,<span class="string">'f'</span>,<span class="string">'s'</span>,<span class="string">'x'</span>};
<span class="keyword">for</span> u = 1:length(state_enumeration)
    <span class="keyword">if</span> strcmp(state_enumeration{u},<span class="string">'q'</span>)
       [state.deoxyhemo.B,state.deoxyhemo.b] = rewrite_bold_signal_eqn_as_linear_combination_in_deoxyhemo(symbols);
    <span class="keyword">elseif</span> strcmp(state_enumeration{u},<span class="string">'v'</span>)
        [state.vol.B,state.vol.b] = rewrite_deoxyhemo_ODE_as_linear_combination_in_vol(ode,symbols);
    <span class="keyword">elseif</span> strcmp(state_enumeration{u},<span class="string">'f'</span>)
        [state.flow.B,state.flow.b] = rewrite_vol_ODE_as_linear_combination_in_flow(ode,symbols);
    <span class="keyword">elseif</span> strcmp(state_enumeration{u},<span class="string">'s'</span>)
        [state.vaso.B,state.vaso.b] = rewrite_vaso_and_flow_odes_as_linear_combination_in_vaso(ode,symbols);
    <span class="keyword">elseif</span> strcmp(state_enumeration{u},<span class="string">'x'</span>)
        [state.neuronal.B,state.neuronal.b] = rewrite_odes_as_linear_combination_in_ind_neuronal_states(ode,symbols,coupling_idx.states);
    <span class="keyword">end</span>
<span class="keyword">end</span>
</pre><h2 id="31">Posterior over Individual States</h2><p>Inserting (7) into (4) and solving for <img src="dynamic_causal_models_eq00398522576481313565.png" alt="$\mathbf{x}_u$" style="width:11px;height:7px;"> yields:</p><p><img src="dynamic_causal_models_eq03984175207751185199.png" alt="$\mathbf{x}_u = \mathbf{B}_{u}^+ \left( \boldmath\epsilon_0 -\mathbf{b}_{u} \right)$" style="width:86px;height:12px;">,</p><p>where <img src="dynamic_causal_models_eq03266229480980241917.png" alt="$\mathbf{B}_{u}^+$" style="width:15px;height:12px;"> denotes the pseudo-inverse of <img src="dynamic_causal_models_eq11755194738169897586.png" alt="$\mathbf{B}_{u}$" style="width:13px;height:10px;">. We can therefore derive the posterior distribution over an individual state <img src="dynamic_causal_models_eq00398522576481313565.png" alt="$\mathbf{x}_u$" style="width:11px;height:7px;">:</p><p><img src="dynamic_causal_models_eq00180698902597322227.png" alt="$p(\mathbf{x}_u \mid \mathbf{X}_{-u}, \boldmath\phi, \gamma) = \mathcal{N}\left(\mathbf{x}_u ; -\mathbf{B}_{u}^+ \mathbf{b}_u, ~\mathbf{B}_u^{+} ~ (\mathbf{A} + \mathbf{I}\gamma) ~ \mathbf{B}_u^{+T} \right) \qquad (8)$" style="width:300px;height:14px;">,</p><p>with <img src="dynamic_causal_models_eq11492802563980187967.png" alt="$\mathbf{X}_{-u}$" style="width:20px;height:10px;"> denoting the set of all states except state <img src="dynamic_causal_models_eq00398522576481313565.png" alt="$\mathbf{x}_u$" style="width:11px;height:7px;">.</p><h2 id="32">Mean-field Variational Inference</h2><p>To infer the parameters <img src="dynamic_causal_models_eq07852716426910655037.png" alt="$\boldmath\theta$" style="width:5px;height:8px;">, we want to find the maximum a posteriori estimate (MAP):</p><p><img src="dynamic_causal_models_eq02662686890869235014.png" alt="$\theta^* := arg \max_{\theta} ~ \ln p(\theta \mid \mathbf{Y},\phi,\gamma, \sigma)$" style="width:161px;height:11px;"></p><p><img src="dynamic_causal_models_eq14040861108369768609.png" alt="$= arg\max_{\boldmath\theta} ~ \ln \int  p(\boldmath\theta,\mathbf{X} \mid \mathbf{Y},\boldmath\phi,\boldmath\gamma,\boldmath\sigma) d\mathbf{X}$" style="width:185px;height:13px;"></p><p><img src="dynamic_causal_models_eq11858686225046084718.png" alt="$= arg\max_{\boldmath\theta} ~ \ln \int p(\boldmath\theta \mid \mathbf{X},\boldmath\phi,\boldmath\gamma) p(\mathbf{X} \mid \mathbf{Y}, \boldmath\phi,\boldmath\sigma) d\mathbf{X} \qquad (9)$" style="width:259px;height:13px;">.</p><p>However, the integral above is intractable due to the strong couplings induced by the nonlinear ODEs <img src="dynamic_causal_models_eq15427371409597902919.png" alt="$\mathbf{f}$" style="width:5px;height:8px;"> which appear in the term <img src="dynamic_causal_models_eq07315403459475000172.png" alt="$p(\boldmath\theta \mid \mathbf{X},\boldmath\phi,\boldmath\gamma)$" style="width:60px;height:11px;">.</p><p>We use mean-field variational inference to establish variational lower bounds that are analytically tractable by decoupling state variables from the ODE parameters as well as decoupling the state variables from each other. Note that, since the ODEs described by equation (2) are <b>locally linear</b>, both conditional distributions <img src="dynamic_causal_models_eq03019155322140654594.png" alt="$p(\boldmath\theta \mid \mathbf{X},\mathbf{Y},\boldmath\phi,\boldmath\gamma,\boldmath\sigma)$" style="width:87px;height:11px;"> (equation (6)) and <img src="dynamic_causal_models_eq04387901815768360273.png" alt="$p(\mathbf{x}_u \mid \boldmath\theta, \mathbf{X}_{-u},\mathbf{Y},\boldmath\phi,\boldmath\gamma,\boldmath\sigma)$" style="width:114px;height:11px;"> (equation (8)) are analytically tractable and Gaussian distributed as mentioned previously.</p><p>The decoupling is induced by designing a variational distribution <img src="dynamic_causal_models_eq14500435956303858789.png" alt="$Q(\boldmath\theta,\mathbf{X})$" style="width:36px;height:11px;"> which is restricted to the family of factorial distributions:</p><p><img src="dynamic_causal_models_eq17914853368725890151.png" alt="$\mathcal{Q} := \bigg{\{} Q : Q(\boldmath\theta,\mathbf{X}) = q(\boldmath\theta) \prod_u q(\mathbf{x}_u) \bigg{\}}$" style="width:195px;height:27px;">.</p><p>The particular form of <img src="dynamic_causal_models_eq00738086801338514421.png" alt="$q(\boldmath\theta)$" style="width:19px;height:11px;"> and <img src="dynamic_causal_models_eq03894946144229571455.png" alt="$q(\mathbf{x}_u)$" style="width:25px;height:11px;"> are designed to be Gaussian distributed which places them in the same family as the true full conditional distributions. To find the optimal factorial distribution we minimize the Kullback-Leibler divergence between the variational and the true posterior distribution:</p><p><img src="dynamic_causal_models_eq07214799316343190862.png" alt="$\hat{Q} := arg \min_{Q(\boldmath\theta,\mathbf{X}) \in \mathcal{Q}} \mathrm{KL} \left[ Q(\theta,\mathbf{X}) \mid \mid p(\boldmath\theta,\mathbf{X} \mid \mathbf{Y},\boldmath\phi, \boldmath\gamma,\boldmath\sigma) \right] \qquad (10)$" style="width:304px;height:15px;">,</p><p>where <img src="dynamic_causal_models_eq03753133506936905529.png" alt="$\hat{Q}$" style="width:8px;height:13px;"> is the proxy distribution. The proxy distribution that minimizes the KL-divergence (10) depends on the true full conditionals and is given by:</p><p><img src="dynamic_causal_models_eq08024912143204138115.png" alt="$\hat{q}({\boldmath\theta}) \propto \exp \left(~ E_{Q_{-\theta}} \ln p(\boldmath\theta \mid \mathbf{X},\mathbf{Y},\boldmath\phi,\boldmath\gamma,\boldmath\sigma) ~\right) \qquad (11)$" style="width:234px;height:12px;"></p><p><img src="dynamic_causal_models_eq09451345083692260152.png" alt="$\hat{q}(\mathbf{x}_u) \propto \exp\left( ~ E_{Q_{-u}} \ln p(\mathbf{x}_u \mid \theta, \mathbf{X}_{-u},\mathbf{Y},\phi,\gamma,\sigma) ~ \right) \qquad (12)$" style="width:268px;height:12px;">.</p><h2 id="33">GP Regression for Observations</h2><p>The data-informed distribution <img src="dynamic_causal_models_eq13980762633675004648.png" alt="$p(\mathbf{X} \mid \mathbf{Y}, \boldmath\phi,\boldmath\sigma)$" style="width:65px;height:11px;"> in euqation (9) can be determined analytically using Gaussian process regression with the GP prior <img src="dynamic_causal_models_eq14930907090870324432.png" alt="$p(\mathbf{X} \mid \boldmath\phi) = \prod_k \mathcal{N}(\mathbf{x}_k ; \mathbf{0},\mathbf{C}_{\boldmath\phi})$" style="width:145px;height:13px;">:</p><p><img src="dynamic_causal_models_eq04537216543789424217.png" alt="$p(\mathbf{X} \mid \mathbf{Y}, \boldmath\phi,\gamma) = \prod_k \mathcal{N}(\mathbf{x}_k ; \boldmath\mu_k(\mathbf{y}_k),\boldmath\Sigma_k)$" style="width:181px;height:12px;">,</p><p>where <img src="dynamic_causal_models_eq06586455063503371300.png" alt="$\boldmath\mu_k(\mathbf{y}_k) := \sigma_k^{-2} \left(\sigma_k^{-2} \mathbf{I} + \mathbf{C}_{\boldmath\phi_k}^{-1} \right)^{-1} \mathbf{y}_k$" style="width:177px;height:23px;"> and <img src="dynamic_causal_models_eq05050976928104673176.png" alt="$\boldmath\Sigma_k ^{-1}:=\sigma_k^{-2} \mathbf{I} + \mathbf{C}_{\boldmath\phi_k}^{-1}$" style="width:101px;height:15px;">.</p><pre class="codeinput">[bold_response.denoised_obs,inv_sigma] = GP_regression(bold_response,inv_C,symbols);
</pre><h2 id="34">Coordinate Ascent Variational Gradient Matching</h2><p>We minimize the KL-divergence in equation (10) by coordinate descent (where each step is analytically tractable) by iterating between determining the proxy for the distribution over ODE parameters <img src="dynamic_causal_models_eq14367149541941707627.png" alt="$\hat{q}(\boldmath\theta)$" style="width:19px;height:11px;"> and the proxies for the distribution over individual states <img src="dynamic_causal_models_eq16039342152573661646.png" alt="$\hat{q}(\mathbf{x}_u)$" style="width:25px;height:11px;">.</p><pre class="codeinput">bold_response.obs_old = bold_response.denoised_obs;

state_enumeration = {<span class="string">'q'</span>,<span class="string">'v'</span>,<span class="string">'f'</span>,<span class="string">'s'</span>,<span class="string">'x'</span>};
state_enumeration(find(ismember(state_enumeration,simulation.observed_states))) = [];

ode_param.proxy.mean = zeros(length(symbols.param),1);
state.proxy.mean = zeros(length(time.est),length(symbols.state));
<span class="comment">% external_input</span>
ext_input_idx = cellfun(@(x) strcmp(x(2),<span class="string">'u'</span>),symbols.state);
state.proxy.mean(:,ext_input_idx) = state.ext_input(state.ext_input_to_bold_response_mapping_idx,2:end);

<span class="keyword">for</span> i=1:coord_ascent_numb_iter

    <span class="comment">% Learn intercept due to confounding effects</span>
    <span class="comment">% The intercept is determined by a minimum least squares estimator:</span>
    <span class="comment">%</span>
    <span class="comment">% $$\mathbf{X} \hat{\beta} := \mathbf{X} ( \mathbf{X}^T \mathbf{X} )^{-1} \mathbf{X}^T (\mathbf{y} - \mathbf{h}(\mathbf{q},\mathbf{v},\mathbf{u}))$$</span>
    <span class="comment">%</span>

    vol_idx = cellfun(@(x) strcmp(x(2),<span class="string">'v'</span>),symbols.state);
    deoxyhemo_idx = cellfun(@(x) strcmp(x(2),<span class="string">'q'</span>),symbols.state);

    bold_response_signal_change = bold_signal_change_eqn(state.proxy.mean(:,vol_idx),state.proxy.mean(:,deoxyhemo_idx));
    bold_response.confounding_effects.intercept = determine_intercept(bold_response.obs_old-bold_response_signal_change,<span class="keyword">...</span>
        bold_response.confounding_effects.X0,bold_response.confounding_effects.X0_penrose_inv);

    bold_response.confounding_effects.intercept = zeros(size(bold_response.obs,1),size(bold_response.obs,2));
    bold_response.denoised_obs = bold_response.obs_old - bold_response.confounding_effects.intercept;

    <span class="comment">% Proxy for states</span>
    <span class="comment">% Maximize the evidence lower bound (ELBO) one state at a time</span>
    <span class="comment">% (coordinate-ascent-wise) starting with deoxyhemoglobin followed by</span>
    <span class="comment">% blood volume, blood flow, vasosignalling and finally the neuronal</span>
    <span class="comment">% states.</span>

    damping = 0.1;
    <span class="keyword">for</span> j = 1:length(state_enumeration)
        <span class="keyword">if</span> strcmp(state_enumeration{j},<span class="string">'q'</span>)
            <span class="comment">% deoxyhemoglobin</span>
            state_idx = cellfun(@(x) strcmp(x(2),<span class="string">'q'</span>),symbols.state);
            state_tmp = maximize_lower_bound_wrt_deoxyhemo(state.deoxyhemo,state.proxy.mean,bold_response.denoised_obs,symbols);
            state.proxy.mean(:,state_idx) = (1-damping) * state.proxy.mean(:,state_idx) + damping * state_tmp;
        <span class="keyword">elseif</span> strcmp(state_enumeration{j},<span class="string">'v'</span>)
            <span class="comment">% blood volume</span>
            state_idx = cellfun(@(x) strcmp(x(2),<span class="string">'v'</span>),symbols.state);
            state_tmp = maximize_lower_bound_wrt_vol(state.vol,dC_times_invC,state.proxy.mean,ode_param.proxy.mean,symbols);
            state.proxy.mean(:,state_idx) = (1-damping) * state.proxy.mean(:,state_idx) + damping * state_tmp;
        <span class="keyword">elseif</span> strcmp(state_enumeration{j},<span class="string">'f'</span>)
            <span class="comment">% blood flow</span>
            state_idx = cellfun(@(x) strcmp(x(2),<span class="string">'f'</span>),symbols.state);
            state_tmp = maximize_lower_bound_wrt_flow(state.flow,dC_times_invC,state.proxy.mean,ode_param.proxy.mean,symbols);
            state.proxy.mean(:,state_idx) = (1-damping) * state.proxy.mean(:,state_idx) + damping * state_tmp;
        <span class="keyword">elseif</span> strcmp(state_enumeration{j},<span class="string">'s'</span>)
            <span class="comment">% vasosignalling</span>
            state_idx = cellfun(@(x) strcmp(x(2),<span class="string">'s'</span>),symbols.state);
            state.proxy.mean(:,state_idx) = maximize_lower_bound_wrt_vaso(state.vaso,dC_times_invC,state.proxy.mean,ode_param.proxy.mean,symbols);
        <span class="keyword">elseif</span> strcmp(state_enumeration{j},<span class="string">'x'</span>)
            <span class="comment">% neuronal populations</span>
            state_idx = cellfun(@(x) strcmp(x(2),<span class="string">'x'</span>),symbols.state);
            state.proxy.mean(:,state_idx) = maximize_lower_bound_wrt_neuronal_states(state.neuronal,state.proxy.mean,ode_param.proxy.mean',<span class="keyword">...</span>
                dC_times_invC,coupling_idx.states,symbols);
        <span class="keyword">end</span>
        <span class="comment">%state.proxy.mean(:,13:15) = bsxfun(@minus,state.proxy.mean(:,13:15),state.proxy.mean(1,13:15));</span>
        state.proxy.mean(:,1:15) = bsxfun(@minus,state.proxy.mean(:,1:15),state.proxy.mean(1,1:15));
    <span class="keyword">end</span>

    <span class="comment">% Plot states</span>
    <span class="keyword">if</span> ~mod(i,7)
        state_plot = state.proxy.mean; state_plot(:,1:9) = exp(state_plot(:,1:9));
        <span class="keyword">for</span> u = [3,6,9,12,15]<span class="comment">%13:15;</span>
            idx = 360; tmp = h.dynamics{u}.YLim;
            hold <span class="string">on</span>; plot(h.dynamics{u},time.est(1:idx),state_plot(1:idx,u),<span class="string">'LineWidth'</span>,0.7,<span class="string">'Color'</span>,[0.6,0.6,0.6]); h.dynamics{u}.YLim = tmp;
        <span class="keyword">end</span>
        drawnow
    <span class="keyword">end</span>

    <span class="comment">% Proxy for ODE parameters</span>
    <span class="comment">% Given the states, we estimate the proxy to the ODE parameters.</span>

    <span class="keyword">if</span> i&gt;200 || i==coord_ascent_numb_iter
        [ode_param.proxy.mean,ode_param.proxy.inv_cov] = proxy_for_ode_parameters(state.proxy.mean,dC_times_invC,ode_param.lin_comb,symbols,ode_param,A_plus_gamma);
    <span class="keyword">end</span>

<span class="keyword">end</span>
</pre><h2 id="35">Numerical integration with parameters estimated by variational gradient matching</h2><p>See whether we actually fit the BOLD response well. Curves are shown in black.</p><pre class="codeinput">[state,bold_response] = simulate_trajectory_with_vgm_param_est(state,state_orig,ode_param,bold_response,<span class="keyword">...</span>
    time,ode,state_sym,param_sym,symbols);
</pre><p><h4> Final result </h4></p><pre class="codeinput">plot_results(state,ode_param,bold_response,time,h,[1,2],simulation.odes,candidate_odes,simulation);
</pre><img vspace="5" hspace="5" src="dynamic_causal_models_05.png" style="width:1600px;height:800px;" alt=""> <img vspace="5" hspace="5" src="dynamic_causal_models_06.png" style="width:1200px;height:600px;" alt=""> <h2 id="37">Time Taken</h2><pre class="codeinput">disp([<span class="string">'time taken: '</span> num2str(toc) <span class="string">' seconds'</span>])
</pre><pre class="codeoutput">time taken: 27.3363 seconds
</pre><h2 id="38">References</h2><div><ul><li><b>Gorbach, N.S.</b> , <b>Bauer, S.</b> and Buhmann, J.M., Scalable Variational Inference for Dynamical Systems. 2017a. Neural Information Processing Systems (NIPS). <a href="https://papers.nips.cc/paper/7066-scalable-variational-inference-for-dynamical-systems.pdf">https://papers.nips.cc/paper/7066-scalable-variational-inference-for-dynamical-systems.pdf</a>, arxiv: <a href="https://arxiv.org/abs/1705.07079">https://arxiv.org/abs/1705.07079</a>.</li><li><b>Bauer, S.</b> , <b>Gorbach, N.S.</b> and Buhmann, J.M., Efficient and Flexible Inference for Stochastic Differential Equations. 2017b. Neural Information Processing Systems (NIPS). <a href="https://papers.nips.cc/paper/7274-efficient-and-flexible-inference-for-stochastic-systems.pdf">https://papers.nips.cc/paper/7274-efficient-and-flexible-inference-for-stochastic-systems.pdf</a></li><li>Wenk, P., Gotovos, A., Bauer, S., Gorbach, N.S., Krause, A. and Buhmann, J.M., Fast Gaussian Process Based Gradient Matching for Parameters Identification in Systems of Nonlinear ODEs. 2018. In submission to Conference on Uncertainty in Artificial Intelligence (UAI).</li><li>Calderhead, B., Girolami, M. and Lawrence. N.D., 2002. Accelerating Bayesian inference over nonlinear differential equation models. <i>In Advances in Neural Information Processing Systems (NIPS)</i> . 22.</li></ul></div><p>The authors in bold font have contributed equally to their respective papers.</p><h2 id="39">Subroutines</h2><p><h4> Kernel function </h4></p><p>Gradient matching with Gaussian processes assumes a joint Gaussian process prior on states and their derivatives:</p><p><img src="dynamic_causal_models_eq09462475681373695039.png" alt="$\left(\begin{array}{c} \mathbf{X} \\ \dot{\mathbf{X}} \end{array}\right)  \sim \mathcal{N} \left( \begin{array}{c} \mathbf{X} \\ \dot{\mathbf{X}} \end{array}; \begin{array}{c}  \mathbf{0} \\ \mathbf{0}  \end{array}, \begin{array}{cc}  \mathbf{C}_{\phi} &amp; \mathbf{C}_{\phi}' \\  '\mathbf{C}_{\phi} &amp; \mathbf{C}_{\phi}''  \end{array}  \right)$" style="width:177px;height:28px;">,</p><p><img src="dynamic_causal_models_eq15132385546029468189.png" alt="$\mathrm{cov}(x_k(t), x_k(t)) = C_{\phi_k}(t,t')$" style="width:131px;height:12px;"></p><p><img src="dynamic_causal_models_eq17058345339069568247.png" alt="$\mathrm{cov}(\dot{x}_k(t), x_k(t)) = \frac{\partial C_{\phi_k}(t,t') }{\partial t} =: C_{\phi_k}'(t,t')$" style="width:185px;height:18px;"></p><p><img src="dynamic_causal_models_eq08196297352138716370.png" alt="$\mathrm{cov}(x_k(t), \dot{x}_k(t)) = \frac{\partial C_{\phi_k}(t,t') }{\partial t'} =: {'C_{\phi_k}(t,t')}$" style="width:187px;height:17px;"></p><p><img src="dynamic_causal_models_eq02914213731374756582.png" alt="$\mathrm{cov}(\dot{x}_k(t), \dot{x}_k(t)) = \frac{\partial C_{\phi_k}(t,t') }{\partial t \partial t'} =: C_{\phi_k}''(t,t')$" style="width:185px;height:18px;">.</p><pre class="codeinput"><span class="keyword">function</span> [dC_times_invC,inv_C,A_plus_gamma] = kernel_function(kernel,state,time_est)

kernel.param_sym = sym([<span class="string">'rbf_param%d'</span>],[1,2]); assume(kernel.param_sym,<span class="string">'real'</span>);
kernel.time1 = sym(<span class="string">'time1'</span>); assume(kernel.time1,<span class="string">'real'</span>); kernel.time2 = sym(<span class="string">'time2'</span>); assume(kernel.time2,<span class="string">'real'</span>);
kernel.func = kernel.param_sym(1).*exp(-(kernel.time1-kernel.time2).^2./(kernel.param_sym(2).^2));                      <span class="comment">% RBF kernel</span>
kernel.name = <span class="string">'rbf'</span>;

<span class="comment">% kernel derivatives</span>
<span class="keyword">for</span> i = 1:length(kernel)
    kernel.func_d = diff(kernel.func,kernel.time1);
    kernel.func_dd = diff(kernel.func_d,kernel.time2);
    GP.fun = matlabFunction(kernel.func,<span class="string">'Vars'</span>,{kernel.time1,kernel.time2,kernel.param_sym});
    GP.fun_d = matlabFunction(kernel.func_d,<span class="string">'Vars'</span>,{kernel.time1,kernel.time2,kernel.param_sym});
    GP.fun_dd = matlabFunction(kernel.func_dd,<span class="string">'Vars'</span>,{kernel.time1,kernel.time2,kernel.param_sym});
<span class="keyword">end</span>

<span class="comment">% populate GP covariance matrix</span>
<span class="keyword">for</span> t=1:length(time_est)
    C(t,:)=GP.fun(time_est(t),time_est,kernel.param);
    dC(t,:)=GP.fun_d(time_est(t),time_est,kernel.param);
    Cd(t,:)=GP.fun_d(time_est,time_est(t),kernel.param);
    ddC(t,:)=GP.fun_dd(time_est(t),time_est,kernel.param);
<span class="keyword">end</span>

<span class="comment">% GP covariance scaling</span>
[~,D] = eig(C); perturb = abs(max(diag(D))-min(diag(D))) / 10000;
<span class="keyword">if</span> any(diag(D)&lt;1e-6); C(logical(eye(size(C,1)))) = C(logical(eye(size(C,1)))) + perturb.*rand(size(C,1),1); <span class="keyword">end</span>
[~,D] = eig(C);
<span class="keyword">if</span> any(diag(D)&lt;0); error(<span class="string">'C has negative eigenvalues!'</span>); <span class="keyword">elseif</span> any(diag(D)&lt;1e-6); warning(<span class="string">'C is badly scaled'</span>); <span class="keyword">end</span>
inv_C = inv_chol(chol(C,<span class="string">'lower'</span>));

dC_times_invC = dC * inv_C;

<span class="comment">% plot GP prior samples</span>
figure(3);
hold <span class="string">on</span>; plot(time_est,mvnrnd(zeros(1,length(time_est)),C(:,:,1),3),<span class="string">'LineWidth'</span>,2);
h1 = gca; h1.FontSize = 20; h1.XLabel.String = <span class="string">'time'</span>; h1.YLabel.String = <span class="string">'state value'</span>;
h1.Title.String = [kernel.name <span class="string">' kernel'</span>];

<span class="comment">% determine A_plus_gamma:</span>
A = ddC - dC_times_invC * Cd;
inv_Lambda = A + state.derivative_variance(1) .* eye(size(A));
inv_Lambda = 0.5.*(inv_Lambda+inv_Lambda');
A_plus_gamma = inv_chol(chol(inv_Lambda,<span class="string">'lower'</span>));

<span class="keyword">end</span>
</pre><p><h4> GP regression for observations</h4></p><p><img src="dynamic_causal_models_eq04537216543789424217.png" alt="$p(\mathbf{X} \mid \mathbf{Y}, \boldmath\phi,\gamma) = \prod_k \mathcal{N}(\mathbf{x}_k ; \boldmath\mu_k(\mathbf{y}_k),\boldmath\Sigma_k)$" style="width:181px;height:12px;">,</p><p>where <img src="dynamic_causal_models_eq06586455063503371300.png" alt="$\boldmath\mu_k(\mathbf{y}_k) := \sigma_k^{-2} \left(\sigma_k^{-2} \mathbf{I} + \mathbf{C}_{\boldmath\phi_k}^{-1} \right)^{-1} \mathbf{y}_k$" style="width:177px;height:23px;"> and <img src="dynamic_causal_models_eq05050976928104673176.png" alt="$\boldmath\Sigma_k ^{-1}:=\sigma_k^{-2} \mathbf{I} + \mathbf{C}_{\boldmath\phi_k}^{-1}$" style="width:101px;height:15px;">.</p><pre class="codeinput"><span class="keyword">function</span> [mu,inv_sigma] = GP_regression(bold_response,inv_Cxx,symbols)

inv_Cxx_cell = num2cell(inv_Cxx(:,:,ones(1,sum(cellfun(@(x) strcmp(x(2),<span class="string">'x'</span>),symbols.state)))),[1,2]);
inv_Cxx_blkdiag = blkdiag(inv_Cxx_cell{:});

b = repmat(var(bold_response.obs)./bold_response.SNR,size(bold_response.obs,1),1);
dim = size(inv_Cxx_blkdiag,1);
D = spdiags(reshape(b.^(-1),[],1),0,dim,dim) * speye(dim); <span class="comment">% covariance matrix of error term (big E)</span>
inv_sigma = D + inv_Cxx_blkdiag;

mu = inv_sigma \ D * reshape(bold_response.obs,[],1);
mu = reshape(mu,[],size(bold_response.obs,2));

<span class="keyword">end</span>
</pre><p><h4> Find ODE couplings </h4></p><pre class="codeinput"><span class="keyword">function</span> coupling_idx = find_couplings_in_odes(ode,symbols)

state_idx = cellfun(@(x) ~strcmp(x(2),<span class="string">'u'</span>),symbols.state);
learn_method.state(state_idx) = {<span class="string">'Laplace mean-field'</span>};
learn_method.state(~state_idx) = {<span class="string">'external input'</span>};

<span class="comment">%state couplings</span>
state_sym = sym([<span class="string">'state%d'</span>],[1,length(ode.system)]); assume(state_sym,<span class="string">'real'</span>);
<span class="keyword">for</span> k = 1:length(ode.system)
    tmp_idx = ismember(state_sym,symvar(ode.system_sym(k))); tmp_idx(:,k) = 1;
    ode_couplings_states(k,tmp_idx) = 1;
<span class="keyword">end</span>
<span class="keyword">for</span> u = find(strcmp(learn_method.state,<span class="string">'Laplace mean-field'</span>))
    coupling_idx_tmp = find(ode_couplings_states(:,u));
    coupling_idx.states{u} = coupling_idx_tmp;
<span class="keyword">end</span>

<span class="comment">% param couplings</span>
param_sym = sym([<span class="string">'param%d'</span>],[1,length(symbols.param)]); assume(param_sym,<span class="string">'real'</span>);
<span class="keyword">for</span> k = 1:length(ode.system)
    tmp_idx = ismember(param_sym,symvar(ode.system_sym(k)));
    ode_couplings_param(k,tmp_idx) = 1;
<span class="keyword">end</span>
<span class="keyword">for</span> i = 1:length(symbols.param)
    coupling_idx_tmp = find(ode_couplings_param(:,i));
    coupling_idx.param{i} = coupling_idx_tmp;
<span class="keyword">end</span>


<span class="keyword">end</span>
</pre><p><h4> Rewrite ODEs as linear combination in parameters </h4></p><p><img src="dynamic_causal_models_eq10575569337757673449.png" alt="$\mathbf{B}_{\boldmath\theta} \boldmath\theta + \mathbf{b}_{\boldmath\theta} \stackrel{!}{=} \mathbf{f}(\mathbf{X},\boldmath\theta)$" style="width:101px;height:15px;">,</p><p>where matrices <img src="dynamic_causal_models_eq12395521263852684086.png" alt="$\mathbf{B}_{\boldmath\theta}$" style="width:13px;height:10px;"> and <img src="dynamic_causal_models_eq14370145166438995955.png" alt="$\mathbf{b}_{\boldmath\theta}$" style="width:11px;height:10px;"> are defined such that the ODEs <img src="dynamic_causal_models_eq12466937249580769582.png" alt="$\mathbf{f}(\mathbf{X},\boldmath\theta)$" style="width:33px;height:11px;"> are expressed as a linear combination in <img src="dynamic_causal_models_eq07852716426910655037.png" alt="$\boldmath\theta$" style="width:5px;height:8px;">.</p><pre class="codeinput"><span class="keyword">function</span> [B,b] = rewrite_odes_as_linear_combination_in_parameters(ode,symbols)

param_sym = sym([<span class="string">'param%d'</span>],[1,length(symbols.param)]); assume(param_sym,<span class="string">'real'</span>);
state_sym = sym([<span class="string">'state%d'</span>],[1,length(symbols.state)]); assume(state_sym,<span class="string">'real'</span>);
state0_sym = sym([<span class="string">'state0'</span>]); assume(state0_sym,<span class="string">'real'</span>);
state_const_sym = sym([<span class="string">'state_const'</span>]); assume(state_const_sym,<span class="string">'real'</span>);

<span class="comment">% Rewrite ODEs as linear combinations in parameters</span>
[B_sym,b_sym] = equationsToMatrix(ode.system_sym,param_sym);
b_sym = -b_sym; <span class="comment">% See the documentation of the function "equationsToMatrix"</span>

<span class="comment">% Product of ODE factors (product of Gaussians)</span>
<span class="keyword">for</span> k = 1:length(ode.system)
    B_sym(k,B_sym(k,:)==<span class="string">'0'</span>) = state0_sym;
    <span class="keyword">for</span> i = 1:length(B_sym(k,:))
        sym_var = symvar(B_sym(k,i));
        <span class="keyword">if</span> isempty(sym_var)
            B_sym(k,i) = B_sym(k,i) + state0_sym;
        <span class="keyword">end</span>
    <span class="keyword">end</span>
    B{k} = matlabFunction(B_sym(k,:),<span class="string">'Vars'</span>,{state_sym,state0_sym,state_const_sym});
    b{k} = matlabFunction(b_sym(k,:),<span class="string">'Vars'</span>,{state_sym,state0_sym,state_const_sym});
<span class="keyword">end</span>

<span class="keyword">end</span>
</pre><p><h4> Rewrite ODEs as linear combination in individual states </h4></p><p><img src="dynamic_causal_models_eq16521733572904471250.png" alt="$\mathbf{B}_{u} \mathbf{x}_u + \mathbf{b}_{u} \stackrel{!}{=} \mathbf{f}(\mathbf{X},\boldmath\theta) - {'\mathbf{C}}_{\boldmath\phi} \mathbf{C}_{\boldmath\phi}^{-1} \mathbf{X}$" style="width:173px;height:17px;">.</p><p>where matrices <img src="dynamic_causal_models_eq11780124863314593273.png" alt="$\mathbf{B}_u$" style="width:13px;height:10px;"> and <img src="dynamic_causal_models_eq15590211095018081680.png" alt="$\mathbf{b}_u$" style="width:11px;height:10px;"> are defined such that the expression <img src="dynamic_causal_models_eq08371510633112951161.png" alt="$\mathbf{f}(\mathbf{X},\boldmath\theta) - {'\mathbf{C}}_{\boldmath\phi} \mathbf{C}_{\boldmath\phi}^{-1} \mathbf{X}$" style="width:101px;height:15px;"> is rewritten as a linear combination in the individual state <img src="dynamic_causal_models_eq00398522576481313565.png" alt="$\mathbf{x}_u$" style="width:11px;height:7px;">.</p><pre class="codeinput"><span class="keyword">function</span> [deoxyhemo,vol,flow,vaso,neuronal] = rewrite_odes_as_linear_combination_in_ind_states(ode,symbols,coupling_idx)

q_bool = 1; v_bool = 1; f_bool = 1; s_bool = 1;
state.neuronal = [];
<span class="keyword">for</span> u = 1:length(symbols.state)
    <span class="keyword">if</span> strcmp(symbols.state{u}(2),<span class="string">'q'</span>) &amp;&amp; q_bool
       [deoxyhemo.B,deoxyhemo.b] = rewrite_bold_signal_eqn_as_linear_combination_in_deoxyhemo(symbols);
       q_bool = 0;
    <span class="keyword">elseif</span> strcmp(symbols.state{u}(2),<span class="string">'v'</span>) &amp;&amp; v_bool
        [vol.B,vol.b] = rewrite_deoxyhemo_ODE_as_linear_combination_in_vol(ode,symbols);
        v_bool = 0;
    <span class="keyword">elseif</span> strcmp(symbols.state{u}(2),<span class="string">'f'</span>) &amp;&amp; f_bool
        [flow.B,flow.b] = rewrite_vol_ODE_as_linear_combination_in_flow(ode,symbols);
        f_bool = 0;
    <span class="keyword">elseif</span> strcmp(symbols.state{u}(2),<span class="string">'s'</span>) &amp;&amp; s_bool
        [vaso.B,vaso.b] = rewrite_vaso_and_flow_odes_as_linear_combination_in_vaso(ode,symbols);
        s_bool = 0;
    <span class="keyword">elseif</span> ~strcmp(symbols.state{u}(2),<span class="string">'q'</span>) &amp;&amp; ~strcmp(symbols.state{u}(2),<span class="string">'v'</span>) &amp;&amp; ~strcmp(symbols.state{u}(2),<span class="string">'f'</span>) &amp;&amp; ~strcmp(symbols.state{u}(2),<span class="string">'s'</span>)  &amp;&amp; ~strcmp(symbols.state{u}(2),<span class="string">'u'</span>)
        [neuronal.B,neuronal.b] = rewrite_odes_as_linear_combination_in_ind_neuronal_states(ode,symbols,coupling_idx.states{u}',u);
    <span class="keyword">end</span>
<span class="keyword">end</span>

<span class="keyword">end</span>
</pre><p><h4> Rewrite ODEs as linear combination in monotonic function of deoxyhemoglobin content $e^q$ </h4></p><pre class="codeinput"><span class="keyword">function</span> [B,b] = rewrite_bold_signal_eqn_as_linear_combination_in_deoxyhemo(symbols)

<span class="comment">% define symbolic variables</span>

param_sym = sym([<span class="string">'param%d'</span>],[1,length(symbols.param)]); assume(param_sym,<span class="string">'real'</span>);
state_sym = sym([<span class="string">'state%d'</span>],[1,length(symbols.state)]); assume(state_sym,<span class="string">'real'</span>);
v = sym(<span class="string">'v'</span>); assume(v,<span class="string">'real'</span>);
q = sym(<span class="string">'q'</span>); assume(q,<span class="string">'real'</span>);
exp_q = sym(<span class="string">'exp_q'</span>); assume(exp_q,<span class="string">'real'</span>);

<span class="comment">% bold signal change equation</span>

bold_signal_change = bold_signal_change_eqn(v,q);
[B,b] = equationsToMatrix(subs(bold_signal_change,exp(q),exp_q),exp_q);

B = matlabFunction(B,<span class="string">'Vars'</span>,{v,q});
b = matlabFunction(b,<span class="string">'Vars'</span>,{v,q});

<span class="keyword">end</span>
</pre><p><h4> Rewrite ODEs as linear combination in monotonic function of blood volume $e^v$ </h4></p><pre class="codeinput"><span class="keyword">function</span> [B,b] = rewrite_deoxyhemo_ODE_as_linear_combination_in_vol(ode,symbols)

<span class="comment">% define symbolic variables</span>
param_sym = sym([<span class="string">'param%d'</span>],[1,length(symbols.param)]); assume(param_sym,<span class="string">'real'</span>);
state_sym = sym([<span class="string">'state%d'</span>],[1,length(symbols.state)]); assume(state_sym,<span class="string">'real'</span>);
exp_v = sym(<span class="string">'exp_v'</span>); assume(exp_v,<span class="string">'real'</span>);

state_idx = find(cellfun(@(x) strcmp(x(2),<span class="string">'v'</span>),symbols.state));

<span class="comment">% deoxyhemo differential equation</span>
ode_idx = find(cellfun(@(x) strcmp(x(2),<span class="string">'q'</span>),symbols.state));
j = 0;
<span class="keyword">for</span> u = state_idx
    j = j+1;
    [B_sym,b_sym] = equationsToMatrix(subs(ode.system{ode_idx(j)}(state_sym,param_sym),exp((17*state_sym(u)/8)),exp_v),exp_v);
    B{u} = matlabFunction(B_sym,<span class="string">'Vars'</span>,{state_sym,param_sym});
    b{u} = matlabFunction(b_sym,<span class="string">'Vars'</span>,{state_sym,param_sym});
<span class="keyword">end</span>

<span class="keyword">end</span>
</pre><p><h4> Rewrite ODEs as linear combination in monotonic function of blood flow $e^f$ </h4></p><pre class="codeinput"><span class="keyword">function</span> [B,b] = rewrite_vol_ODE_as_linear_combination_in_flow(ode,symbols)

<span class="comment">% define symbolic variables</span>

param_sym = sym([<span class="string">'param%d'</span>],[1,length(symbols.param)]); assume(param_sym,<span class="string">'real'</span>);
state_sym = sym([<span class="string">'state%d'</span>],[1,length(symbols.state)]); assume(state_sym,<span class="string">'real'</span>);
exp_f = sym(<span class="string">'exp_f'</span>); assume(exp_f,<span class="string">'real'</span>);

state_idx = find(cellfun(@(x) strcmp(x(2),<span class="string">'f'</span>),symbols.state));

<span class="comment">% blood vol ODE</span>
ode_idx = find(cellfun(@(x) strcmp(x(2),<span class="string">'v'</span>),symbols.state));

j = 0;
<span class="keyword">for</span> u = state_idx
    j = j+1;
    [B_sym,b_sym] = equationsToMatrix(subs(ode.system{ode_idx(j)}(state_sym,param_sym),exp(state_sym(u)),exp_f),exp_f);
    B{u} = matlabFunction(B_sym,<span class="string">'Vars'</span>,{state_sym,param_sym});
    b{u} = matlabFunction(b_sym,<span class="string">'Vars'</span>,{state_sym,param_sym});
<span class="keyword">end</span>

<span class="keyword">end</span>
</pre><p><h4> Rewrite ODEs as linear combination in vasosignalling $s$ </h4></p><pre class="codeinput"><span class="keyword">function</span> [B,b] = rewrite_vaso_and_flow_odes_as_linear_combination_in_vaso(ode,symbols)

<span class="comment">% define symbolic variables</span>
param_sym = sym([<span class="string">'param%d'</span>],[1,length(symbols.param)]); assume(param_sym,<span class="string">'real'</span>);
state_sym = sym([<span class="string">'state%d'</span>],[1,length(symbols.state)]); assume(state_sym,<span class="string">'real'</span>);

state_idx = find(cellfun(@(x) strcmp(x(2),<span class="string">'s'</span>),symbols.state));

<span class="comment">% vasosignaling ODE</span>
ode_idx = find(cellfun(@(x) strcmp(x(2),<span class="string">'s'</span>),symbols.state));
j = 0;
<span class="keyword">for</span> u = state_idx
    j = j+1;
    [B_sym,b_sym] = equationsToMatrix(ode.system{ode_idx(j)}(state_sym,param_sym),state_sym(u));
    B{u}.vaso = matlabFunction(B_sym,<span class="string">'Vars'</span>,{state_sym,param_sym});
    b{u}.vaso = matlabFunction(b_sym,<span class="string">'Vars'</span>,{state_sym,param_sym});
<span class="keyword">end</span>

<span class="comment">% blood flow ODE</span>
ode_idx = find(cellfun(@(x) strcmp(x(2),<span class="string">'f'</span>),symbols.state));
j = 0;
<span class="keyword">for</span> u = state_idx
    j = j+1;
    [B_sym,b_sym] = equationsToMatrix(ode.system{ode_idx(j)}(state_sym,param_sym),state_sym(u));
    B{u}.flow = matlabFunction(B_sym,<span class="string">'Vars'</span>,{state_sym,param_sym});
    b{u}.flow = matlabFunction(b_sym,<span class="string">'Vars'</span>,{state_sym,param_sym});
<span class="keyword">end</span>

<span class="keyword">end</span>
</pre><p><h4> Rewrite ODEs as linear combination in neuronal states $n$ </h4></p><pre class="codeinput"><span class="keyword">function</span> [B,b]= rewrite_odes_as_linear_combination_in_ind_neuronal_states(ode,symbols,coupling_idx)

state_sym = sym(<span class="string">'state%d'</span>,[1,length(symbols.state)]); assume(state_sym,<span class="string">'real'</span>);
param_sym = sym(<span class="string">'param%d'</span>,[1,length(symbols.param)]); assume(param_sym,<span class="string">'real'</span>);

state_idx = find(cellfun(@(x) strcmp(x(2),<span class="string">'x'</span>),symbols.state));

<span class="keyword">for</span> u = state_idx
    <span class="keyword">for</span> k = coupling_idx{u}'
        [B_sym,b_sym] = equationsToMatrix(ode.system{k}(state_sym,param_sym'),state_sym(:,u));
        B{u,k} = matlabFunction(B_sym,<span class="string">'Vars'</span>,{state_sym,param_sym});
        b{u,k} = matlabFunction(b_sym,<span class="string">'Vars'</span>,{state_sym,param_sym});
    <span class="keyword">end</span>
<span class="keyword">end</span>

<span class="keyword">end</span>
</pre><img vspace="5" hspace="5" src="dynamic_causal_models_04.png" style="width:1600px;height:800px;" alt=""> <p><h4> Proxy for ODE parameters </h4></p><p><img src="dynamic_causal_models_eq09289431292542106091.png" alt="$\hat{q}(\theta) {\propto} \exp \left( ~E_{Q_{-\theta}}  \ln \mathcal{N} \left( \theta; \mathbf{B}_{\theta}^+ ~ \left( '\mathbf{C}_{\phi} \mathbf{C}_{\phi}^{-1} \mathbf{X} - \mathbf{b}_{\theta} \right), ~ \mathbf{B}_{\theta}^+ ~ (\mathbf{A} + \mathbf{I}\gamma) ~ \mathbf{B}_{\theta}^{+T} \right) ~\right)$" style="width:342px;height:20px;">,</p><pre class="codeinput"><span class="keyword">function</span> [param_proxy_mean,param_proxy_inv_cov] = proxy_for_ode_parameters(state_proxy_mean,dC_times_invC,lin_comb,symbols,ode_param,A_plus_gamma)

state0 = zeros(size(dC_times_invC,1),1);
param_proxy_inv_cov = zeros(length(symbols.param));
local_mean_sum = zeros(length(symbols.param),1);
<span class="keyword">for</span> k = 1: 1:sum(cellfun(@(x) ~strcmp(x(2),<span class="string">'u'</span>),symbols.state))
    B = lin_comb.B{k}(state_proxy_mean,state0,ones(size(state_proxy_mean,1),1));
    b = lin_comb.b{k}(state_proxy_mean,state0,ones(size(state_proxy_mean,1),1));

    local_mean = B' * (dC_times_invC * state_proxy_mean(:,k) - b);
    local_mean_sum = local_mean_sum + local_mean;

    local_inv_cov = B' * B;                 <span class="comment">% This works better than "B' * A_plus_gamma * B".</span>
    <span class="comment">%local_inv_cov = B' * A_plus_gamma * B;</span>
    param_proxy_inv_cov = param_proxy_inv_cov + local_inv_cov;
<span class="keyword">end</span>

<span class="keyword">if</span> isfield(ode_param,<span class="string">'prior'</span>)
    local_mean_sum = local_mean_sum + ode_param.prior.inv_cov*ode_param.prior.mean;
    param_proxy_inv_cov = param_proxy_inv_cov + ode_param.prior.inv_cov;
<span class="keyword">end</span>

<span class="comment">% Check consistency of covariance matrix</span>
[~,D] = eig(param_proxy_inv_cov);
<span class="keyword">if</span> any(diag(D)&lt;0)
    warning(<span class="string">'ode_param.proxy.inv_cov has negative eigenvalues!'</span>);
<span class="keyword">elseif</span> any(diag(D)&lt;1e-3)
    warning(<span class="string">'ode_param.proxy.inv_cov is badly scaled'</span>)
    disp(<span class="string">'perturbing diagonal of ode_param.proxy.inv_cov'</span>)
    perturb = abs(max(diag(D))-min(diag(D))) / 10000;
    param.proxy.inv_cov(logical(eye(size(param_proxy_inv_cov,1)))) = param_proxy_inv_cov(logical(eye(size(param_proxy_inv_cov,1)))) <span class="keyword">...</span>
        + perturb.*rand(size(param_proxy_inv_cov,1),1);
<span class="keyword">end</span>

param_proxy_mean = pinv(param_proxy_inv_cov) * local_mean_sum;

<span class="keyword">end</span>
</pre><p><h4> Proxy for individual states </h4></p><p><img src="dynamic_causal_models_eq00255091975289065005.png" alt="$\hat{q}(\mathbf{x}_u) \propto \exp\big( ~ E_{Q_{-u}} \ln \mathcal{N}\left(\mathbf{x}_u ; -\mathbf{B}_{u}^+ \mathbf{b}_u, ~\mathbf{B}_u^{+} ~ (\mathbf{A} + \mathbf{I}\gamma) ~ \mathbf{B}_u^{+T} \right) + E_{Q_{-u}} \ln \mathcal{N}\left(\mathbf{x}_u ; \boldmath\mu_u(\mathbf{Y}), \Sigma_u \right) \big)$" style="width:413px;height:14px;">,</p><pre class="codeinput"><span class="keyword">function</span> [state_mean,state_inv_cov] = proxy_for_ind_states(lin_comb,state_mean,<span class="keyword">...</span>
    ode_param,dC_times_invC,coupling_idx,symbols,mu,inv_sigma,state_obs_idx,<span class="keyword">...</span>
    clamp_obs_state_to_GP_regression)

<span class="keyword">if</span> clamp_obs_state_to_GP_regression
    state_enumeration = find(~state_obs_idx);
<span class="keyword">else</span>
    state_enumeration = 1:length(symbols.state);
<span class="keyword">end</span>

<span class="keyword">for</span> u = state_enumeration

    state_inv_cov(:,:,u) = zeros(size(dC_times_invC));
    local_mean_sum = zeros(size(dC_times_invC,1),1);
    <span class="keyword">for</span> k = coupling_idx{u}'
        <span class="keyword">if</span> k~=u
            B_ode = diag(lin_comb.B_ode{u,k}(state_mean,ode_param));
            <span class="keyword">if</span> size(B_ode,1) == 1; B_ode = B_ode.*eye(size(dC_times_invC,1)); <span class="keyword">end</span>

            state_inv_cov(:,:,u) = state_inv_cov(:,:,u) + B_ode' * B_ode;
            local_mean_sum = local_mean_sum + B_ode' * (dC_times_invC * state_mean(:,k) <span class="keyword">...</span>
                - lin_comb.b_ode{u,k}(state_mean,ode_param));
        <span class="keyword">else</span>
            B_ode = diag(lin_comb.B_ode{u,k}(state_mean,ode_param));
            <span class="keyword">if</span> size(B_ode,1) == 1; B_ode = B_ode.*eye(size(dC_times_invC,1)); <span class="keyword">end</span>
            B_ode = B_ode - dC_times_invC;

            state_inv_cov(:,:,u) = state_inv_cov(:,:,u) + B_ode' * B_ode;

            l = lin_comb.b_ode{u,k}(state_mean,ode_param); <span class="keyword">if</span> length(l)==1; l = zeros(length(local_mean_sum),1); <span class="keyword">end</span>
            local_mean_sum = local_mean_sum - B_ode' * l;
        <span class="keyword">end</span>
    <span class="keyword">end</span>

    state_mean(:,u) = (state_inv_cov(:,:,u) + inv_sigma(:,:,u)) \ (local_mean_sum + (inv_sigma(:,:,u) * mu(:,u)));
<span class="keyword">end</span>

<span class="keyword">end</span>
</pre><p><h4> Prior on neuronal couplings </h4></p><pre class="codeinput"><span class="keyword">function</span> ode_param = prior_on_ODE_param(ode_param,param_prior,param_symbols)

numb_states = 3;
ode_param.prior.mean = zeros(length(param_symbols),1);
ode_param.prior.mean(end-numb_states+1:end) = -1;
tmp = param_prior*ones(1,length(param_symbols));
tmp(end-numb_states+1:end) = 1e-3;
ode_param.prior.inv_cov = diag(tmp.^(-1));

<span class="keyword">end</span>
</pre><p><h4> Confounding effects </h4></p><pre class="codeinput"><span class="keyword">function</span> bold_response = confounding_effects(bold_response)

bold_response.confounding_effects.X0 = importdata(<span class="string">'dcm/confounding_effects_X0.txt'</span>);
bold_response.confounding_effects.beta = importdata(<span class="string">'dcm/confounding_effects_beta.txt'</span>);

<span class="comment">%bold_response.confounding_effects.X0 = importdata('aphasia/confounding_effects_X0.txt');</span>

<span class="comment">%bold_response.confounding_effects.X0 = ones(size(bold_response.confounding_effects.X0,1),1);</span>

<span class="comment">% bold_response.confounding_effects.X0 = [ones(size(bold_response.confounding_effects.X0,1),1),...</span>
<span class="comment">%     bold_response.confounding_effects.X0];</span>

bold_response.confounding_effects.X0_penrose_inv = (bold_response.confounding_effects.X0' * <span class="keyword">...</span>
    bold_response.confounding_effects.X0)^(-1) * bold_response.confounding_effects.X0';

bold_response.confounding_effects.intercept = ones(size(bold_response.obs));

<span class="keyword">end</span>
</pre><p><h4> Import ODEs </h4></p><pre class="codeinput"><span class="keyword">function</span> ode = import_odes(symbols)

path_ode = <span class="string">'./dcm/candidate_odes.txt'</span>;                                      <span class="comment">% path to candidtae system of ODEs</span>

ode.raw = importdata(path_ode);
ode.refined = ode.raw;

<span class="keyword">for</span> k = 1:length(ode.refined)
<span class="keyword">for</span> u = 1:length(symbols.state); ode.refined{k} = strrep(ode.refined{k},[symbols.state{u}],[<span class="string">'state(:,'</span> num2str(u) <span class="string">')'</span>]); <span class="keyword">end</span>
<span class="keyword">for</span> j = 1:length(symbols.param); ode.refined{k} = strrep(ode.refined{k},symbols.param{j},[<span class="string">'param('</span> num2str(j) <span class="string">')'</span>]); <span class="keyword">end</span>
<span class="keyword">end</span>
<span class="keyword">for</span> k = 1:length(ode.refined); ode.system{k} = str2func([<span class="string">'@(state,param)('</span> ode.refined{k} <span class="string">')'</span>]); <span class="keyword">end</span>

<span class="keyword">end</span>
</pre><p><h4> write ODEs symbolically </h4></p><pre class="codeinput"><span class="keyword">function</span> [ode,state_sym,param_sym] = write_ODEs_symbolically(symbols,ode)

param_sym = sym(<span class="string">'param%d'</span>,[1,length(symbols.param)]); assume(param_sym,<span class="string">'real'</span>);
state_sym = sym(<span class="string">'state%d'</span>,[1,length(symbols.state)]); assume(state_sym,<span class="string">'real'</span>);
<span class="keyword">for</span> k = 1:length(ode.system)
    ode.system_sym(k) = ode.system{k}(state_sym,param_sym);
<span class="keyword">end</span>

<span class="keyword">end</span>
</pre><p><h4> Simulate state trajectories by numerical integration </h4></p><pre class="codeinput"><span class="keyword">function</span> [state,time,bold_response] = simulate_dynamics_by_numerical_integration(state,state_sym,param_sym,<span class="keyword">...</span>
    time,ode,ode_param_true,bold_response,symbols)

idx0 = cellfun(@(x) ~strcmp(x(2),<span class="string">'u'</span>),symbols.state);
learn_method.state(idx0) = {<span class="string">'Laplace mean-field'</span>};
learn_method.state(~idx0) = {<span class="string">'external input'</span>};

state.obs_idx = zeros(1,sum(idx0));
state.init_val = zeros(1,sum(idx0));
<span class="comment">%</span>
init_val = 0.01*ones(1,sum(idx0));

<span class="comment">%</span>
dt = state.ext_input(end,1) - state.ext_input(end-1,1);
ode_system_mat = matlabFunction(ode.system_sym',<span class="string">'Vars'</span>,{state_sym(~strcmp(learn_method.state,<span class="string">'external input'</span>))',<span class="keyword">...</span>
        param_sym',state_sym(strcmp(learn_method.state,<span class="string">'external input'</span>))'});

<span class="comment">% warning ('off','all');</span>
[ToutX,OutX_solver] = ode113(@(t,x) ode_function(t,x,ode_system_mat,ode_param_true',state.ext_input(:,2:end),state.ext_input(:,1)),<span class="keyword">...</span>
    state.ext_input(:,1), init_val);
<span class="comment">% warning ('on','all');</span>

[~,idx] = min(pdist2(ToutX,state.ext_input(:,1)),[],1);
ToutX = ToutX(idx); OutX_solver = OutX_solver(idx,:);

<span class="comment">% pack</span>
[~,state.ext_input_to_bold_response_mapping_idx] = min(pdist2(state.ext_input(:,1),time.est'),[],1);
state.true = OutX_solver(state.ext_input_to_bold_response_mapping_idx,:);
state.true(1:5,:) = 0;

time.true = ToutX';
time.samp = time.true(state.ext_input_to_bold_response_mapping_idx);

<span class="comment">% true bold responses</span>
bold_response.true = bold_signal_change_eqn(state.true(:,cellfun(@(x) strcmp(x(2),<span class="string">'v'</span>),symbols.state)),state.true(:,cellfun(@(x) strcmp(x(2),<span class="string">'q'</span>),symbols.state)));
<span class="comment">% mean correction</span>
<span class="comment">% bold_response.confounding_effects.intercept = mean(bold_response.true,1);</span>
<span class="comment">% bold_response.true = bsxfun(@minus,bold_response.true,mean(bold_response.true,1));</span>
<span class="comment">% % bold_response.confounding_effects.X0 = ones(size(bold_response.true));</span>

<span class="comment">% observed bold responses</span>
bold_response.obs = bold_response.true + bsxfun(@times,sqrt(var(bold_response.true) ./ bold_response.SNR),randn(size(bold_response.true)));
bold_response.confounding_effects.intercept = mean(bold_response.obs,1);
bold_response.variance = (repmat(max(bold_response.obs,[],1),size(bold_response.obs,1),1)./bold_response.SNR).^2;

<span class="comment">% pack</span>
state.obs = state.true(:,find(state.obs_idx));

<span class="comment">% align externel input with observations</span>
shift_num = 1;
e = state.ext_input;
e(shift_num+1:end,2:end) = state.ext_input(1:end-shift_num,2:end);
e(1:shift_num,2:end) = zeros(shift_num,size(state.ext_input,2)-1);
state.ext_input = e;

<span class="keyword">end</span>
</pre><p><h4> Simulate state trajectories by numerical integration with parameters estimated by variational gradient matching </h4></p><pre class="codeinput"><span class="keyword">function</span> [state,bold_response] = simulate_trajectory_with_vgm_param_est(state,state_orig,ode_param,<span class="keyword">...</span>
    bold_response,time,ode,state_sym,param_sym,symbols)
</pre><pre class="codeinput"><span class="comment">% Learn_method</span>
idx = cellfun(@(x) ~strcmp(x(2),<span class="string">'u'</span>),symbols.state);
learn_method.state(idx) = {<span class="string">'Laplace mean-field'</span>};
learn_method.state(~idx) = {<span class="string">'external input'</span>};
</pre><pre class="codeinput">bold_response.prediction.num_int_with_gm_param_est = [];
<span class="comment">%try</span>
    state_orig.init_val = state.proxy.mean(1,~strcmp(learn_method.state,<span class="string">'external input'</span>));

    state_sim = simulate_dynamics_by_numerical_integration(state_orig,state_sym,param_sym,<span class="keyword">...</span>
        time,ode,ode_param.proxy.mean',bold_response,symbols);

    state.num_int_with_gm_param_est = state_sim.true;

    <span class="comment">%</span>
    bold_response_signal_change = bold_signal_change_eqn(state.num_int_with_gm_param_est(:,cellfun(@(x) strcmp(x(2),<span class="string">'v'</span>),symbols.state)),<span class="keyword">...</span>
        state.num_int_with_gm_param_est(:,cellfun(@(x) strcmp(x(2),<span class="string">'q'</span>),symbols.state)));
    bold_response.confounding_effects.intercept = determine_intercept(bold_response.obs_old-bold_response_signal_change,<span class="keyword">...</span>
        bold_response.confounding_effects.X0,bold_response.confounding_effects.X0_penrose_inv);
    bold_response.prediction.num_int_with_gm_param_est = bold_response_signal_change + bold_response.confounding_effects.intercept;

    <span class="comment">%</span>
    state.num_int_with_gm_param_est(1,:) = [];
    state.num_int_with_gm_param_est(end+1,:) = zeros(1,size(state.num_int_with_gm_param_est,2));
    bold_response.prediction.num_int_with_gm_param_est(1,:) = [];
    bold_response.prediction.num_int_with_gm_param_est(end+1,:) = zeros(1,size(bold_response.prediction.num_int_with_gm_param_est,2));

<span class="comment">%     var = diag(ode_param.prior.inv_cov).^(-1);</span>
<span class="comment">%     %if max(var)&lt;=0.5%~any(isnan(var))</span>
<span class="comment">%     ode_param.proxy.mean(1:end-3) = sqrt(var(1:end-3)).*randn(length(ode_param.proxy.mean(1:end-3)),1);</span>
<span class="comment">%     warning('off')</span>
<span class="comment">%</span>
<span class="comment">%     state_sim_prior_sampled = simulate_dynamics(state_orig,state_sym,param_sym,...</span>
<span class="comment">%         time,ode,ode_param.proxy.mean',bold_response,symbols);</span>
<span class="comment">%     warning('on')</span>
<span class="comment">%     state.num_int_with_prior_sampled_param = state_sim_prior_sampled.true;</span>
<span class="comment">%</span>
<span class="comment">%     bold_response.prediction.num_int_with_prior_sampled_param = bold_signal_change_eqn(state_sim_prior_sampled.true(:,cellfun(@(x) strcmp(x(2),'v'),symbols.state)),...</span>
<span class="comment">%         state_sim_prior_sampled.true(:,cellfun(@(x) strcmp(x(2),'q'),symbols.state))) ...</span>
<span class="comment">%         + bold_response.confounding_effects.intercept;</span>
    <span class="comment">%end</span>
<span class="comment">%end</span>
</pre><pre class="codeinput"><span class="keyword">end</span>
</pre><p><h4> Generate observations of states </h4></p><pre class="codeinput"><span class="keyword">function</span> [state,time,obs_to_state_relation] = generate_state_obs(state,time,simulation)

<span class="comment">% State observations</span>
state_obs_variance = simulation.state_obs_variance(state.true);
state.obs = state.true + sqrt(state_obs_variance) .* randn(size(state.true));

<span class="comment">% Relationship between states and observations</span>
<span class="keyword">if</span> length(simulation.time_samp) &lt; length(time.est)
    time.idx = munkres(pdist2(simulation.time_samp',time.est'));
    time.ind = sub2ind([length(simulation.time_samp),length(time.est)],1:length(simulation.time_samp),time.idx);
<span class="keyword">else</span>
    time.idx = munkres(pdist2(time.est',simulation.time_samp'));
    time.ind = sub2ind([length(time.est),length(simulation.time_samp)],1:length(time.est),time.idx);
<span class="keyword">end</span>

time.obs_time_to_state_time_relation = zeros(length(simulation.time_samp),length(time.est)); time.obs_time_to_state_time_relation(time.ind) = 1;
state_mat = eye(size(state.true,2));
obs_to_state_relation = sparse(kron(state_mat,time.obs_time_to_state_time_relation));
time.samp = simulation.time_samp;

<span class="keyword">end</span>
</pre><p>generate DCM ODEs</p><pre class="codeinput"><span class="keyword">function</span> [symbols,param_learning_mask] = generate_generic_DCM_odes2(ode_type,ode_path)

numb_states = 3;
<span class="keyword">if</span> strcmp(ode_type,<span class="string">'nonlin_fwd_mod'</span>)
    param_learning_mask.a = ones(numb_states,numb_states); param_learning_mask.a(1,3) = 0; param_learning_mask.a(3,1) = 0;
    [row_idx,col_idx] = find(eye(size(param_learning_mask.a,1)));
    lin_ind = sub2ind(size(param_learning_mask.a),row_idx(1:end-1)+1,col_idx(1:end-1));
    param_learning_mask.a(lin_ind) = 1;

    param_learning_mask.b = zeros(numb_states,numb_states,3); param_learning_mask.b(2,1,2) = 1;
    param_learning_mask.c = zeros(numb_states,3); param_learning_mask.c(1,1) = 1; param_learning_mask.c(3,3) = 1;
    param_learning_mask.d = zeros(numb_states,numb_states,3); param_learning_mask.d(2,1,3) = 1;

<span class="keyword">elseif</span> strcmp(ode_type,<span class="string">'bwd_mod_driving'</span>)
    param_learning_mask.a = ones(numb_states,numb_states); param_learning_mask.a(1,3) = 0; param_learning_mask.a(3,1) = 0;
    [row_idx,col_idx] = find(eye(size(param_learning_mask.a,1)));
    lin_ind = sub2ind(size(param_learning_mask.a),row_idx(1:end-1)+1,col_idx(1:end-1));
    param_learning_mask.a(lin_ind) = 1;

    param_learning_mask.b = zeros(numb_states,numb_states,3); param_learning_mask.b(2,1,2) = 1; param_learning_mask.b(2,3,3) = 1;
    param_learning_mask.c = zeros(numb_states,3); param_learning_mask.c(1,1) = 1; param_learning_mask.c(3,3) = 1;
    param_learning_mask.d = zeros(numb_states,numb_states,3);

<span class="keyword">elseif</span> strcmp(ode_type,<span class="string">'bwd_mod'</span>)
    param_learning_mask.a = ones(numb_states,numb_states); param_learning_mask.a(1,3) = 0; param_learning_mask.a(3,1) = 0;
    [row_idx,col_idx] = find(eye(size(param_learning_mask.a,1)));
    lin_ind = sub2ind(size(param_learning_mask.a),row_idx(1:end-1)+1,col_idx(1:end-1));
    param_learning_mask.a(lin_ind) = 1;

    param_learning_mask.b = zeros(numb_states,numb_states,3); param_learning_mask.b(2,1,2) = 1; param_learning_mask.b(2,3,3) = 1;
    param_learning_mask.c = zeros(numb_states,3); param_learning_mask.c(1,1) = 1;
    param_learning_mask.d = zeros(numb_states,numb_states,3);

<span class="keyword">elseif</span> strcmp(ode_type,<span class="string">'driving'</span>)
    param_learning_mask.a = ones(numb_states,numb_states); param_learning_mask.a(1,3) = 0; param_learning_mask.a(3,1) = 0;
    [row_idx,col_idx] = find(eye(size(param_learning_mask.a,1)));
    lin_ind = sub2ind(size(param_learning_mask.a),row_idx(1:end-1)+1,col_idx(1:end-1));
    param_learning_mask.a(lin_ind) = 1;

    param_learning_mask.b = zeros(numb_states,numb_states,3); param_learning_mask.b(2,1,2) = 1;
    param_learning_mask.c = zeros(numb_states,3); param_learning_mask.c(1,1) = 1; param_learning_mask.c(3,3) = 1;
    param_learning_mask.d = zeros(numb_states,numb_states,3);

<span class="keyword">elseif</span> strcmp(ode_type,<span class="string">'fwd_mod'</span>)
    param_learning_mask.a = ones(numb_states,numb_states); param_learning_mask.a(1,3) = 0; param_learning_mask.a(3,1) = 0;
    [row_idx,col_idx] = find(eye(size(param_learning_mask.a,1)));
    lin_ind = sub2ind(size(param_learning_mask.a),row_idx(1:end-1)+1,col_idx(1:end-1));
    param_learning_mask.a(lin_ind) = 1;

    param_learning_mask.b = zeros(numb_states,numb_states,3); param_learning_mask.b(2,1,2) = 1; param_learning_mask.b(2,1,3) = 1;
    param_learning_mask.c = zeros(numb_states,3); param_learning_mask.c(1,1) = 1;
    param_learning_mask.d = zeros(numb_states,numb_states,3);

<span class="keyword">elseif</span> strcmp(ode_type,<span class="string">'fwd_mod_driving'</span>)
    param_learning_mask.a = ones(numb_states,numb_states); param_learning_mask.a(1,3) = 0; param_learning_mask.a(3,1) = 0;
    [row_idx,col_idx] = find(eye(size(param_learning_mask.a,1)));
    lin_ind = sub2ind(size(param_learning_mask.a),row_idx(1:end-1)+1,col_idx(1:end-1));
    param_learning_mask.a(lin_ind) = 1;

    param_learning_mask.b = zeros(numb_states,numb_states,3); param_learning_mask.b(2,1,2) = 1; param_learning_mask.b(2,1,3) = 1;
    param_learning_mask.c = zeros(numb_states,3); param_learning_mask.c(1,1) = 1; param_learning_mask.c(3,3) = 1;
    param_learning_mask.d = zeros(numb_states,numb_states,3);

<span class="keyword">elseif</span> strcmp(ode_type,<span class="string">'no_att'</span>)
    param_learning_mask.a = ones(numb_states,numb_states); param_learning_mask.a(1,3) = 0; param_learning_mask.a(3,1) = 0; param_learning_mask.a(2,3) = 0;
    [row_idx,col_idx] = find(eye(size(param_learning_mask.a,1)));
    lin_ind = sub2ind(size(param_learning_mask.a),row_idx(1:end-1)+1,col_idx(1:end-1));
    param_learning_mask.a(lin_ind) = 1;

    param_learning_mask.b = zeros(numb_states,numb_states,3); param_learning_mask.b(2,1,2) = 1;
    param_learning_mask.c = zeros(numb_states,3); param_learning_mask.c(1,1) = 1; param_learning_mask.c(3,3) = 0;
    param_learning_mask.d = zeros(numb_states,numb_states,3);

<span class="keyword">elseif</span> strcmp(ode_type,<span class="string">'no_photic'</span>)
    param_learning_mask.a = ones(numb_states,numb_states); param_learning_mask.a(1,3) = 0; param_learning_mask.a(3,1) = 0;
    [row_idx,col_idx] = find(eye(size(param_learning_mask.a,1)));
    lin_ind = sub2ind(size(param_learning_mask.a),row_idx(1:end-1)+1,col_idx(1:end-1));
    param_learning_mask.a(lin_ind) = 1;

    param_learning_mask.b = zeros(numb_states,numb_states,3); param_learning_mask.b(2,1,2) = 1;
    param_learning_mask.c = zeros(numb_states,3); param_learning_mask.c(1,1) = 0; param_learning_mask.c(3,3) = 1;
    param_learning_mask.d = zeros(numb_states,numb_states,3);

<span class="keyword">elseif</span> strcmp(ode_type,<span class="string">'photic'</span>)
    param_learning_mask.a = ones(numb_states,numb_states); param_learning_mask.a(1,3) = 0; param_learning_mask.a(3,1) = 0;
    [row_idx,col_idx] = find(eye(size(param_learning_mask.a,1)));
    lin_ind = sub2ind(size(param_learning_mask.a),row_idx(1:end-1)+1,col_idx(1:end-1));
    param_learning_mask.a(lin_ind) = 1;

    param_learning_mask.b = zeros(numb_states,numb_states,3); param_learning_mask.b(2,1,2) = 1;
    param_learning_mask.c = zeros(numb_states,3); param_learning_mask.c(1,1) = 1; param_learning_mask.c(3,3) = 1;
    param_learning_mask.d = zeros(numb_states,numb_states,3);

<span class="keyword">elseif</span> strcmp(ode_type,<span class="string">'no_mod'</span>)
    param_learning_mask.a = ones(numb_states,numb_states); param_learning_mask.a(1,3) = 0; param_learning_mask.a(3,1) = 0;
    [row_idx,col_idx] = find(eye(size(param_learning_mask.a,1)));
    lin_ind = sub2ind(size(param_learning_mask.a),row_idx(1:end-1)+1,col_idx(1:end-1));
    param_learning_mask.a(lin_ind) = 1;

    param_learning_mask.b = zeros(numb_states,numb_states,3);
    param_learning_mask.c = zeros(numb_states,3); param_learning_mask.c(1,1) = 1; param_learning_mask.c(3,3) = 1;
    param_learning_mask.d = zeros(numb_states,numb_states,3);

<span class="keyword">end</span>

symbols = generate_DCM_ODEs(ode_path,param_learning_mask,numb_states);                 <span class="comment">% writes the "ODE.txt" file</span>

<span class="keyword">end</span>
</pre><p>generate DCM ODEs</p><pre class="codeinput"><span class="keyword">function</span> symbols = generate_DCM_ODEs(path_ode,param_learning_idx,numb_states)

[odes,X,U,A,B,C,D] = neuronal_dynamics(param_learning_idx,numb_states);
[odes(numb_states+1:5*numb_states,:),S,F,V,Q] = hemodynamics_balloon(X,numb_states);

<span class="keyword">if</span> numb_states==3
    ode_reordered(1:3,:) = odes([13,15,14],:); ode_reordered(4:6,:) = odes([10,12,11],:); ode_reordered(7:9,:) = odes([7,9,8],:);
    ode_reordered(10:12,:) = odes([4,6,5],:); ode_reordered(13:15,:) = odes([1,3,2],:);

    X = X([1,3,2]); S = S([1,3,2]); F = F([1,3,2]); V = V([1,3,2]); Q = Q([1,3,2]);
<span class="keyword">else</span>
    ode_reordered = odes(end:-1:1);
    X = flipdim(X,1); S = flipdim(S,1); F = flipdim(F,1); V = flipdim(V,1); Q = flipdim(Q,1);
<span class="keyword">end</span>

<span class="comment">% State symbols renaming</span>
j=0;
<span class="keyword">for</span> i=1:length(Q)
    j = j+1;
    state_symbols_old{j} = char(Q(i));
    symbols.state{j} = [<span class="string">'['</span>,state_symbols_old{j}(1),<span class="string">'_{'</span>,state_symbols_old{j}(2:end),<span class="string">'}]'</span>];
<span class="keyword">end</span>
<span class="keyword">for</span> i=1:length(V)
    j = j+1;
    state_symbols_old{j} = char(V(i));
    symbols.state{j} = [<span class="string">'['</span>,state_symbols_old{j}(1),<span class="string">'_{'</span>,state_symbols_old{j}(2:end),<span class="string">'}]'</span>];
<span class="keyword">end</span>
<span class="keyword">for</span> i=1:length(F)
    j = j+1;
    state_symbols_old{j} = char(F(i));
    symbols.state{j} = [<span class="string">'['</span>,state_symbols_old{j}(1),<span class="string">'_{'</span>,state_symbols_old{j}(2:end),<span class="string">'}]'</span>];
<span class="keyword">end</span>
<span class="keyword">for</span> i=1:length(S)
    j = j+1;
    state_symbols_old{j} = char(S(i));
    symbols.state{j} = [<span class="string">'['</span>,state_symbols_old{j}(1),<span class="string">'_{'</span>,state_symbols_old{j}(2:end),<span class="string">'}]'</span>];
<span class="keyword">end</span>
<span class="keyword">for</span> u=1:length(X)
    j = j+1;
    state_symbols_old{j} = char(X(u));
    <span class="keyword">if</span> strcmp(state_symbols_old{j},<span class="string">'x1'</span>)
        symbols.state{j} = <span class="string">'[x_1]'</span>;
    <span class="keyword">elseif</span> strcmp(state_symbols_old{j},<span class="string">'x2'</span>)
        symbols.state{j} = <span class="string">'[x_2]'</span>;
    <span class="keyword">elseif</span> strcmp(state_symbols_old{j},<span class="string">'x3'</span>)
        symbols.state{j} = <span class="string">'[x_3]'</span>;
    <span class="keyword">end</span>
<span class="keyword">end</span>
<span class="keyword">for</span> i=1:length(U)
    j = j+1;
    state_symbols_old{j} = char(U(i));
    symbols.state{j} = [<span class="string">'['</span>,state_symbols_old{j}(1),<span class="string">'_{'</span>,state_symbols_old{j}(2:end),<span class="string">'}]'</span>];
<span class="keyword">end</span>

<span class="comment">% ODE parameter renaming</span>
j=0;
A2 = A;
A2(logical(eye(size(A2)))) = 0;
A2=reshape(A2,[],1); A2(A2==<span class="string">'0'</span>) = [];
<span class="keyword">for</span> i=1:length(A2)
    j = j+1;
    param_symbols_old{j} = [<span class="string">' '</span>,char(A2(i)),<span class="string">' '</span>];
    <span class="comment">%param_symbols_old{j} = make_index_double_digits(param_symbols_old{j});</span>
    symbols.param{j} = [<span class="string">'['</span>,param_symbols_old{j}(2),<span class="string">'_{'</span>,param_symbols_old{j}(3:end-1),<span class="string">'}]'</span>];
<span class="keyword">end</span>

<span class="keyword">for</span> u = 1:size(B,3)
    B2=reshape(B(:,:,u),[],1); B2(B2==<span class="string">'0'</span>) = [];
    <span class="keyword">if</span> ~isempty(D)
        <span class="keyword">for</span> i=1:length(B2)
            j = j+1;
            param_symbols_old{j} = [<span class="string">' '</span>,char(B2(i)),<span class="string">' '</span>];
            symbols.param{j} = [<span class="string">'['</span>,param_symbols_old{j}(2),<span class="string">'_{'</span>,param_symbols_old{j}(3:end-1),<span class="string">'}]'</span>];
        <span class="keyword">end</span>
    <span class="keyword">end</span>
<span class="keyword">end</span>

C=reshape(C,[],1); C(C==<span class="string">'0'</span>) = [];
<span class="keyword">for</span> i=1:length(C)
    j = j+1;
    param_symbols_old{j} = [<span class="string">' '</span>,char(C(i)),<span class="string">' '</span>];
    symbols.param{j} = [<span class="string">'['</span>,param_symbols_old{j}(2),<span class="string">'_{'</span>,param_symbols_old{j}(3:end-1),<span class="string">'}]'</span>];
<span class="keyword">end</span>

<span class="keyword">for</span> u = 1:size(D,3)
    D2=reshape(D(:,:,u),[],1); D2(D2==<span class="string">'0'</span>) = [];
    <span class="keyword">if</span> ~isempty(D2)
        <span class="keyword">for</span> i=1:length(D2)
            j = j+1;
            param_symbols_old{j} = [<span class="string">' '</span>,char(D2(i)),<span class="string">' '</span>];
            symbols.param{j} = [<span class="string">'['</span>,param_symbols_old{j}(2),<span class="string">'_{'</span>,param_symbols_old{j}(3:end-1),<span class="string">'}]'</span>];
        <span class="keyword">end</span>
    <span class="keyword">end</span>
<span class="keyword">end</span>

<span class="keyword">for</span> i=1:size(A)
    j = j+1;
    param_symbols_old{j} = [<span class="string">' '</span>,char(A(i,i)),<span class="string">' '</span>];
    symbols.param{j} = [<span class="string">'['</span>,param_symbols_old{j}(2),<span class="string">'_{'</span>,param_symbols_old{j}(3:end-1),<span class="string">'}]'</span>];
<span class="keyword">end</span>

<span class="comment">% replace symbols in ODEs</span>
dlmwrite(path_ode,[],<span class="string">'delimiter'</span>,<span class="string">''</span>)
<span class="keyword">for</span> k = 1:size(ode_reordered,1)
    string = [<span class="string">' '</span>,char(ode_reordered(k,:)),<span class="string">' '</span>];
    string = strrep(string,<span class="string">'*'</span>,<span class="string">' .* '</span>);
    string = strrep(string,<span class="string">'/'</span>,<span class="string">' ./ '</span>);
    string = strrep(string,<span class="string">'^'</span>,<span class="string">' .^ '</span>);

    <span class="keyword">for</span> u=1:length(state_symbols_old)
        string = strrep(string,state_symbols_old{u},symbols.state{u});
    <span class="keyword">end</span>

    <span class="keyword">for</span> i=1:length(param_symbols_old)
        string = strrep(string,param_symbols_old{i},[<span class="string">' '</span>,symbols.param{i},<span class="string">' '</span>]);
    <span class="keyword">end</span>
    string = strrep(string,<span class="string">'a21'</span>,[<span class="string">' '</span>,<span class="string">'[a_{21}]'</span>,<span class="string">' '</span>]);
    string = strrep(string,<span class="string">'a23'</span>,[<span class="string">' '</span>,<span class="string">'[a_{23}]'</span>,<span class="string">' '</span>]);

    string = strrep(string,<span class="string">' '</span>,<span class="string">''</span>);

    dlmwrite(path_ode,string,<span class="string">'delimiter'</span>,<span class="string">''</span>,<span class="string">'-append'</span>)
<span class="keyword">end</span>

<span class="keyword">end</span>
</pre><p><h4> Neuronal dynamics </h4></p><pre class="codeinput"><span class="keyword">function</span> [odes,X,U,A,B,C,D] = neuronal_dynamics(param_learning_mask,numb_states)

A = sym(<span class="string">'a%d%d'</span>,[numb_states,numb_states]); A(param_learning_mask.a==0) = 0; <span class="comment">%A(logical(eye(size(A)))) = -exp(diag(A));</span>
B = sym(<span class="string">'b%d%d%d'</span>,[numb_states,numb_states,size(param_learning_mask.c,2)]); B(param_learning_mask.b==0) = 0;
C = sym(<span class="string">'c%d%d'</span>,[numb_states,size(param_learning_mask.c,2)]); C(param_learning_mask.c==0) = 0;
D = sym(<span class="string">'d%d%d%d'</span>,[numb_states,numb_states,3]); D(param_learning_mask.d==0) = 0;

X = sym(<span class="string">'x%d'</span>,[numb_states,1]);
U = sym(<span class="string">'u%d'</span>,[size(param_learning_mask.c,2),1]);

B_times_U = zeros(numb_states,numb_states);
<span class="keyword">for</span> i = 1:size(B,3)
    B_times_U = B_times_U + B(:,:,i) .* U(i);
<span class="keyword">end</span>

odes = (A + B(:,:,1) .* U(1) + B_times_U <span class="keyword">...</span>
    + D(:,:,1) .* X(1) + D(:,:,2) .* X(2) + D(:,:,3) .* X(3)) * X + C * U;

<span class="keyword">end</span>
</pre><p><h4> Hemodynamics balloon model </h4></p><pre class="codeinput"><span class="keyword">function</span> [odes,S,F,V,Q] = hemodynamics_balloon(X,numb_states)

H = [0.64 0.32 2.00 0.32 0.4];

<span class="comment">% P.decay = [-0.0490; 0.0092; -0.0321];</span>
<span class="comment">% P.transit = [-0.1696;-0.2031;-0.0907];</span>
P.decay = [-0.0920;0.0192;-0.0661];
P.transit = [-0.2466;-0.1111;-0.1194];

kappa = H(1) * exp(P.decay);
gamma = H(2);
tau = H(3)*exp(P.transit);
alpha = H(4);
E0 = H(5);

kappa = 0.6; tau = 1.6;

S = sym(<span class="string">'s%d'</span>,[numb_states,1]);
F = sym(<span class="string">'f%d'</span>,[numb_states,1]);
V = sym(<span class="string">'v%d'</span>,[numb_states,1]);
Q = sym(<span class="string">'q%d'</span>,[numb_states,1]);

E = 1 - (1 - E0).^(exp(-F));

odes(1:numb_states,:) = X - kappa .* S - gamma .* (exp(F) - 1);
odes(numb_states+1:2*numb_states,:) = S ./ exp(F);
odes(2*numb_states+1:3*numb_states,:) = exp(F).*exp(-V)./tau - exp(V.*(1/alpha-1)) ./ tau;
odes(3*numb_states+1:4*numb_states,:) = E.*exp(F)./(E0*tau.*exp(Q)) - exp(V.*(1/alpha-1))./tau;

<span class="keyword">end</span>
</pre><p><h4> ODE function </h4></p><pre class="codeinput"><span class="keyword">function</span> state_derivatives = ode_function(time,states,ode_system_mat,ode_param,ext_input,time_lst)

[~,idx] = min(pdist2(time,time_lst));
u = ext_input(idx,:);

state_derivatives = ode_system_mat(states,ode_param,u');

<span class="keyword">end</span>
</pre><pre class="codeoutput">Warning: Failure at t=3.765300e+01.  Unable to meet integration tolerances
without reducing the step size below the smallest value allowed (1.136868e-13)
at time t. 
Warning: Failure at t=3.557028e+01.  Unable to meet integration tolerances
without reducing the step size below the smallest value allowed (1.136868e-13)
at time t. 
Warning: Failure at t=3.727086e+01.  Unable to meet integration tolerances
without reducing the step size below the smallest value allowed (1.136868e-13)
at time t. 
</pre><p><h4> Determine intercept </h4></p><pre class="codeinput"><span class="keyword">function</span> intercept = determine_intercept(bold_response_diff,X0,X0_penrose_inv)

<span class="comment">%intercept = X0 * X0_penrose_inv * X0' * bold_response_diff;</span>
intercept = X0 * X0_penrose_inv * bold_response_diff;

<span class="keyword">end</span>
</pre><p><h4> Setup plots </h4></p><pre class="codeinput"><span class="keyword">function</span> h = setup_plots(state,time,symbols,bold_response,fig_numbers,candidate_odes,simulation,plot_type)

<span class="keyword">if</span> nargin == 6
    plotting.layout = [4,4];                                               <span class="comment">% set the number of subplots</span>
    plotting.states = 1:15;                                                <span class="comment">% plot states</span>
<span class="keyword">else</span>
    plotting.layout = [3,2];                                               <span class="comment">% set the number of subplots</span>
    neuronal_state_titles_idx = find(cellfun(@(x) strcmp(x(2),<span class="string">'x'</span>),symbols.state));
    plotting.states = neuronal_state_titles_idx(1:3);
    plotting.states = [3,6,9,12,15];
<span class="keyword">end</span>

<span class="comment">% Plot colors</span>
color = [[117,112,179]./255; [217,95,2]./255; 0.7,0.7,0.7; [152,78,163]./255];
<span class="comment">%</span>
<span class="keyword">for</span> i = 1:length(symbols.param)
    symbols_param_plot{i} = symbols.param{i}(2:end-1);
<span class="keyword">end</span>

figure(fig_numbers(1)); clf
set(fig_numbers(1), <span class="string">'Position'</span>, [0, 200, 1400, 1000]);
set(fig_numbers(1), <span class="string">'Position'</span>, [0, 200, 1600, 800]);
axis <span class="string">tight</span>


h.couplings = subplot(plotting.layout(1),plotting.layout(2),1);

h.couplings.YLabel.String = <span class="string">'Neuronal Couplings'</span>;
h.couplings.YLabel.Rotation = 0;
h.couplings.YLabel.Units = <span class="string">'normalized'</span>;
h.couplings.YLabel.Position(1) = h.couplings.Title.Position(1);<span class="comment">%-0.35;</span>
h.couplings.YLabel.Position(2) = h.couplings.Title.Position(2);
h.couplings.XRuler.TickLength = [0,0];

set(gca,<span class="string">'XTick'</span>,[1:length(symbols.param)]); set(gca,<span class="string">'XTickLabel'</span>,symbols_param_plot);


<span class="keyword">if</span> length(symbols.param)&gt;9; h.couplings.XTickLabelRotation = 90; <span class="keyword">end</span>
h.couplings.FontSize = 15;
hold <span class="string">on</span>; drawnow

<span class="keyword">try</span>
    state_plot_true = state.true;
    state_plot_true(:,1:9) = exp(state_plot_true(:,1:9));

    state_plot_obs = state.obs;
    <span class="keyword">if</span> size(state_plot_obs,2)&lt;9
        state_plot_obs(:,1:end) = exp(state_plot_obs(:,1:end));
    <span class="keyword">else</span>
        state_plot_obs(:,1:9) = exp(state_plot_obs(:,1:9));
    <span class="keyword">end</span>
    idx = 360;
    state_plot_true = state_plot_true(1:idx,:); state_plot_obs = state_plot_obs(1:idx,:);
<span class="keyword">end</span>



i = 1; u2=0;
<span class="keyword">for</span> u = plotting.states
    i = i+1;
	h.dynamics{u} = subplot(plotting.layout(1),plotting.layout(2),i); cla
    <span class="keyword">try</span>; plot(h.dynamics{u},time.samp(1:idx),state_plot_true(:,u),<span class="string">'Color'</span>,color(2,:),<span class="string">'LineWidth'</span>,2); <span class="keyword">end</span>
    <span class="keyword">try</span>; hold <span class="string">on</span>; plot(h.dynamics{u},time.samp(1,:),state_plot_obs(:,u),<span class="string">'*'</span>,<span class="string">'MarkerSize'</span>,1,<span class="string">'Color'</span>,color(2,:)); <span class="keyword">end</span>
    <span class="keyword">try</span>; plot(h.dynamics{u},time.samp(1,:),state.num_int(:,u),<span class="string">'Color'</span>,color(4,:),<span class="string">'LineWidth'</span>,1); <span class="keyword">end</span>
    xlabel(<span class="string">'time (s)'</span>);
    h.dynamics{u}.FontSize = 20;
    h.dynamics{u}.Title.Units = <span class="string">'normalized'</span>;
    h.dynamics{u}.YLabel.String = symbols.state{u}(2:end-1);
    h.dynamics{u}.YLabel.Rotation = 0;
    h.dynamics{u}.YLabel.Units = <span class="string">'normalized'</span>;
    h.dynamics{u}.YLabel.Position(1) = h.dynamics{u}.Title.Position(1)-0.45;
    h.dynamics{u}.YLabel.Position(2) = h.dynamics{u}.Title.Position(2);
   <span class="comment">% h.dynamics{u}.XLim = [time.est(1), time.est(end)];</span>

    <span class="keyword">if</span> any(cellfun(@(x) strcmp(x,symbols.state{u}(2:end-1)),simulation.observed_states))
        u2 = u2+1; <span class="comment">%</span>
        <span class="keyword">try</span>;hold <span class="string">on</span>; plot(h.dynamics{u},time.samp,state.obs(:,u),<span class="string">'*'</span>,<span class="string">'Color'</span>,color,<span class="string">'MarkerSize'</span>,10); <span class="keyword">end</span>
        <span class="comment">%try;hold on; plot(time.samp,state_plot_obs(:,u),'*','Color',color(2,:)); end</span>
    <span class="keyword">end</span>

    hold <span class="string">on</span>;
    h.dynamics{u}.XLim(2) = max(time.est(1:idx));
<span class="keyword">end</span>

text(-0.45,4.2,{[<span class="string">'true:          '</span> simulation.odes],[<span class="string">'candidate: '</span> candidate_odes]},<span class="string">'Units'</span>,<span class="string">'normalized'</span>,<span class="string">'FontSize'</span>,18,<span class="string">'Interpreter'</span>,<span class="string">'none'</span>)

<span class="comment">% Bold Response</span>

<span class="keyword">if</span> length(fig_numbers)==2
figure(fig_numbers(2)); clf
set(fig_numbers(2), <span class="string">'Position'</span>, [0, 200, 1200, 600]);
axis <span class="string">tight</span>

plot_titles_idx = find(cellfun(@(x) strcmp(x(2),<span class="string">'x'</span>),symbols.state));

nPlot_rows = size(bold_response.obs,2); <span class="keyword">if</span> nPlot_rows &gt; 6; nPlot_rows = 3; <span class="keyword">end</span>

plot_idx = [1:2:nPlot_rows*2];
<span class="keyword">for</span> i = 1:nPlot_rows
    h.bold{i} = subplot(nPlot_rows,2,plot_idx(i));
    plot(h.bold{i},time.samp,bold_response.obs(:,i),<span class="string">'LineWidth'</span>,2,<span class="string">'Color'</span>,color(2,:)); hold <span class="string">on</span>;
    <span class="keyword">try</span>; plot(h.bold{i},time.est,bold_response.prediction.num_int(:,i),<span class="string">'LineWidth'</span>,1,<span class="string">'Color'</span>,color(4,:)); hold <span class="string">on</span>; <span class="keyword">end</span>
    h.bold{i}.XLim = [time.est(1), time.est(end)]; <span class="comment">%h.bold{i}.YLim = [-3,3];</span>
    h.bold{i}.FontSize = 15; xlabel(<span class="string">'time (s)'</span>);
    h.bold{i}.YLabel.String = [symbols.state{plot_titles_idx(i)}(2:end-1) <span class="string">' BOLD response'</span>]; h.bold{i}.YLabel.Rotation = 0; h.bold{i}.YLabel.Units = <span class="string">'normalized'</span>;
    h.bold{i}.Title.Units = <span class="string">'normalized'</span>; h.bold{i}.YLabel.Position(1) = h.bold{i}.Title.Position(1)-0.35;
    h.bold{i}.YLabel.Position(2) = h.bold{i}.Title.Position(2);
    <span class="comment">%h.bold{i}.YLim = [-5,5];</span>
<span class="keyword">end</span>
<span class="comment">%plot(h.bold{1},time.samp,2*state.ext_input(:,end),'LineWidth',1,'Color',[0.8,0.8,0.8]); hold on;</span>

<span class="comment">% External Input</span>
plot_titles_idx = flipdim(find(cellfun(@(x) strcmp(x(2),<span class="string">'u'</span>),symbols.state)),2);

plot_idx = [2:2:nPlot_rows*2];
<span class="keyword">for</span> i = 1:sum(cellfun(@(x) strcmp(x(2),<span class="string">'u'</span>),symbols.state))
    hY2 = subplot(nPlot_rows,2,plot_idx(i));
    plot(time.true,state.ext_input(:,i+1),<span class="string">'LineWidth'</span>,2,<span class="string">'Color'</span>,color(2,:)); hold <span class="string">on</span>;
    hY2.XLim = [state.ext_input(1,1), state.ext_input(end,1)]; hY2.FontSize = 15; xlabel(<span class="string">'time (s)'</span>,<span class="string">'FontSize'</span>,15);
    hY2.YLabel.String = symbols.state{plot_titles_idx(i)}(2:end-1); hY2.YLabel.Rotation = 0; hY2.YLabel.Units = <span class="string">'normalized'</span>;
    hY2.Title.Units = <span class="string">'normalized'</span>; hY2.YLabel.Position(1) = hY2.Title.Position(1)-0.4;
    hY2.YLabel.Position(2) = hY2.Title.Position(2);
<span class="keyword">end</span>

<span class="keyword">end</span>

<span class="comment">%</span>
color = [[117,112,179]./255; [217,95,2]./255; 0.7,0.7,0.7];

param_plot.true = simulation.ode_param';
param_plot.proxy = zeros(length(simulation.ode_param),1);

<span class="keyword">if</span> strcmp(simulation.odes,candidate_odes)
    <span class="keyword">try</span>
        b = bar(h.couplings,[1:length(param_plot.true)],[param_plot.true,param_plot.proxy]);
    <span class="keyword">catch</span>
        b = bar(h.couplings,[1:length(param_plot.true)+1],[[param_plot.true;0],[param_plot.proxy;0]]);
    <span class="keyword">end</span>
<span class="keyword">end</span>

b(1).EdgeColor = <span class="string">'none'</span>; b(1).FaceAlpha = 1; b(1).FaceColor = color(2,:);
b(2).EdgeColor = <span class="string">'none'</span>; b(2).FaceAlpha = 1; b(2).FaceColor = color(1,:);

h.couplings.XLim = [0.5,length(param_plot.true)+0.5];
<span class="keyword">try</span>;h.couplings.YLim = [min(min([param_plot.true',param_plot.proxy],[],1)),max(max([param_plot.true',param_plot.proxy],[],1))];<span class="keyword">end</span>
h.couplings.FontSize = 20;

figure(fig_numbers(1));

drawnow
<span class="keyword">end</span>
</pre><p><h4> Plot results </h4></p><pre class="codeinput"><span class="keyword">function</span> plot_results(state,ode_param,bold_response,time,h,fig_numbers,odes_true,candidate_odes,simulation)

plotting.layout = [2,2];                                               <span class="comment">% set the number of subplots</span>
plotting.states = find(~cellfun(@(x) isempty(x),h.dynamics));
plotting.states = plotting.states(1:3);
plotting.states = [3,6,9,12,15];


<span class="comment">% Plot colors</span>
color = [[117,112,179]./255; [217,95,2]./255; 0.7,0.7,0.7];

<span class="comment">% plot results</span>
state.obs_idx = [];

state.obs_ind = find(state.obs_idx);
state_plot_gm = state.proxy.mean; state_plot_gm(:,1:9) = exp(state_plot_gm(:,1:9));
state_plot_num_int = state.num_int_with_gm_param_est; state_plot_num_int(:,1:9) = exp(state_plot_num_int(:,1:9));

state_plot_true = state.true;
state_plot_true(:,1:9) = exp(state_plot_true(:,1:9));

<span class="keyword">try</span>; <span class="keyword">if</span> strcmp(plot_type,<span class="string">'plot_all'</span>); plotting.states = find(ones(1,size(state_plot_num_int,2))); <span class="keyword">end</span>; <span class="keyword">end</span>
<span class="keyword">for</span> u = plotting.states
    xlim = h.dynamics{u}.XLim; ylim = h.dynamics{u}.YLim;

    <span class="comment">%shaded_region = [state_plot_gm(:,u)+1*sqrt(state.proxy.variance(:,u)); flipdim(state_plot_gm(:,u)-1*sqrt(state.proxy.variance(:,u)),1)];</span>
    <span class="comment">%f = fill(h.dynamics{u},[time.est'; flipdim(time.est',1)], shaded_region, [222,235,247]/255); set(f,'EdgeColor','None');</span>

     <span class="comment">%hold on; plot(h.dynamics{u},time.est,state_plot_gm(:,u),'Color',color(1,:),'LineWidth',1);</span>
     <span class="comment">%hold on; plot(h.dynamics{u},time.est,state_plot_num_int(:,u),'Color',[77,175,74]./255,'LineWidth',2);</span>
     <span class="comment">%h.dynamics{u}.YLim = [min(state_plot(:,u)),max(state_plot(:,u))];</span>
     <span class="comment">%try;hold on; plot(h.dynamics{u},time.est(1:120),state.true(1:120,u),'Color',color(2,:),'LineWidth',2);end</span>
     idx = 360;
     <span class="keyword">try</span>;hold <span class="string">on</span>; plot(h.dynamics{u},time.est(1:idx),state_plot_true(1:idx,u),<span class="string">'Color'</span>,color(2,:),<span class="string">'LineWidth'</span>,2);<span class="keyword">end</span>
     hold <span class="string">on</span>; plot(h.dynamics{u},time.est(1:idx),state_plot_num_int(1:idx,u),<span class="string">'Color'</span>,[0,0,0],<span class="string">'LineWidth'</span>,1);
     <span class="comment">%h.dynamics{u}.YLim(2) = 0.6;</span>
     h.dynamics{u}.XLim(2) = max(time.est(1:idx));
<span class="keyword">end</span>

<span class="comment">% Predicted bold response</span>

<span class="keyword">if</span> length(fig_numbers)==2
figure(fig_numbers(2));

nPlot_rows = size(bold_response.obs,2); <span class="keyword">if</span> nPlot_rows &gt; 6; nPlot_rows = 3; <span class="keyword">end</span>
plot_idx = [1:2:nPlot_rows*2];
<span class="keyword">for</span> i = 1:nPlot_rows
    subplot(nPlot_rows,2,plot_idx(i)); hold <span class="string">on</span>;
    <span class="comment">%plot(h.bold{i}time.est,bold_response.prediction.gm(:,i),'LineWidth',2,'Color',color(1,:)); hold on;</span>
    <span class="comment">%plot(h.bold{i}time.est,bold_response.prediction.num_int_with_gm_param_est(:,i),'LineWidth',2,'Color',[77,175,74]./255); hold on;</span>
    plot(h.bold{i},time.est,bold_response.prediction.num_int_with_gm_param_est(:,i),<span class="string">'LineWidth'</span>,1,<span class="string">'Color'</span>,[0,0,0]); hold <span class="string">on</span>;
    <span class="keyword">try</span>;plot(h.bold{i},time.est,bold_response.prediction.num_int_with_prior_sampled_param(:,i),<span class="string">'LineWidth'</span>,2,<span class="string">'Color'</span>,[0.8,0.8,0.8]); hold <span class="string">on</span>;<span class="keyword">end</span>
    <span class="comment">%h.bold{i}.YLim = [-3,3];</span>
<span class="keyword">end</span>

<span class="comment">% try</span>
<span class="comment">% a = axes;</span>
<span class="comment">% t1 = title({odes_true,candidate_odes});</span>
<span class="comment">% t1.FontSize = 11;</span>
<span class="comment">% a.Visible = 'off';</span>
<span class="comment">% t1.Visible = 'on';</span>
<span class="comment">% t1.Interpreter = 'none';</span>
<span class="comment">% end</span>

<span class="keyword">end</span>
<span class="comment">% write results</span>
<span class="comment">%disp(' '); disp(['writing plots in ' results_directory]);</span>
<span class="comment">% if ~exist(results_directory); mkdir(results_directory); end</span>
<span class="comment">%</span>
<span class="comment">% set(1,'Units','Inches');</span>
<span class="comment">% pos = get(1,'Position'); set(1,'PaperPositionMode','Auto','PaperUnits','Inches','PaperSize',[pos(3),pos(4)]);</span>
<span class="comment">% print(1,[results_directory '/anticipate_dynamics.pdf'],'-dpdf','-r0')</span>
<span class="comment">%</span>
<span class="comment">% set(6,'Units','Inches');</span>
<span class="comment">% pos = get(6,'Position'); set(6,'PaperPositionMode','Auto','PaperUnits','Inches','PaperSize',[pos(3),pos(4)]);</span>
<span class="comment">% print(6,[results_directory '/anticipate_BOLD_responses.pdf'],'-dpdf','-r0')</span>

<span class="comment">% ODE param</span>
<span class="comment">% Plotting</span>
<span class="comment">% state_plot = state.proxy.mean; state_plot(:,1:9) = exp(state_plot(:,1:9));</span>
<span class="comment">% for u = plotting.states</span>
<span class="comment">%     hold on; plot(h.dynamics{u},time.est,state_plot(:,u),'LineWidth',0.5,'Color',color(3,:));</span>
<span class="comment">% end</span>

hold <span class="string">on</span>; cla(h.couplings);

param_plot.proxy = ode_param.proxy.mean;
<span class="comment">% try</span>
<span class="comment">%     param_plot.true = ode_param.true;</span>
<span class="comment">%     try</span>
<span class="comment">%         b = bar(h.couplings,[1:length(param_plot.proxy)],[param_plot.true',param_plot.proxy]);</span>
<span class="comment">%     catch</span>
<span class="comment">%         b = bar(h.couplings,[1:length(param_plot.proxy)+1],[[param_plot.true';0],[param_plot.proxy;0]]);</span>
<span class="comment">%     end</span>
<span class="comment">%     b(1).EdgeColor = 'none'; b(1).FaceAlpha = 1; b(1).FaceColor = color(2,:);</span>
<span class="comment">%     b(2).EdgeColor = 'none'; b(2).FaceAlpha = 1; b(2).FaceColor = color(1,:);</span>
<span class="comment">% catch</span>
<span class="comment">%     b = bar(h.couplings,[1:length(param_plot.proxy)],[param_plot.proxy]);</span>
<span class="comment">%     b(1).EdgeColor = 'none'; b(1).FaceAlpha = 1; b(1).FaceColor = color(1,:);</span>
<span class="comment">% end</span>

<span class="keyword">if</span> ~strcmp(odes_true,candidate_odes)
    b = bar(h.couplings,[1:length(param_plot.proxy)],[param_plot.proxy]);
    b(1).EdgeColor = <span class="string">'none'</span>; b(1).FaceAlpha = 1; b(1).FaceColor = color(1,:);
<span class="keyword">else</span>
     param_plot.true = simulation.ode_param;
    <span class="keyword">try</span>
        b = bar(h.couplings,[1:length(param_plot.proxy)],[param_plot.true',param_plot.proxy]);
    <span class="keyword">catch</span>
        b = bar(h.couplings,[1:length(param_plot.proxy)+1],[[param_plot.true';0],[param_plot.proxy;0]]);
    <span class="keyword">end</span>
    b(1).EdgeColor = <span class="string">'none'</span>; b(1).FaceAlpha = 1; b(1).FaceColor = color(2,:);
    b(2).EdgeColor = <span class="string">'none'</span>; b(2).FaceAlpha = 1; b(2).FaceColor = color(1,:);
<span class="keyword">end</span>

h.couplings.XLim = [0.5,length(param_plot.proxy)+0.5];
<span class="keyword">try</span>;h.couplings.YLim = [min(min([param_plot.true',param_plot.proxy],[],1)),max(max([param_plot.true',param_plot.proxy],[],1))];<span class="keyword">end</span>

drawnow

<span class="keyword">end</span>
</pre><p class="footer"><br><a href="http://www.mathworks.com/products/matlab/">Published with MATLAB&reg; R2017a</a><br></p></div><!--
##### SOURCE BEGIN #####
%% Variational Gradient Matching for Dynamical Systems: Dynamic Causal Models
%
% <<cover_pic.png>>
%
% Authors: *Nico Stephan Gorbach* and *Stefan Bauer*, email: nico.gorbach@gmail.com
%
% Instructional code for the NIPS (2018) paper " *Scalable Variational Inference for Dynamical Systems* "
% by Nico S. Gorbach, Stefan Bauer and Joachim M. Buhmann.
% The paper is available at <https://papers.nips.cc/paper/7066-scalable-variational-inference-for-dynamical-systems.pdf>.
% Please cite our paper if you use our program for a further publication.
% Part of the derivation below is described in Wenk et al. (2018).
%
% Example dynamical system used in this code: Lotka-Volterra system with *half* of the time points *unobserved*. The ODE parameters are also unobserved.

%% Advantages of Variational Gradient Matching
% The essential idea of gradient matching (Calderhead et al., 2002) is to match the gradient
% governed by the ODEs with that inferred from the observations. In contrast
% to previous approaches gradient matching introduces a prior over states
% instead of a prior over ODE parameters. The advantages of gradients
% matching is two-fold:
%%
%
% # A prior over the functional form of state dynamics as opposed to ODE parameters facilitates a
% more expert-aware estimation of ODE parameters since experts can provide
% a better _a priori_ description of state dynamics than ODE parameters.
% # Gradient matching yields a global gradient as opposed to a local one which
% offers significant computational advantages and provides access to a rich
% source of sophisticated optimization tools.
%

%%
% Clear workspace and close figures
clear all; close all;

%% Simulation Settings

simulation.odes = 'fwd_mod_driving';
simulation.state_obs_variance = @(mean)(bsxfun(@times,[0.5^2,0.5^2],...
    ones(size(mean))));                                                    % observation noise
simulation.ode_param = -0.8 + (0.8-(-0.8)) * rand(1,11);                   % true non-selfinhibitory neuronal couplings (sampled uniformily in the interval [-0.8,0.8];
simulation.ode_param(end-4:end) = -1;                                      % self-inhibotory neuronal couplings set to -1.
simulation.final_time = 359*3.22;                                          % end time for integration
simulation.int_interval = 0.01;                                            % integration interval
simulation.time_samp = 0:0.1:simulation.final_time;                        % sample times for observations
simulation.init_val = [5 3];                                               % state values at first time point
simulation.observed_states = {};                                           % indices of states that are directly observed (Boolean)

%% User Input
%
% <html><h4> Candidate mechanism </h4></html>
candidate_odes = 'fwd_mod_driving';
%%
% <html><h4> Signal-to-noise-ratio of BOLD response </h4></html>
bold_response.SNR = 5;   
%%
% <html><h4> Prior variance on non-selfinhibitory neuronal couplings </h4></html>
param_prior_variance = realmax;                                            
%%
% <html><h4> Kernel </h4></html>
%
% Kernel parameters $\phi$:
kernel.param = [2,10];                                                     % set values of rbf kernel parameters
%%
% Error variance on state derivatives (i.e. $\gamma$):
state.derivative_variance = 6.*ones(11-3,1);                               %% $\gamma$ for gradient matching model                                   
%%
% <html><h4> Estimation </h4></html>
time.est= 0:3.22:359*3.22;                                                 % estimation times
coord_ascent_numb_iter = 200;                                              % number of coordinate ascent iterations
clamp_obs_state_to_GP_regression = true;                                   % The observed state trajectories are clamped to the trajectories determined by standard GP regression (Boolean)
%%
% <html><h4> External input </h4></html>
state.ext_input = importdata('dcm/external_input.txt');                    % importing external inputs
time.samp = state.ext_input(:,1)';                                         % unpack sampling time        
%%
% <html><h4> Symbols </h4></html>
symbols = generate_generic_DCM_odes2(candidate_odes,'dcm/candidate_odes.txt'); % symbols of parameters and states and in 'ODEs.txt' file

%% Import ODEs
%
ode = import_odes(symbols);

%%
disp('candidate ODEs:'); disp(ode.raw)

%% Mass Action Dynamical Systems
%
% A deterministic dynamical system is represented by a set of $K$ ordinary differential equations (ODEs) with model parameters $\theta \in R^d$ that describe the evolution of $K$ states $\mathbf{x}(t) = [x_1(t),\ldots, x_K(t)]^T$ such that:
% 
% $\dot{\mathbf{x}}(t) = \frac{d \mathbf{x}(t)}{d t} = \mathbf{f}(\mathbf{x}(t),\theta) \qquad (1)$.
% 
% A sequence of observations, $\mathbf{y}(t)$, is usually contaminated by measurement error which we assume to be normally distributed with zero mean and variance for each of the $K$ states, i.e. $\mathbf{E}\sim \mathcal{N}(\mathbf{E};\mathbf{0},\mathbf{D})$, with $\mathbf{D}_{ik}=\sigma_k ^2 \delta_{ik}$. For $N$ distinct time points the overall system may therefore be summarized as:
% 
% $\mathbf{Y} = \mathbf{X} + \mathbf{E}$,
% 
% where 
%
% $\mathbf{X} = [\mathbf{x}(t_1),\ldots,\mathbf{x}(t_N)] = [\mathbf{x}_1,\ldots,\mathbf{x}_K]^T$,
%
% $\mathbf{Y} = [\mathbf{y}(t_1),\ldots,\mathbf{y}(t_N)] = [\mathbf{y}_1,\ldots,\mathbf{y}_K]^T$,
% 
% and $\mathbf{x}_k = [x_k(t_1),\ldots,x_k(t_N)]^T$ is the $k$'th state sequence and $\mathbf{y}_k = [y_k(t_1),$ $\ldots,y_k(t_N)]^T$ are the observations. Given the observations $\mathbf{Y}$ and the description of the dynamical system (1), the aim is to estimate both state variables $\mathbf{X}$ and parameters $\theta$.
% 
% We consider only dynamical systems that are locally linear with respect to ODE parameters $\boldmath\theta$ and individual states $\mathbf{x}_u$. Such ODEs include mass-action kinetics and are given by: 
%
% $f_{k}(\mathbf{x}(t),\boldmath\theta) = \sum_{i=1} \theta_{ki} \prod_{j \in \mathcal{M}_{ki}} x_j \qquad (2)$,
%
% with $\mathcal{M}_{ki} \subseteq \{ 1, \dots, K\}$ describing the state variables in each factor of the equation (i.e. the functions are linear in parameters and contain arbitrary large products of monomials of the states).

%% Simulate Trajectory Observations
%%
% <html><h4> Write ODEs symbolically </h4></html>
[ode,state_sym,param_sym] = write_ODEs_symbolically(symbols,ode);          % symbolic computations
%%
% <html><h4> Simulate state trajectories by numerical integration </h4></html>
non_diverging_trajectories = false;
while ~non_diverging_trajectories
    
simulation.ode_param = -0.8 + (0.8-(-0.8)) * rand(1,length(symbols.param));% true non-selfinhibitory neuronal couplings (sampled uniformily in the interval [-0.8,0.8];
simulation.ode_param(end-2:end) = -1;                                      % self-inhibitory neuronal couplings set to -1.

state_orig = state;
[state,time,bold_response] = simulate_dynamics_by_numerical_integration(state,state_sym,param_sym,...
            time,ode,simulation.ode_param,bold_response,symbols);
        
if ~any(any(isnan(state.true))) && time.samp(end) > 1000; non_diverging_trajectories = 1; end

end
%%
% <html><h4> Generate state observations </h4></html>
tmp = cellfun(@(x) {strcmp(x(2),simulation.observed_states)},symbols.state);
state.obs_idx = cellfun(@(x) any(x),tmp);
state.obs_idx(cellfun(@(x) strcmp(x(2),'u'),symbols.state)) = [];
state.obs = state.true(:,state.obs_idx) +  sqrt(var(state.true(:,state.obs_idx)) ./ bold_response.SNR) .* randn(size(state.true(:,state.obs_idx)));

% mean correction
bold_response.obs = bsxfun(@minus,bold_response.obs,mean(bold_response.obs,1));
%%
% <html><h4> Symbols </h4></html>
state.sym.mean = sym('x%d%d',[length(time.est),length(ode.system)]);
state.sym.variance = sym('sigma%d%d',[length(time.est),length(ode.system)]);
ode_param.sym.mean = sym('param%d',[length(symbols.param),1]); assume(ode_param.sym.mean,'real');

%%
% <html><h4> Setup plots </h4></html>
%
%[h_states,h_param] = setup_plots(state,time,simulation,symbols);
h = setup_plots(state,time,symbols,bold_response,[1,2],candidate_odes,simulation);

%% Prior on ODE parameters
% Constuct prior on ODE parameters.
ode_param = prior_on_ODE_param(ode_param,param_prior_variance,symbols.param);% prior on ODE parameters

%% Confounding effects
% BOLD response observations are given by the signal change equation plus
% an intercept due to confounding effects:
%%
%
% $$\mathbf{y} = \mathbf{h}(\mathbf{q},\mathbf{v},\mathbf{u}) + \mathbf{X} \beta + \epsilon$$
%
bold_response = confounding_effects(bold_response);
                
tic; %start timer
%% Prior on States and State Derivatives
% Gradient matching with Gaussian processes assumes a joint Gaussian process prior on states and their derivatives:
%
% $\left(\begin{array}{c}
% \mathbf{X} \\ \dot{\mathbf{X}}
% \end{array}\right)
%  \sim \mathcal{N} \left(
% \begin{array}{c}
% \mathbf{X} \\ \dot{\mathbf{X}}
% \end{array}; 
% \begin{array}{c}
%  \mathbf{0} \\ 
% \mathbf{0}
%  \end{array},
% \begin{array}{cc}
%  \mathbf{C}_{\phi} & \mathbf{C}_{\phi}' \\
%  '\mathbf{C}_{\phi} & \mathbf{C}_{\phi}'' 
%  \end{array}
%  \right) \qquad (3)$,
%
% $\mathrm{cov}(x_k(t), x_k(t)) = C_{\phi_k}(t,t')$
%
% $\mathrm{cov}(\dot{x}_k(t), x_k(t)) = \frac{\partial C_{\phi_k}(t,t') }{\partial t} =: C_{\phi_k}'(t,t')$
%
% $\mathrm{cov}(x_k(t), \dot{x}_k(t)) = \frac{\partial C_{\phi_k}(t,t') }{\partial t'} =: {'C_{\phi_k}(t,t')}$
%
% $\mathrm{cov}(\dot{x}_k(t), \dot{x}_k(t)) = \frac{\partial C_{\phi_k}(t,t') }{\partial t \partial t'} =: C_{\phi_k}''(t,t')$.

%% Matching Gradients
%
% Given the joint distribution over states and their derivatives (3) as well as the ODEs (2), we therefore have two expressions for the state derivatives:
%
% $\dot{\mathbf{X}} = \mathbf{F} + \epsilon_1, \epsilon_1 \sim \mathcal{N}\left(\epsilon_1;\mathbf{0}, \mathbf{I}\gamma \right)$
%
% $\dot{\mathbf{X}} = {'\mathbf{C}_{\phi}} \mathbf{C}_{\phi}^{-1} ~\mathbf{X} + \epsilon_2, \epsilon_2 \sim \mathcal{N}\left(\epsilon_2;\mathbf{0}, \mathbf{A} \right)$
%
% where $\mathbf{F} := \mathbf{f}(\mathbf{X},\theta)$, $\mathbf{A} := \mathbf{C}_{\phi}'' -  {'\mathbf{C}_{\phi}} \mathbf{C}_{\phi}^{-1} \mathbf{C}_{\phi}'$ and $\gamma$ is the error variance in the ODEs. Note that, in a deterministic system, the output of the ODEs $\mathbf{F}$ should equal the state derivatives $\dot{\mathbf{X}}$. However, in the first equation above we relax this contraint by adding stochasticity to the state derivatives $\dot{\mathbf{X}}$ in order to compensate for a potential model mismatch. The second equation above is obtained by deriving the conditional distribution for $\dot{\mathbf{X}}$ from the joint distribution in equation (3). Equating the two expressions in the equations above we can eliminate the unknown state derivatives $\dot{\mathbf{X}}$:
%
% $\mathbf{F} = {'\mathbf{C}_{\phi}} \mathbf{C}_{\phi}^{-1} ~\mathbf{X} + \epsilon_0 \qquad (4)$,
%
% with $\epsilon_0 := \epsilon_2 - \epsilon_1$.

[dC_times_invC,inv_C,A_plus_gamma] = kernel_function(kernel,state,time.est);

%% State Couplings in ODEs

coupling_idx = find_couplings_in_odes(ode,symbols);

%% Rewrite ODEs as Linear Combination in Parameters
%
% We rewrite the ODEs in equation (2) as a linear combination in the parameters:
%
% $\mathbf{B}_{\boldmath\theta} \boldmath\theta + \mathbf{b}_{\boldmath\theta} \stackrel{!}{=} \mathbf{f}(\mathbf{X},\boldmath\theta) \qquad (5)$,
%
% where matrices $\mathbf{B}_{\boldmath\theta}$ and $\mathbf{b}_{\boldmath\theta}$ are defined such that the ODEs $\mathbf{f}(\mathbf{X},\boldmath\theta)$ are expressed as a linear combination in $\boldmath\theta$.

[ode_param.lin_comb.B,ode_param.lin_comb.b] = rewrite_odes_as_linear_combination_in_parameters(ode,symbols);

%% Posterior over ODE Parameters
%
% Inserting (5) into (4) and solving for $\boldmath\theta$ yields:
%
% $\boldmath\theta = \mathbf{B}_{\boldmath\theta}^+ \left( {'\mathbf{C}_{\boldmath\phi}} \mathbf{C}_{\boldmath\phi}^{-1} \mathbf{X} - \mathbf{b}_{\boldmath\theta} + \boldmath\epsilon_0 \right)$,
% 
% where $\mathbf{B}_{\boldmath\theta}^+$ denotes the pseudo-inverse of $\mathbf{B}_{\boldmath\theta}$. We can therefore derive the posterior distribution over ODE parameters:
%
% $p(\boldmath\theta \mid \mathbf{X}, \boldmath\phi, \gamma) = \mathcal{N}\left(\boldmath\theta ; \mathbf{B}_{\boldmath\theta}^+ ~ \left( {'\mathbf{C}_{\boldmath\phi}} \mathbf{C}_{\boldmath\phi}^{-1} \mathbf{X} - \mathbf{b}_{\boldmath\theta} \right), ~ \mathbf{B}_{\boldmath\theta}^+ ~ (\mathbf{A} + \mathbf{I}\gamma) ~ \mathbf{B}_{\boldmath\theta}^{+T} \right) \qquad (6)$.
% 
%% Rewrite ODEs as Linear Combination in (monotonic functions of) Individual States
%
% We rewrite the expression $\mathbf{f}(\mathbf{X},\boldmath\theta) - {'\mathbf{C}}_{\boldmath\phi} \mathbf{C}_{\boldmath\phi}^{-1} \mathbf{X}$ in equation (4) as a linear combination in the individual state $\mathbf{x}_u$:
%
% $\mathbf{B}_{u} \mathbf{x}_u + \mathbf{b}_{u} \stackrel{!}{=} \mathbf{f}(\mathbf{X},\boldmath\theta) - {'\mathbf{C}}_{\boldmath\phi} \mathbf{C}_{\boldmath\phi}^{-1} \mathbf{X} \qquad (7)$.
%
% where matrices $\mathbf{B}_u$ and $\mathbf{b}_u$ are defined such that the expression $\mathbf{f}(\mathbf{X},\boldmath\theta) - {'\mathbf{C}}_{\boldmath\phi} \mathbf{C}_{\boldmath\phi}^{-1} \mathbf{X}$ is rewritten as a linear combination in the individual state $\mathbf{x}_u$.

state_enumeration = {'q','v','f','s','x'};
for u = 1:length(state_enumeration)
    if strcmp(state_enumeration{u},'q')
       [state.deoxyhemo.B,state.deoxyhemo.b] = rewrite_bold_signal_eqn_as_linear_combination_in_deoxyhemo(symbols);
    elseif strcmp(state_enumeration{u},'v')
        [state.vol.B,state.vol.b] = rewrite_deoxyhemo_ODE_as_linear_combination_in_vol(ode,symbols);
    elseif strcmp(state_enumeration{u},'f')
        [state.flow.B,state.flow.b] = rewrite_vol_ODE_as_linear_combination_in_flow(ode,symbols);
    elseif strcmp(state_enumeration{u},'s')
        [state.vaso.B,state.vaso.b] = rewrite_vaso_and_flow_odes_as_linear_combination_in_vaso(ode,symbols);
    elseif strcmp(state_enumeration{u},'x')
        [state.neuronal.B,state.neuronal.b] = rewrite_odes_as_linear_combination_in_ind_neuronal_states(ode,symbols,coupling_idx.states);
    end
end

%% Posterior over Individual States
%
% Inserting (7) into (4) and solving for $\mathbf{x}_u$ yields:
%
% $\mathbf{x}_u = \mathbf{B}_{u}^+ \left( \boldmath\epsilon_0 -\mathbf{b}_{u} \right)$,
%
% where $\mathbf{B}_{u}^+$ denotes the pseudo-inverse of $\mathbf{B}_{u}$. We can therefore derive the posterior distribution over an individual state $\mathbf{x}_u$:
%
% $p(\mathbf{x}_u \mid \mathbf{X}_{-u}, \boldmath\phi, \gamma) = \mathcal{N}\left(\mathbf{x}_u ; -\mathbf{B}_{u}^+ \mathbf{b}_u, ~\mathbf{B}_u^{+} ~ (\mathbf{A} + \mathbf{I}\gamma) ~ \mathbf{B}_u^{+T} \right) \qquad (8)$,
%
% with $\mathbf{X}_{-u}$ denoting the set of all states except state $\mathbf{x}_u$.

%% Mean-field Variational Inference
%
% To infer the parameters $\boldmath\theta$, we want to find the maximum a posteriori estimate (MAP): 
%
% $\theta^* := arg \max_{\theta} ~ \ln p(\theta \mid \mathbf{Y},\phi,\gamma, \sigma)$
%
% $= arg\max_{\boldmath\theta} ~ \ln \int  p(\boldmath\theta,\mathbf{X} \mid \mathbf{Y},\boldmath\phi,\boldmath\gamma,\boldmath\sigma) d\mathbf{X}$
%
% $= arg\max_{\boldmath\theta} ~ \ln \int p(\boldmath\theta \mid \mathbf{X},\boldmath\phi,\boldmath\gamma) p(\mathbf{X} \mid \mathbf{Y}, \boldmath\phi,\boldmath\sigma) d\mathbf{X} \qquad (9)$.
% 
% However, the integral above is intractable due to the strong couplings induced by the nonlinear ODEs $\mathbf{f}$ which appear in the term $p(\boldmath\theta \mid \mathbf{X},\boldmath\phi,\boldmath\gamma)$. 
% 
% We use mean-field variational inference to establish variational lower bounds that are analytically tractable by decoupling state variables from the ODE parameters as well as decoupling the state variables from each other. Note that, since the ODEs described by equation (2) are *locally linear*, both conditional distributions $p(\boldmath\theta \mid \mathbf{X},\mathbf{Y},\boldmath\phi,\boldmath\gamma,\boldmath\sigma)$ (equation (6)) and $p(\mathbf{x}_u \mid \boldmath\theta, \mathbf{X}_{-u},\mathbf{Y},\boldmath\phi,\boldmath\gamma,\boldmath\sigma)$ (equation (8)) are analytically tractable and Gaussian distributed as mentioned previously. 
% 
% The decoupling is induced by designing a variational distribution $Q(\boldmath\theta,\mathbf{X})$ which is restricted to the family of factorial distributions:
%
% $\mathcal{Q} := \bigg{\{} Q : Q(\boldmath\theta,\mathbf{X}) = q(\boldmath\theta) \prod_u q(\mathbf{x}_u) \bigg{\}}$.
% 
% The particular form of $q(\boldmath\theta)$ and $q(\mathbf{x}_u)$ are designed to be Gaussian distributed which places them in the same family as the true full conditional distributions. To find the optimal factorial distribution we minimize the Kullback-Leibler divergence between the variational and the true posterior distribution:
%
% $\hat{Q} := arg \min_{Q(\boldmath\theta,\mathbf{X}) \in \mathcal{Q}} \mathrm{KL} \left[ Q(\theta,\mathbf{X}) \mid \mid p(\boldmath\theta,\mathbf{X} \mid \mathbf{Y},\boldmath\phi, \boldmath\gamma,\boldmath\sigma) \right] \qquad (10)$,
%
% where $\hat{Q}$ is the proxy distribution. The proxy distribution that minimizes the KL-divergence (10) depends on the true full conditionals and is given by:
%
% $\hat{q}({\boldmath\theta}) \propto \exp \left(~ E_{Q_{-\theta}} \ln p(\boldmath\theta \mid \mathbf{X},\mathbf{Y},\boldmath\phi,\boldmath\gamma,\boldmath\sigma) ~\right) \qquad (11)$
% 
% $\hat{q}(\mathbf{x}_u) \propto \exp\left( ~ E_{Q_{-u}} \ln p(\mathbf{x}_u \mid \theta, \mathbf{X}_{-u},\mathbf{Y},\phi,\gamma,\sigma) ~ \right) \qquad (12)$.

%% GP Regression for Observations
%
% The data-informed distribution $p(\mathbf{X} \mid \mathbf{Y}, \boldmath\phi,\boldmath\sigma)$ in euqation (9) can be determined analytically using Gaussian process regression with the GP prior $p(\mathbf{X} \mid \boldmath\phi) = \prod_k \mathcal{N}(\mathbf{x}_k ; \mathbf{0},\mathbf{C}_{\boldmath\phi})$:
%
% $p(\mathbf{X} \mid \mathbf{Y}, \boldmath\phi,\gamma) = \prod_k \mathcal{N}(\mathbf{x}_k ; \boldmath\mu_k(\mathbf{y}_k),\boldmath\Sigma_k)$,
%
% where $\boldmath\mu_k(\mathbf{y}_k) := \sigma_k^{-2} \left(\sigma_k^{-2} \mathbf{I} + \mathbf{C}_{\boldmath\phi_k}^{-1} \right)^{-1} \mathbf{y}_k$ and $\boldmath\Sigma_k ^{-1}:=\sigma_k^{-2} \mathbf{I} + \mathbf{C}_{\boldmath\phi_k}^{-1}$.

[bold_response.denoised_obs,inv_sigma] = GP_regression(bold_response,inv_C,symbols);

%% Coordinate Ascent Variational Gradient Matching
% 
% We minimize the KL-divergence in equation (10) by coordinate descent (where each step is analytically tractable) by iterating between determining the proxy for the distribution over ODE parameters $\hat{q}(\boldmath\theta)$ and the proxies for the distribution over individual states $\hat{q}(\mathbf{x}_u)$. 

bold_response.obs_old = bold_response.denoised_obs;

state_enumeration = {'q','v','f','s','x'};
state_enumeration(find(ismember(state_enumeration,simulation.observed_states))) = [];

ode_param.proxy.mean = zeros(length(symbols.param),1);
state.proxy.mean = zeros(length(time.est),length(symbols.state));
% external_input
ext_input_idx = cellfun(@(x) strcmp(x(2),'u'),symbols.state);
state.proxy.mean(:,ext_input_idx) = state.ext_input(state.ext_input_to_bold_response_mapping_idx,2:end);

for i=1:coord_ascent_numb_iter
    
    % Learn intercept due to confounding effects
    % The intercept is determined by a minimum least squares estimator:
    %
    % $$\mathbf{X} \hat{\beta} := \mathbf{X} ( \mathbf{X}^T \mathbf{X} )^{-1} \mathbf{X}^T (\mathbf{y} - \mathbf{h}(\mathbf{q},\mathbf{v},\mathbf{u}))$$
    %
    
    vol_idx = cellfun(@(x) strcmp(x(2),'v'),symbols.state);
    deoxyhemo_idx = cellfun(@(x) strcmp(x(2),'q'),symbols.state);
    
    bold_response_signal_change = bold_signal_change_eqn(state.proxy.mean(:,vol_idx),state.proxy.mean(:,deoxyhemo_idx));
    bold_response.confounding_effects.intercept = determine_intercept(bold_response.obs_old-bold_response_signal_change,...
        bold_response.confounding_effects.X0,bold_response.confounding_effects.X0_penrose_inv);
    
    bold_response.confounding_effects.intercept = zeros(size(bold_response.obs,1),size(bold_response.obs,2));
    bold_response.denoised_obs = bold_response.obs_old - bold_response.confounding_effects.intercept;
    
    % Proxy for states
    % Maximize the evidence lower bound (ELBO) one state at a time
    % (coordinate-ascent-wise) starting with deoxyhemoglobin followed by
    % blood volume, blood flow, vasosignalling and finally the neuronal
    % states.
    
    damping = 0.1;
    for j = 1:length(state_enumeration)
        if strcmp(state_enumeration{j},'q')
            % deoxyhemoglobin
            state_idx = cellfun(@(x) strcmp(x(2),'q'),symbols.state);
            state_tmp = maximize_lower_bound_wrt_deoxyhemo(state.deoxyhemo,state.proxy.mean,bold_response.denoised_obs,symbols);
            state.proxy.mean(:,state_idx) = (1-damping) * state.proxy.mean(:,state_idx) + damping * state_tmp;
        elseif strcmp(state_enumeration{j},'v')
            % blood volume
            state_idx = cellfun(@(x) strcmp(x(2),'v'),symbols.state);
            state_tmp = maximize_lower_bound_wrt_vol(state.vol,dC_times_invC,state.proxy.mean,ode_param.proxy.mean,symbols);
            state.proxy.mean(:,state_idx) = (1-damping) * state.proxy.mean(:,state_idx) + damping * state_tmp;
        elseif strcmp(state_enumeration{j},'f')
            % blood flow
            state_idx = cellfun(@(x) strcmp(x(2),'f'),symbols.state);
            state_tmp = maximize_lower_bound_wrt_flow(state.flow,dC_times_invC,state.proxy.mean,ode_param.proxy.mean,symbols);
            state.proxy.mean(:,state_idx) = (1-damping) * state.proxy.mean(:,state_idx) + damping * state_tmp;
        elseif strcmp(state_enumeration{j},'s')
            % vasosignalling
            state_idx = cellfun(@(x) strcmp(x(2),'s'),symbols.state);
            state.proxy.mean(:,state_idx) = maximize_lower_bound_wrt_vaso(state.vaso,dC_times_invC,state.proxy.mean,ode_param.proxy.mean,symbols);
        elseif strcmp(state_enumeration{j},'x')
            % neuronal populations
            state_idx = cellfun(@(x) strcmp(x(2),'x'),symbols.state);
            state.proxy.mean(:,state_idx) = maximize_lower_bound_wrt_neuronal_states(state.neuronal,state.proxy.mean,ode_param.proxy.mean',...
                dC_times_invC,coupling_idx.states,symbols);
        end
        %state.proxy.mean(:,13:15) = bsxfun(@minus,state.proxy.mean(:,13:15),state.proxy.mean(1,13:15));
        state.proxy.mean(:,1:15) = bsxfun(@minus,state.proxy.mean(:,1:15),state.proxy.mean(1,1:15));
    end

    % Plot states
    if ~mod(i,7)
        state_plot = state.proxy.mean; state_plot(:,1:9) = exp(state_plot(:,1:9));
        for u = [3,6,9,12,15]%13:15;
            idx = 360; tmp = h.dynamics{u}.YLim;
            hold on; plot(h.dynamics{u},time.est(1:idx),state_plot(1:idx,u),'LineWidth',0.7,'Color',[0.6,0.6,0.6]); h.dynamics{u}.YLim = tmp;
        end
        drawnow
    end
    
    % Proxy for ODE parameters
    % Given the states, we estimate the proxy to the ODE parameters.
    
    if i>200 || i==coord_ascent_numb_iter
        [ode_param.proxy.mean,ode_param.proxy.inv_cov] = proxy_for_ode_parameters(state.proxy.mean,dC_times_invC,ode_param.lin_comb,symbols,ode_param,A_plus_gamma);
    end
    
end

%% Numerical integration with parameters estimated by variational gradient matching
% See whether we actually fit the BOLD response well. Curves are shown in black.

[state,bold_response] = simulate_trajectory_with_vgm_param_est(state,state_orig,ode_param,bold_response,...
    time,ode,state_sym,param_sym,symbols);
                
%%
% <html><h4> Final result </h4></html>
plot_results(state,ode_param,bold_response,time,h,[1,2],simulation.odes,candidate_odes,simulation);

%% Time Taken

disp(['time taken: ' num2str(toc) ' seconds'])

%% References
%
% * *Gorbach, N.S.* , *Bauer, S.* and Buhmann, J.M., Scalable Variational Inference for Dynamical Systems. 2017a. Neural Information Processing Systems (NIPS). <https://papers.nips.cc/paper/7066-scalable-variational-inference-for-dynamical-systems.pdf>, arxiv: <https://arxiv.org/abs/1705.07079>.
% * *Bauer, S.* , *Gorbach, N.S.* and Buhmann, J.M., Efficient and Flexible Inference for Stochastic Differential Equations. 2017b. Neural Information Processing Systems (NIPS). <https://papers.nips.cc/paper/7274-efficient-and-flexible-inference-for-stochastic-systems.pdf>
% * Wenk, P., Gotovos, A., Bauer, S., Gorbach, N.S., Krause, A. and Buhmann, J.M., Fast Gaussian Process Based Gradient Matching for Parameters Identification in Systems of Nonlinear ODEs. 2018. In submission to Conference on Uncertainty in Artificial Intelligence (UAI).
% * Calderhead, B., Girolami, M. and Lawrence. N.D., 2002. Accelerating Bayesian inference over nonlinear differential equation models. _In Advances in Neural Information Processing Systems (NIPS)_ . 22.
%
% The authors in bold font have contributed equally to their respective
% papers.

%% Subroutines
% <html><h4> Kernel function </h4></html>
%
% Gradient matching with Gaussian processes assumes a joint Gaussian process prior on states and their derivatives:
%
% $\left(\begin{array}{c}
% \mathbf{X} \\ \dot{\mathbf{X}}
% \end{array}\right)
%  \sim \mathcal{N} \left(
% \begin{array}{c}
% \mathbf{X} \\ \dot{\mathbf{X}}
% \end{array}; 
% \begin{array}{c}
%  \mathbf{0} \\ 
% \mathbf{0}
%  \end{array},
% \begin{array}{cc}
%  \mathbf{C}_{\phi} & \mathbf{C}_{\phi}' \\
%  '\mathbf{C}_{\phi} & \mathbf{C}_{\phi}'' 
%  \end{array}
%  \right)$,
%
% $\mathrm{cov}(x_k(t), x_k(t)) = C_{\phi_k}(t,t')$
%
% $\mathrm{cov}(\dot{x}_k(t), x_k(t)) = \frac{\partial C_{\phi_k}(t,t') }{\partial t} =: C_{\phi_k}'(t,t')$
%
% $\mathrm{cov}(x_k(t), \dot{x}_k(t)) = \frac{\partial C_{\phi_k}(t,t') }{\partial t'} =: {'C_{\phi_k}(t,t')}$
%
% $\mathrm{cov}(\dot{x}_k(t), \dot{x}_k(t)) = \frac{\partial C_{\phi_k}(t,t') }{\partial t \partial t'} =: C_{\phi_k}''(t,t')$.

function [dC_times_invC,inv_C,A_plus_gamma] = kernel_function(kernel,state,time_est)

kernel.param_sym = sym(['rbf_param%d'],[1,2]); assume(kernel.param_sym,'real');
kernel.time1 = sym('time1'); assume(kernel.time1,'real'); kernel.time2 = sym('time2'); assume(kernel.time2,'real');
kernel.func = kernel.param_sym(1).*exp(-(kernel.time1-kernel.time2).^2./(kernel.param_sym(2).^2));                      % RBF kernel
kernel.name = 'rbf';   

% kernel derivatives
for i = 1:length(kernel)
    kernel.func_d = diff(kernel.func,kernel.time1);
    kernel.func_dd = diff(kernel.func_d,kernel.time2);
    GP.fun = matlabFunction(kernel.func,'Vars',{kernel.time1,kernel.time2,kernel.param_sym});
    GP.fun_d = matlabFunction(kernel.func_d,'Vars',{kernel.time1,kernel.time2,kernel.param_sym});
    GP.fun_dd = matlabFunction(kernel.func_dd,'Vars',{kernel.time1,kernel.time2,kernel.param_sym});
end

% populate GP covariance matrix
for t=1:length(time_est)
    C(t,:)=GP.fun(time_est(t),time_est,kernel.param);
    dC(t,:)=GP.fun_d(time_est(t),time_est,kernel.param);
    Cd(t,:)=GP.fun_d(time_est,time_est(t),kernel.param);
    ddC(t,:)=GP.fun_dd(time_est(t),time_est,kernel.param);
end

% GP covariance scaling
[~,D] = eig(C); perturb = abs(max(diag(D))-min(diag(D))) / 10000;
if any(diag(D)<1e-6); C(logical(eye(size(C,1)))) = C(logical(eye(size(C,1)))) + perturb.*rand(size(C,1),1); end
[~,D] = eig(C);
if any(diag(D)<0); error('C has negative eigenvalues!'); elseif any(diag(D)<1e-6); warning('C is badly scaled'); end
inv_C = inv_chol(chol(C,'lower'));

dC_times_invC = dC * inv_C;

% plot GP prior samples
figure(3); 
hold on; plot(time_est,mvnrnd(zeros(1,length(time_est)),C(:,:,1),3),'LineWidth',2);
h1 = gca; h1.FontSize = 20; h1.XLabel.String = 'time'; h1.YLabel.String = 'state value';
h1.Title.String = [kernel.name ' kernel'];

% determine A_plus_gamma:
A = ddC - dC_times_invC * Cd;
inv_Lambda = A + state.derivative_variance(1) .* eye(size(A));
inv_Lambda = 0.5.*(inv_Lambda+inv_Lambda');
A_plus_gamma = inv_chol(chol(inv_Lambda,'lower'));

end

%%
% <html><h4> GP regression for observations</h4></html>
%
% $p(\mathbf{X} \mid \mathbf{Y}, \boldmath\phi,\gamma) = \prod_k \mathcal{N}(\mathbf{x}_k ; \boldmath\mu_k(\mathbf{y}_k),\boldmath\Sigma_k)$,
%
% where $\boldmath\mu_k(\mathbf{y}_k) := \sigma_k^{-2} \left(\sigma_k^{-2} \mathbf{I} + \mathbf{C}_{\boldmath\phi_k}^{-1} \right)^{-1} \mathbf{y}_k$ and $\boldmath\Sigma_k ^{-1}:=\sigma_k^{-2} \mathbf{I} + \mathbf{C}_{\boldmath\phi_k}^{-1}$.

function [mu,inv_sigma] = GP_regression(bold_response,inv_Cxx,symbols)

inv_Cxx_cell = num2cell(inv_Cxx(:,:,ones(1,sum(cellfun(@(x) strcmp(x(2),'x'),symbols.state)))),[1,2]);
inv_Cxx_blkdiag = blkdiag(inv_Cxx_cell{:});

b = repmat(var(bold_response.obs)./bold_response.SNR,size(bold_response.obs,1),1);
dim = size(inv_Cxx_blkdiag,1);
D = spdiags(reshape(b.^(-1),[],1),0,dim,dim) * speye(dim); % covariance matrix of error term (big E)
inv_sigma = D + inv_Cxx_blkdiag;

mu = inv_sigma \ D * reshape(bold_response.obs,[],1);
mu = reshape(mu,[],size(bold_response.obs,2));

end

%%
% <html><h4> Find ODE couplings </h4></html>
function coupling_idx = find_couplings_in_odes(ode,symbols)

state_idx = cellfun(@(x) ~strcmp(x(2),'u'),symbols.state);
learn_method.state(state_idx) = {'Laplace mean-field'};
learn_method.state(~state_idx) = {'external input'};

%state couplings 
state_sym = sym(['state%d'],[1,length(ode.system)]); assume(state_sym,'real');
for k = 1:length(ode.system)
    tmp_idx = ismember(state_sym,symvar(ode.system_sym(k))); tmp_idx(:,k) = 1;
    ode_couplings_states(k,tmp_idx) = 1; 
end
for u = find(strcmp(learn_method.state,'Laplace mean-field'))
    coupling_idx_tmp = find(ode_couplings_states(:,u));
    coupling_idx.states{u} = coupling_idx_tmp;    
end

% param couplings 
param_sym = sym(['param%d'],[1,length(symbols.param)]); assume(param_sym,'real');
for k = 1:length(ode.system)
    tmp_idx = ismember(param_sym,symvar(ode.system_sym(k))); 
    ode_couplings_param(k,tmp_idx) = 1; 
end
for i = 1:length(symbols.param)
    coupling_idx_tmp = find(ode_couplings_param(:,i));
    coupling_idx.param{i} = coupling_idx_tmp;    
end


end

%%
% <html><h4> Rewrite ODEs as linear combination in parameters </h4></html>
%
% $\mathbf{B}_{\boldmath\theta} \boldmath\theta + \mathbf{b}_{\boldmath\theta} \stackrel{!}{=} \mathbf{f}(\mathbf{X},\boldmath\theta)$,
%
% where matrices $\mathbf{B}_{\boldmath\theta}$ and $\mathbf{b}_{\boldmath\theta}$ are defined such that the ODEs $\mathbf{f}(\mathbf{X},\boldmath\theta)$ are expressed as a linear combination in $\boldmath\theta$.

function [B,b] = rewrite_odes_as_linear_combination_in_parameters(ode,symbols)

param_sym = sym(['param%d'],[1,length(symbols.param)]); assume(param_sym,'real');
state_sym = sym(['state%d'],[1,length(symbols.state)]); assume(state_sym,'real');
state0_sym = sym(['state0']); assume(state0_sym,'real');
state_const_sym = sym(['state_const']); assume(state_const_sym,'real');

% Rewrite ODEs as linear combinations in parameters
[B_sym,b_sym] = equationsToMatrix(ode.system_sym,param_sym);
b_sym = -b_sym; % See the documentation of the function "equationsToMatrix"

% Product of ODE factors (product of Gaussians)
for k = 1:length(ode.system)
    B_sym(k,B_sym(k,:)=='0') = state0_sym;
    for i = 1:length(B_sym(k,:))
        sym_var = symvar(B_sym(k,i));
        if isempty(sym_var)
            B_sym(k,i) = B_sym(k,i) + state0_sym;
        end
    end
    B{k} = matlabFunction(B_sym(k,:),'Vars',{state_sym,state0_sym,state_const_sym});
    b{k} = matlabFunction(b_sym(k,:),'Vars',{state_sym,state0_sym,state_const_sym});
end

end

%%
% <html><h4> Rewrite ODEs as linear combination in individual states </h4></html>
%
% $\mathbf{B}_{u} \mathbf{x}_u + \mathbf{b}_{u} \stackrel{!}{=} \mathbf{f}(\mathbf{X},\boldmath\theta) - {'\mathbf{C}}_{\boldmath\phi} \mathbf{C}_{\boldmath\phi}^{-1} \mathbf{X}$.
%
% where matrices $\mathbf{B}_u$ and $\mathbf{b}_u$ are defined such that the expression $\mathbf{f}(\mathbf{X},\boldmath\theta) - {'\mathbf{C}}_{\boldmath\phi} \mathbf{C}_{\boldmath\phi}^{-1} \mathbf{X}$ is rewritten as a linear combination in the individual state $\mathbf{x}_u$.

function [deoxyhemo,vol,flow,vaso,neuronal] = rewrite_odes_as_linear_combination_in_ind_states(ode,symbols,coupling_idx)

q_bool = 1; v_bool = 1; f_bool = 1; s_bool = 1;
state.neuronal = [];
for u = 1:length(symbols.state)
    if strcmp(symbols.state{u}(2),'q') && q_bool
       [deoxyhemo.B,deoxyhemo.b] = rewrite_bold_signal_eqn_as_linear_combination_in_deoxyhemo(symbols);
       q_bool = 0;
    elseif strcmp(symbols.state{u}(2),'v') && v_bool
        [vol.B,vol.b] = rewrite_deoxyhemo_ODE_as_linear_combination_in_vol(ode,symbols);
        v_bool = 0;
    elseif strcmp(symbols.state{u}(2),'f') && f_bool
        [flow.B,flow.b] = rewrite_vol_ODE_as_linear_combination_in_flow(ode,symbols);
        f_bool = 0;
    elseif strcmp(symbols.state{u}(2),'s') && s_bool
        [vaso.B,vaso.b] = rewrite_vaso_and_flow_odes_as_linear_combination_in_vaso(ode,symbols);
        s_bool = 0;
    elseif ~strcmp(symbols.state{u}(2),'q') && ~strcmp(symbols.state{u}(2),'v') && ~strcmp(symbols.state{u}(2),'f') && ~strcmp(symbols.state{u}(2),'s')  && ~strcmp(symbols.state{u}(2),'u')
        [neuronal.B,neuronal.b] = rewrite_odes_as_linear_combination_in_ind_neuronal_states(ode,symbols,coupling_idx.states{u}',u);
    end
end

end

%%
% <html><h4> Rewrite ODEs as linear combination in monotonic function of deoxyhemoglobin content $e^q$ </h4></html>
function [B,b] = rewrite_bold_signal_eqn_as_linear_combination_in_deoxyhemo(symbols)

% define symbolic variables

param_sym = sym(['param%d'],[1,length(symbols.param)]); assume(param_sym,'real');
state_sym = sym(['state%d'],[1,length(symbols.state)]); assume(state_sym,'real');
v = sym('v'); assume(v,'real');
q = sym('q'); assume(q,'real');
exp_q = sym('exp_q'); assume(exp_q,'real');

% bold signal change equation

bold_signal_change = bold_signal_change_eqn(v,q);
[B,b] = equationsToMatrix(subs(bold_signal_change,exp(q),exp_q),exp_q);

B = matlabFunction(B,'Vars',{v,q});
b = matlabFunction(b,'Vars',{v,q});

end

%%
% <html><h4> Rewrite ODEs as linear combination in monotonic function of blood volume $e^v$ </h4></html>
function [B,b] = rewrite_deoxyhemo_ODE_as_linear_combination_in_vol(ode,symbols)

% define symbolic variables
param_sym = sym(['param%d'],[1,length(symbols.param)]); assume(param_sym,'real');
state_sym = sym(['state%d'],[1,length(symbols.state)]); assume(state_sym,'real');
exp_v = sym('exp_v'); assume(exp_v,'real');

state_idx = find(cellfun(@(x) strcmp(x(2),'v'),symbols.state));

% deoxyhemo differential equation
ode_idx = find(cellfun(@(x) strcmp(x(2),'q'),symbols.state));
j = 0;
for u = state_idx
    j = j+1;
    [B_sym,b_sym] = equationsToMatrix(subs(ode.system{ode_idx(j)}(state_sym,param_sym),exp((17*state_sym(u)/8)),exp_v),exp_v);
    B{u} = matlabFunction(B_sym,'Vars',{state_sym,param_sym});
    b{u} = matlabFunction(b_sym,'Vars',{state_sym,param_sym});
end

end
%%
% <html><h4> Rewrite ODEs as linear combination in monotonic function of blood flow $e^f$ </h4></html>
function [B,b] = rewrite_vol_ODE_as_linear_combination_in_flow(ode,symbols)

% define symbolic variables

param_sym = sym(['param%d'],[1,length(symbols.param)]); assume(param_sym,'real');
state_sym = sym(['state%d'],[1,length(symbols.state)]); assume(state_sym,'real');
exp_f = sym('exp_f'); assume(exp_f,'real');

state_idx = find(cellfun(@(x) strcmp(x(2),'f'),symbols.state));

% blood vol ODE
ode_idx = find(cellfun(@(x) strcmp(x(2),'v'),symbols.state));

j = 0;
for u = state_idx
    j = j+1;
    [B_sym,b_sym] = equationsToMatrix(subs(ode.system{ode_idx(j)}(state_sym,param_sym),exp(state_sym(u)),exp_f),exp_f);
    B{u} = matlabFunction(B_sym,'Vars',{state_sym,param_sym});
    b{u} = matlabFunction(b_sym,'Vars',{state_sym,param_sym});
end

end
%%
% <html><h4> Rewrite ODEs as linear combination in vasosignalling $s$ </h4></html>
function [B,b] = rewrite_vaso_and_flow_odes_as_linear_combination_in_vaso(ode,symbols)

% define symbolic variables
param_sym = sym(['param%d'],[1,length(symbols.param)]); assume(param_sym,'real');
state_sym = sym(['state%d'],[1,length(symbols.state)]); assume(state_sym,'real');

state_idx = find(cellfun(@(x) strcmp(x(2),'s'),symbols.state));

% vasosignaling ODE
ode_idx = find(cellfun(@(x) strcmp(x(2),'s'),symbols.state));
j = 0;
for u = state_idx
    j = j+1;
    [B_sym,b_sym] = equationsToMatrix(ode.system{ode_idx(j)}(state_sym,param_sym),state_sym(u));
    B{u}.vaso = matlabFunction(B_sym,'Vars',{state_sym,param_sym});
    b{u}.vaso = matlabFunction(b_sym,'Vars',{state_sym,param_sym});
end

% blood flow ODE
ode_idx = find(cellfun(@(x) strcmp(x(2),'f'),symbols.state));
j = 0;
for u = state_idx
    j = j+1;
    [B_sym,b_sym] = equationsToMatrix(ode.system{ode_idx(j)}(state_sym,param_sym),state_sym(u));
    B{u}.flow = matlabFunction(B_sym,'Vars',{state_sym,param_sym});
    b{u}.flow = matlabFunction(b_sym,'Vars',{state_sym,param_sym});
end

end
%%
% <html><h4> Rewrite ODEs as linear combination in neuronal states $n$ </h4></html>
function [B,b]= rewrite_odes_as_linear_combination_in_ind_neuronal_states(ode,symbols,coupling_idx)

state_sym = sym('state%d',[1,length(symbols.state)]); assume(state_sym,'real');
param_sym = sym('param%d',[1,length(symbols.param)]); assume(param_sym,'real');

state_idx = find(cellfun(@(x) strcmp(x(2),'x'),symbols.state));

for u = state_idx
    for k = coupling_idx{u}'
        [B_sym,b_sym] = equationsToMatrix(ode.system{k}(state_sym,param_sym'),state_sym(:,u));
        B{u,k} = matlabFunction(B_sym,'Vars',{state_sym,param_sym});
        b{u,k} = matlabFunction(b_sym,'Vars',{state_sym,param_sym});
    end
end

end

%%
% <html><h4> Proxy for ODE parameters </h4></html>
%
% $\hat{q}(\theta) {\propto} \exp \left( ~E_{Q_{-\theta}}  \ln \mathcal{N} \left( \theta; \mathbf{B}_{\theta}^+ ~ \left( '\mathbf{C}_{\phi} \mathbf{C}_{\phi}^{-1} \mathbf{X} - \mathbf{b}_{\theta} \right), ~ \mathbf{B}_{\theta}^+ ~ (\mathbf{A} + \mathbf{I}\gamma) ~ \mathbf{B}_{\theta}^{+T} \right) ~\right)$,

function [param_proxy_mean,param_proxy_inv_cov] = proxy_for_ode_parameters(state_proxy_mean,dC_times_invC,lin_comb,symbols,ode_param,A_plus_gamma)

state0 = zeros(size(dC_times_invC,1),1);
param_proxy_inv_cov = zeros(length(symbols.param));
local_mean_sum = zeros(length(symbols.param),1);
for k = 1: 1:sum(cellfun(@(x) ~strcmp(x(2),'u'),symbols.state))
    B = lin_comb.B{k}(state_proxy_mean,state0,ones(size(state_proxy_mean,1),1));
    b = lin_comb.b{k}(state_proxy_mean,state0,ones(size(state_proxy_mean,1),1));
    
    local_mean = B' * (dC_times_invC * state_proxy_mean(:,k) - b);
    local_mean_sum = local_mean_sum + local_mean;
    
    local_inv_cov = B' * B;                 % This works better than "B' * A_plus_gamma * B".
    %local_inv_cov = B' * A_plus_gamma * B;
    param_proxy_inv_cov = param_proxy_inv_cov + local_inv_cov;
end

if isfield(ode_param,'prior')
    local_mean_sum = local_mean_sum + ode_param.prior.inv_cov*ode_param.prior.mean;
    param_proxy_inv_cov = param_proxy_inv_cov + ode_param.prior.inv_cov;
end

% Check consistency of covariance matrix
[~,D] = eig(param_proxy_inv_cov);
if any(diag(D)<0)
    warning('ode_param.proxy.inv_cov has negative eigenvalues!');
elseif any(diag(D)<1e-3)
    warning('ode_param.proxy.inv_cov is badly scaled')
    disp('perturbing diagonal of ode_param.proxy.inv_cov')
    perturb = abs(max(diag(D))-min(diag(D))) / 10000;
    param.proxy.inv_cov(logical(eye(size(param_proxy_inv_cov,1)))) = param_proxy_inv_cov(logical(eye(size(param_proxy_inv_cov,1)))) ...
        + perturb.*rand(size(param_proxy_inv_cov,1),1);
end

param_proxy_mean = pinv(param_proxy_inv_cov) * local_mean_sum;

end

%%
% <html><h4> Proxy for individual states </h4></html>
%
% $\hat{q}(\mathbf{x}_u) \propto \exp\big( ~ E_{Q_{-u}} \ln \mathcal{N}\left(\mathbf{x}_u ; -\mathbf{B}_{u}^+ \mathbf{b}_u, ~\mathbf{B}_u^{+} ~ (\mathbf{A} + \mathbf{I}\gamma) ~ \mathbf{B}_u^{+T} \right) + E_{Q_{-u}} \ln \mathcal{N}\left(\mathbf{x}_u ; \boldmath\mu_u(\mathbf{Y}), \Sigma_u \right) \big)$,

function [state_mean,state_inv_cov] = proxy_for_ind_states(lin_comb,state_mean,...
    ode_param,dC_times_invC,coupling_idx,symbols,mu,inv_sigma,state_obs_idx,...
    clamp_obs_state_to_GP_regression)

if clamp_obs_state_to_GP_regression
    state_enumeration = find(~state_obs_idx);
else
    state_enumeration = 1:length(symbols.state);
end

for u = state_enumeration
    
    state_inv_cov(:,:,u) = zeros(size(dC_times_invC));
    local_mean_sum = zeros(size(dC_times_invC,1),1);
    for k = coupling_idx{u}'
        if k~=u
            B_ode = diag(lin_comb.B_ode{u,k}(state_mean,ode_param));
            if size(B_ode,1) == 1; B_ode = B_ode.*eye(size(dC_times_invC,1)); end

            state_inv_cov(:,:,u) = state_inv_cov(:,:,u) + B_ode' * B_ode;
            local_mean_sum = local_mean_sum + B_ode' * (dC_times_invC * state_mean(:,k) ...
                - lin_comb.b_ode{u,k}(state_mean,ode_param));
        else
            B_ode = diag(lin_comb.B_ode{u,k}(state_mean,ode_param));
            if size(B_ode,1) == 1; B_ode = B_ode.*eye(size(dC_times_invC,1)); end
            B_ode = B_ode - dC_times_invC;

            state_inv_cov(:,:,u) = state_inv_cov(:,:,u) + B_ode' * B_ode;
            
            l = lin_comb.b_ode{u,k}(state_mean,ode_param); if length(l)==1; l = zeros(length(local_mean_sum),1); end
            local_mean_sum = local_mean_sum - B_ode' * l;
        end
    end
    
    state_mean(:,u) = (state_inv_cov(:,:,u) + inv_sigma(:,:,u)) \ (local_mean_sum + (inv_sigma(:,:,u) * mu(:,u)));
end

end

%%
% <html><h4> Prior on neuronal couplings </h4></html>
function ode_param = prior_on_ODE_param(ode_param,param_prior,param_symbols)

numb_states = 3;
ode_param.prior.mean = zeros(length(param_symbols),1);
ode_param.prior.mean(end-numb_states+1:end) = -1;                          
tmp = param_prior*ones(1,length(param_symbols));
tmp(end-numb_states+1:end) = 1e-3;
ode_param.prior.inv_cov = diag(tmp.^(-1)); 

end

%%
% <html><h4> Confounding effects </h4></html>
function bold_response = confounding_effects(bold_response)

bold_response.confounding_effects.X0 = importdata('dcm/confounding_effects_X0.txt');
bold_response.confounding_effects.beta = importdata('dcm/confounding_effects_beta.txt');

%bold_response.confounding_effects.X0 = importdata('aphasia/confounding_effects_X0.txt');

%bold_response.confounding_effects.X0 = ones(size(bold_response.confounding_effects.X0,1),1);

% bold_response.confounding_effects.X0 = [ones(size(bold_response.confounding_effects.X0,1),1),...
%     bold_response.confounding_effects.X0];

bold_response.confounding_effects.X0_penrose_inv = (bold_response.confounding_effects.X0' * ...
    bold_response.confounding_effects.X0)^(-1) * bold_response.confounding_effects.X0';

bold_response.confounding_effects.intercept = ones(size(bold_response.obs));

end

%%
% <html><h4> Import ODEs </h4></html>
function ode = import_odes(symbols)

path_ode = './dcm/candidate_odes.txt';                                      % path to candidtae system of ODEs

ode.raw = importdata(path_ode);
ode.refined = ode.raw;

for k = 1:length(ode.refined)
for u = 1:length(symbols.state); ode.refined{k} = strrep(ode.refined{k},[symbols.state{u}],['state(:,' num2str(u) ')']); end 
for j = 1:length(symbols.param); ode.refined{k} = strrep(ode.refined{k},symbols.param{j},['param(' num2str(j) ')']); end
end
for k = 1:length(ode.refined); ode.system{k} = str2func(['@(state,param)(' ode.refined{k} ')']); end

end

%%
% <html><h4> write ODEs symbolically </h4></html>
function [ode,state_sym,param_sym] = write_ODEs_symbolically(symbols,ode)

param_sym = sym('param%d',[1,length(symbols.param)]); assume(param_sym,'real');
state_sym = sym('state%d',[1,length(symbols.state)]); assume(state_sym,'real');
for k = 1:length(ode.system)
    ode.system_sym(k) = ode.system{k}(state_sym,param_sym);
end

end

%%
% <html><h4> Simulate state trajectories by numerical integration </h4></html>
function [state,time,bold_response] = simulate_dynamics_by_numerical_integration(state,state_sym,param_sym,...
    time,ode,ode_param_true,bold_response,symbols)

idx0 = cellfun(@(x) ~strcmp(x(2),'u'),symbols.state);
learn_method.state(idx0) = {'Laplace mean-field'};
learn_method.state(~idx0) = {'external input'};

state.obs_idx = zeros(1,sum(idx0));
state.init_val = zeros(1,sum(idx0));
%
init_val = 0.01*ones(1,sum(idx0));

%
dt = state.ext_input(end,1) - state.ext_input(end-1,1);
ode_system_mat = matlabFunction(ode.system_sym','Vars',{state_sym(~strcmp(learn_method.state,'external input'))',...
        param_sym',state_sym(strcmp(learn_method.state,'external input'))'});
  
% warning ('off','all');    
[ToutX,OutX_solver] = ode113(@(t,x) ode_function(t,x,ode_system_mat,ode_param_true',state.ext_input(:,2:end),state.ext_input(:,1)),...
    state.ext_input(:,1), init_val);
% warning ('on','all');

[~,idx] = min(pdist2(ToutX,state.ext_input(:,1)),[],1);
ToutX = ToutX(idx); OutX_solver = OutX_solver(idx,:);

% pack
[~,state.ext_input_to_bold_response_mapping_idx] = min(pdist2(state.ext_input(:,1),time.est'),[],1);
state.true = OutX_solver(state.ext_input_to_bold_response_mapping_idx,:);
state.true(1:5,:) = 0;

time.true = ToutX';
time.samp = time.true(state.ext_input_to_bold_response_mapping_idx);

% true bold responses
bold_response.true = bold_signal_change_eqn(state.true(:,cellfun(@(x) strcmp(x(2),'v'),symbols.state)),state.true(:,cellfun(@(x) strcmp(x(2),'q'),symbols.state)));
% mean correction
% bold_response.confounding_effects.intercept = mean(bold_response.true,1);
% bold_response.true = bsxfun(@minus,bold_response.true,mean(bold_response.true,1));
% % bold_response.confounding_effects.X0 = ones(size(bold_response.true));

% observed bold responses
bold_response.obs = bold_response.true + bsxfun(@times,sqrt(var(bold_response.true) ./ bold_response.SNR),randn(size(bold_response.true)));
bold_response.confounding_effects.intercept = mean(bold_response.obs,1);
bold_response.variance = (repmat(max(bold_response.obs,[],1),size(bold_response.obs,1),1)./bold_response.SNR).^2;

% pack
state.obs = state.true(:,find(state.obs_idx));

% align externel input with observations
shift_num = 1;
e = state.ext_input;
e(shift_num+1:end,2:end) = state.ext_input(1:end-shift_num,2:end);
e(1:shift_num,2:end) = zeros(shift_num,size(state.ext_input,2)-1);
state.ext_input = e;

end

%%
% <html><h4> Simulate state trajectories by numerical integration with parameters estimated by variational gradient matching </h4></html>
function [state,bold_response] = simulate_trajectory_with_vgm_param_est(state,state_orig,ode_param,...
    bold_response,time,ode,state_sym,param_sym,symbols)

% Learn_method
idx = cellfun(@(x) ~strcmp(x(2),'u'),symbols.state);
learn_method.state(idx) = {'Laplace mean-field'};
learn_method.state(~idx) = {'external input'};
%%
bold_response.prediction.num_int_with_gm_param_est = [];
%try
    state_orig.init_val = state.proxy.mean(1,~strcmp(learn_method.state,'external input'));
    
    state_sim = simulate_dynamics_by_numerical_integration(state_orig,state_sym,param_sym,...
        time,ode,ode_param.proxy.mean',bold_response,symbols);
    
    state.num_int_with_gm_param_est = state_sim.true;
    
    %
    bold_response_signal_change = bold_signal_change_eqn(state.num_int_with_gm_param_est(:,cellfun(@(x) strcmp(x(2),'v'),symbols.state)),...
        state.num_int_with_gm_param_est(:,cellfun(@(x) strcmp(x(2),'q'),symbols.state)));
    bold_response.confounding_effects.intercept = determine_intercept(bold_response.obs_old-bold_response_signal_change,...
        bold_response.confounding_effects.X0,bold_response.confounding_effects.X0_penrose_inv);
    bold_response.prediction.num_int_with_gm_param_est = bold_response_signal_change + bold_response.confounding_effects.intercept;
    
    %
    state.num_int_with_gm_param_est(1,:) = [];
    state.num_int_with_gm_param_est(end+1,:) = zeros(1,size(state.num_int_with_gm_param_est,2));
    bold_response.prediction.num_int_with_gm_param_est(1,:) = [];
    bold_response.prediction.num_int_with_gm_param_est(end+1,:) = zeros(1,size(bold_response.prediction.num_int_with_gm_param_est,2));
    
%     var = diag(ode_param.prior.inv_cov).^(-1);
%     %if max(var)<=0.5%~any(isnan(var))
%     ode_param.proxy.mean(1:end-3) = sqrt(var(1:end-3)).*randn(length(ode_param.proxy.mean(1:end-3)),1);
%     warning('off')
%     
%     state_sim_prior_sampled = simulate_dynamics(state_orig,state_sym,param_sym,...
%         time,ode,ode_param.proxy.mean',bold_response,symbols);
%     warning('on')
%     state.num_int_with_prior_sampled_param = state_sim_prior_sampled.true;
%     
%     bold_response.prediction.num_int_with_prior_sampled_param = bold_signal_change_eqn(state_sim_prior_sampled.true(:,cellfun(@(x) strcmp(x(2),'v'),symbols.state)),...
%         state_sim_prior_sampled.true(:,cellfun(@(x) strcmp(x(2),'q'),symbols.state))) ...
%         + bold_response.confounding_effects.intercept;
    %end
%end

end

%%
% <html><h4> Generate observations of states </h4></html>
function [state,time,obs_to_state_relation] = generate_state_obs(state,time,simulation)

% State observations
state_obs_variance = simulation.state_obs_variance(state.true);
state.obs = state.true + sqrt(state_obs_variance) .* randn(size(state.true));

% Relationship between states and observations
if length(simulation.time_samp) < length(time.est)
    time.idx = munkres(pdist2(simulation.time_samp',time.est'));
    time.ind = sub2ind([length(simulation.time_samp),length(time.est)],1:length(simulation.time_samp),time.idx);
else
    time.idx = munkres(pdist2(time.est',simulation.time_samp'));
    time.ind = sub2ind([length(time.est),length(simulation.time_samp)],1:length(time.est),time.idx);
end

time.obs_time_to_state_time_relation = zeros(length(simulation.time_samp),length(time.est)); time.obs_time_to_state_time_relation(time.ind) = 1;
state_mat = eye(size(state.true,2));
obs_to_state_relation = sparse(kron(state_mat,time.obs_time_to_state_time_relation));
time.samp = simulation.time_samp;

end

%%
% generate DCM ODEs
function [symbols,param_learning_mask] = generate_generic_DCM_odes2(ode_type,ode_path)

numb_states = 3;
if strcmp(ode_type,'nonlin_fwd_mod')
    param_learning_mask.a = ones(numb_states,numb_states); param_learning_mask.a(1,3) = 0; param_learning_mask.a(3,1) = 0;
    [row_idx,col_idx] = find(eye(size(param_learning_mask.a,1)));
    lin_ind = sub2ind(size(param_learning_mask.a),row_idx(1:end-1)+1,col_idx(1:end-1));
    param_learning_mask.a(lin_ind) = 1;
    
    param_learning_mask.b = zeros(numb_states,numb_states,3); param_learning_mask.b(2,1,2) = 1;
    param_learning_mask.c = zeros(numb_states,3); param_learning_mask.c(1,1) = 1; param_learning_mask.c(3,3) = 1;
    param_learning_mask.d = zeros(numb_states,numb_states,3); param_learning_mask.d(2,1,3) = 1;
    
elseif strcmp(ode_type,'bwd_mod_driving')
    param_learning_mask.a = ones(numb_states,numb_states); param_learning_mask.a(1,3) = 0; param_learning_mask.a(3,1) = 0; 
    [row_idx,col_idx] = find(eye(size(param_learning_mask.a,1)));
    lin_ind = sub2ind(size(param_learning_mask.a),row_idx(1:end-1)+1,col_idx(1:end-1));
    param_learning_mask.a(lin_ind) = 1;
    
    param_learning_mask.b = zeros(numb_states,numb_states,3); param_learning_mask.b(2,1,2) = 1; param_learning_mask.b(2,3,3) = 1;
    param_learning_mask.c = zeros(numb_states,3); param_learning_mask.c(1,1) = 1; param_learning_mask.c(3,3) = 1;
    param_learning_mask.d = zeros(numb_states,numb_states,3);
    
elseif strcmp(ode_type,'bwd_mod')
    param_learning_mask.a = ones(numb_states,numb_states); param_learning_mask.a(1,3) = 0; param_learning_mask.a(3,1) = 0;
    [row_idx,col_idx] = find(eye(size(param_learning_mask.a,1)));
    lin_ind = sub2ind(size(param_learning_mask.a),row_idx(1:end-1)+1,col_idx(1:end-1));
    param_learning_mask.a(lin_ind) = 1;
    
    param_learning_mask.b = zeros(numb_states,numb_states,3); param_learning_mask.b(2,1,2) = 1; param_learning_mask.b(2,3,3) = 1;
    param_learning_mask.c = zeros(numb_states,3); param_learning_mask.c(1,1) = 1; 
    param_learning_mask.d = zeros(numb_states,numb_states,3);
    
elseif strcmp(ode_type,'driving')
    param_learning_mask.a = ones(numb_states,numb_states); param_learning_mask.a(1,3) = 0; param_learning_mask.a(3,1) = 0;
    [row_idx,col_idx] = find(eye(size(param_learning_mask.a,1)));
    lin_ind = sub2ind(size(param_learning_mask.a),row_idx(1:end-1)+1,col_idx(1:end-1));
    param_learning_mask.a(lin_ind) = 1;
    
    param_learning_mask.b = zeros(numb_states,numb_states,3); param_learning_mask.b(2,1,2) = 1; 
    param_learning_mask.c = zeros(numb_states,3); param_learning_mask.c(1,1) = 1; param_learning_mask.c(3,3) = 1;
    param_learning_mask.d = zeros(numb_states,numb_states,3);
    
elseif strcmp(ode_type,'fwd_mod')
    param_learning_mask.a = ones(numb_states,numb_states); param_learning_mask.a(1,3) = 0; param_learning_mask.a(3,1) = 0;
    [row_idx,col_idx] = find(eye(size(param_learning_mask.a,1)));
    lin_ind = sub2ind(size(param_learning_mask.a),row_idx(1:end-1)+1,col_idx(1:end-1));
    param_learning_mask.a(lin_ind) = 1;
    
    param_learning_mask.b = zeros(numb_states,numb_states,3); param_learning_mask.b(2,1,2) = 1; param_learning_mask.b(2,1,3) = 1; 
    param_learning_mask.c = zeros(numb_states,3); param_learning_mask.c(1,1) = 1;
    param_learning_mask.d = zeros(numb_states,numb_states,3);
    
elseif strcmp(ode_type,'fwd_mod_driving')
    param_learning_mask.a = ones(numb_states,numb_states); param_learning_mask.a(1,3) = 0; param_learning_mask.a(3,1) = 0;
    [row_idx,col_idx] = find(eye(size(param_learning_mask.a,1)));
    lin_ind = sub2ind(size(param_learning_mask.a),row_idx(1:end-1)+1,col_idx(1:end-1));
    param_learning_mask.a(lin_ind) = 1;
    
    param_learning_mask.b = zeros(numb_states,numb_states,3); param_learning_mask.b(2,1,2) = 1; param_learning_mask.b(2,1,3) = 1; 
    param_learning_mask.c = zeros(numb_states,3); param_learning_mask.c(1,1) = 1; param_learning_mask.c(3,3) = 1;
    param_learning_mask.d = zeros(numb_states,numb_states,3);
    
elseif strcmp(ode_type,'no_att')
    param_learning_mask.a = ones(numb_states,numb_states); param_learning_mask.a(1,3) = 0; param_learning_mask.a(3,1) = 0; param_learning_mask.a(2,3) = 0;
    [row_idx,col_idx] = find(eye(size(param_learning_mask.a,1)));
    lin_ind = sub2ind(size(param_learning_mask.a),row_idx(1:end-1)+1,col_idx(1:end-1));
    param_learning_mask.a(lin_ind) = 1;
    
    param_learning_mask.b = zeros(numb_states,numb_states,3); param_learning_mask.b(2,1,2) = 1; 
    param_learning_mask.c = zeros(numb_states,3); param_learning_mask.c(1,1) = 1; param_learning_mask.c(3,3) = 0;
    param_learning_mask.d = zeros(numb_states,numb_states,3);
    
elseif strcmp(ode_type,'no_photic')
    param_learning_mask.a = ones(numb_states,numb_states); param_learning_mask.a(1,3) = 0; param_learning_mask.a(3,1) = 0; 
    [row_idx,col_idx] = find(eye(size(param_learning_mask.a,1)));
    lin_ind = sub2ind(size(param_learning_mask.a),row_idx(1:end-1)+1,col_idx(1:end-1));
    param_learning_mask.a(lin_ind) = 1;
    
    param_learning_mask.b = zeros(numb_states,numb_states,3); param_learning_mask.b(2,1,2) = 1; 
    param_learning_mask.c = zeros(numb_states,3); param_learning_mask.c(1,1) = 0; param_learning_mask.c(3,3) = 1;
    param_learning_mask.d = zeros(numb_states,numb_states,3);
    
elseif strcmp(ode_type,'photic')
    param_learning_mask.a = ones(numb_states,numb_states); param_learning_mask.a(1,3) = 0; param_learning_mask.a(3,1) = 0; 
    [row_idx,col_idx] = find(eye(size(param_learning_mask.a,1)));
    lin_ind = sub2ind(size(param_learning_mask.a),row_idx(1:end-1)+1,col_idx(1:end-1));
    param_learning_mask.a(lin_ind) = 1;
    
    param_learning_mask.b = zeros(numb_states,numb_states,3); param_learning_mask.b(2,1,2) = 1; 
    param_learning_mask.c = zeros(numb_states,3); param_learning_mask.c(1,1) = 1; param_learning_mask.c(3,3) = 1;
    param_learning_mask.d = zeros(numb_states,numb_states,3);

elseif strcmp(ode_type,'no_mod')
    param_learning_mask.a = ones(numb_states,numb_states); param_learning_mask.a(1,3) = 0; param_learning_mask.a(3,1) = 0; 
    [row_idx,col_idx] = find(eye(size(param_learning_mask.a,1)));
    lin_ind = sub2ind(size(param_learning_mask.a),row_idx(1:end-1)+1,col_idx(1:end-1));
    param_learning_mask.a(lin_ind) = 1;
    
    param_learning_mask.b = zeros(numb_states,numb_states,3);
    param_learning_mask.c = zeros(numb_states,3); param_learning_mask.c(1,1) = 1; param_learning_mask.c(3,3) = 1;
    param_learning_mask.d = zeros(numb_states,numb_states,3);
    
end

symbols = generate_DCM_ODEs(ode_path,param_learning_mask,numb_states);                 % writes the "ODE.txt" file

end

%%
% generate DCM ODEs
function symbols = generate_DCM_ODEs(path_ode,param_learning_idx,numb_states)

[odes,X,U,A,B,C,D] = neuronal_dynamics(param_learning_idx,numb_states);
[odes(numb_states+1:5*numb_states,:),S,F,V,Q] = hemodynamics_balloon(X,numb_states);

if numb_states==3
    ode_reordered(1:3,:) = odes([13,15,14],:); ode_reordered(4:6,:) = odes([10,12,11],:); ode_reordered(7:9,:) = odes([7,9,8],:);
    ode_reordered(10:12,:) = odes([4,6,5],:); ode_reordered(13:15,:) = odes([1,3,2],:);
    
    X = X([1,3,2]); S = S([1,3,2]); F = F([1,3,2]); V = V([1,3,2]); Q = Q([1,3,2]);
else
    ode_reordered = odes(end:-1:1);
    X = flipdim(X,1); S = flipdim(S,1); F = flipdim(F,1); V = flipdim(V,1); Q = flipdim(Q,1);
end

% State symbols renaming
j=0;
for i=1:length(Q)
    j = j+1;
    state_symbols_old{j} = char(Q(i));
    symbols.state{j} = ['[',state_symbols_old{j}(1),'_{',state_symbols_old{j}(2:end),'}]'];
end
for i=1:length(V)
    j = j+1;
    state_symbols_old{j} = char(V(i));
    symbols.state{j} = ['[',state_symbols_old{j}(1),'_{',state_symbols_old{j}(2:end),'}]'];
end
for i=1:length(F)
    j = j+1;
    state_symbols_old{j} = char(F(i));
    symbols.state{j} = ['[',state_symbols_old{j}(1),'_{',state_symbols_old{j}(2:end),'}]'];
end
for i=1:length(S)
    j = j+1;
    state_symbols_old{j} = char(S(i));
    symbols.state{j} = ['[',state_symbols_old{j}(1),'_{',state_symbols_old{j}(2:end),'}]'];
end
for u=1:length(X)
    j = j+1;
    state_symbols_old{j} = char(X(u));
    if strcmp(state_symbols_old{j},'x1')
        symbols.state{j} = '[x_1]';
    elseif strcmp(state_symbols_old{j},'x2')
        symbols.state{j} = '[x_2]';
    elseif strcmp(state_symbols_old{j},'x3')
        symbols.state{j} = '[x_3]';
    end
end
for i=1:length(U)
    j = j+1;
    state_symbols_old{j} = char(U(i));
    symbols.state{j} = ['[',state_symbols_old{j}(1),'_{',state_symbols_old{j}(2:end),'}]'];
end

% ODE parameter renaming
j=0;
A2 = A;
A2(logical(eye(size(A2)))) = 0;
A2=reshape(A2,[],1); A2(A2=='0') = [];
for i=1:length(A2)
    j = j+1;
    param_symbols_old{j} = [' ',char(A2(i)),' '];
    %param_symbols_old{j} = make_index_double_digits(param_symbols_old{j});
    symbols.param{j} = ['[',param_symbols_old{j}(2),'_{',param_symbols_old{j}(3:end-1),'}]'];
end

for u = 1:size(B,3)
    B2=reshape(B(:,:,u),[],1); B2(B2=='0') = [];
    if ~isempty(D)
        for i=1:length(B2)
            j = j+1;
            param_symbols_old{j} = [' ',char(B2(i)),' '];
            symbols.param{j} = ['[',param_symbols_old{j}(2),'_{',param_symbols_old{j}(3:end-1),'}]'];
        end
    end
end

C=reshape(C,[],1); C(C=='0') = [];
for i=1:length(C)
    j = j+1;
    param_symbols_old{j} = [' ',char(C(i)),' '];
    symbols.param{j} = ['[',param_symbols_old{j}(2),'_{',param_symbols_old{j}(3:end-1),'}]'];
end

for u = 1:size(D,3)
    D2=reshape(D(:,:,u),[],1); D2(D2=='0') = [];
    if ~isempty(D2)
        for i=1:length(D2)
            j = j+1;
            param_symbols_old{j} = [' ',char(D2(i)),' '];
            symbols.param{j} = ['[',param_symbols_old{j}(2),'_{',param_symbols_old{j}(3:end-1),'}]'];
        end
    end
end

for i=1:size(A)
    j = j+1;
    param_symbols_old{j} = [' ',char(A(i,i)),' '];
    symbols.param{j} = ['[',param_symbols_old{j}(2),'_{',param_symbols_old{j}(3:end-1),'}]'];
end

% replace symbols in ODEs
dlmwrite(path_ode,[],'delimiter','')
for k = 1:size(ode_reordered,1)
    string = [' ',char(ode_reordered(k,:)),' ']; 
    string = strrep(string,'*',' .* '); 
    string = strrep(string,'/',' ./ '); 
    string = strrep(string,'^',' .^ ');
    
    for u=1:length(state_symbols_old)
        string = strrep(string,state_symbols_old{u},symbols.state{u});
    end
    
    for i=1:length(param_symbols_old)
        string = strrep(string,param_symbols_old{i},[' ',symbols.param{i},' ']);
    end
    string = strrep(string,'a21',[' ','[a_{21}]',' ']);
    string = strrep(string,'a23',[' ','[a_{23}]',' ']);
    
    string = strrep(string,' ','');
    
    dlmwrite(path_ode,string,'delimiter','','-append')
end

end
%%
% <html><h4> Neuronal dynamics </h4></html>
function [odes,X,U,A,B,C,D] = neuronal_dynamics(param_learning_mask,numb_states)

A = sym('a%d%d',[numb_states,numb_states]); A(param_learning_mask.a==0) = 0; %A(logical(eye(size(A)))) = -exp(diag(A));
B = sym('b%d%d%d',[numb_states,numb_states,size(param_learning_mask.c,2)]); B(param_learning_mask.b==0) = 0;
C = sym('c%d%d',[numb_states,size(param_learning_mask.c,2)]); C(param_learning_mask.c==0) = 0;
D = sym('d%d%d%d',[numb_states,numb_states,3]); D(param_learning_mask.d==0) = 0;

X = sym('x%d',[numb_states,1]); 
U = sym('u%d',[size(param_learning_mask.c,2),1]); 

B_times_U = zeros(numb_states,numb_states);
for i = 1:size(B,3)  
    B_times_U = B_times_U + B(:,:,i) .* U(i);
end
    
odes = (A + B(:,:,1) .* U(1) + B_times_U ...
    + D(:,:,1) .* X(1) + D(:,:,2) .* X(2) + D(:,:,3) .* X(3)) * X + C * U;

end

%%
% <html><h4> Hemodynamics balloon model </h4></html>
function [odes,S,F,V,Q] = hemodynamics_balloon(X,numb_states)

H = [0.64 0.32 2.00 0.32 0.4];

% P.decay = [-0.0490; 0.0092; -0.0321];
% P.transit = [-0.1696;-0.2031;-0.0907];
P.decay = [-0.0920;0.0192;-0.0661];
P.transit = [-0.2466;-0.1111;-0.1194];

kappa = H(1) * exp(P.decay);
gamma = H(2);
tau = H(3)*exp(P.transit);
alpha = H(4);
E0 = H(5);

kappa = 0.6; tau = 1.6;

S = sym('s%d',[numb_states,1]); 
F = sym('f%d',[numb_states,1]);
V = sym('v%d',[numb_states,1]);
Q = sym('q%d',[numb_states,1]);

E = 1 - (1 - E0).^(exp(-F));

odes(1:numb_states,:) = X - kappa .* S - gamma .* (exp(F) - 1);
odes(numb_states+1:2*numb_states,:) = S ./ exp(F);
odes(2*numb_states+1:3*numb_states,:) = exp(F).*exp(-V)./tau - exp(V.*(1/alpha-1)) ./ tau;
odes(3*numb_states+1:4*numb_states,:) = E.*exp(F)./(E0*tau.*exp(Q)) - exp(V.*(1/alpha-1))./tau;

end

%%
% <html><h4> ODE function </h4></html>
function state_derivatives = ode_function(time,states,ode_system_mat,ode_param,ext_input,time_lst)

[~,idx] = min(pdist2(time,time_lst));
u = ext_input(idx,:);

state_derivatives = ode_system_mat(states,ode_param,u');

end

%%
% <html><h4> Determine intercept </h4></html>
function intercept = determine_intercept(bold_response_diff,X0,X0_penrose_inv)

%intercept = X0 * X0_penrose_inv * X0' * bold_response_diff;
intercept = X0 * X0_penrose_inv * bold_response_diff;

end

%%
% <html><h4> Setup plots </h4></html>
function h = setup_plots(state,time,symbols,bold_response,fig_numbers,candidate_odes,simulation,plot_type)

if nargin == 6
    plotting.layout = [4,4];                                               % set the number of subplots
    plotting.states = 1:15;                                                % plot states
else
    plotting.layout = [3,2];                                               % set the number of subplots
    neuronal_state_titles_idx = find(cellfun(@(x) strcmp(x(2),'x'),symbols.state));
    plotting.states = neuronal_state_titles_idx(1:3);   
    plotting.states = [3,6,9,12,15];
end

% Plot colors
color = [[117,112,179]./255; [217,95,2]./255; 0.7,0.7,0.7; [152,78,163]./255];
%
for i = 1:length(symbols.param)
    symbols_param_plot{i} = symbols.param{i}(2:end-1);
end

figure(fig_numbers(1)); clf
set(fig_numbers(1), 'Position', [0, 200, 1400, 1000]);
set(fig_numbers(1), 'Position', [0, 200, 1600, 800]);
axis tight


h.couplings = subplot(plotting.layout(1),plotting.layout(2),1);

h.couplings.YLabel.String = 'Neuronal Couplings'; 
h.couplings.YLabel.Rotation = 0;
h.couplings.YLabel.Units = 'normalized';
h.couplings.YLabel.Position(1) = h.couplings.Title.Position(1);%-0.35;
h.couplings.YLabel.Position(2) = h.couplings.Title.Position(2);
h.couplings.XRuler.TickLength = [0,0];

set(gca,'XTick',[1:length(symbols.param)]); set(gca,'XTickLabel',symbols_param_plot);


if length(symbols.param)>9; h.couplings.XTickLabelRotation = 90; end
h.couplings.FontSize = 15;
hold on; drawnow

try
    state_plot_true = state.true;
    state_plot_true(:,1:9) = exp(state_plot_true(:,1:9));

    state_plot_obs = state.obs;
    if size(state_plot_obs,2)<9
        state_plot_obs(:,1:end) = exp(state_plot_obs(:,1:end));
    else
        state_plot_obs(:,1:9) = exp(state_plot_obs(:,1:9));
    end
    idx = 360;
    state_plot_true = state_plot_true(1:idx,:); state_plot_obs = state_plot_obs(1:idx,:); 
end



i = 1; u2=0;
for u = plotting.states
    i = i+1;
	h.dynamics{u} = subplot(plotting.layout(1),plotting.layout(2),i); cla
    try; plot(h.dynamics{u},time.samp(1:idx),state_plot_true(:,u),'Color',color(2,:),'LineWidth',2); end
    try; hold on; plot(h.dynamics{u},time.samp(1,:),state_plot_obs(:,u),'*','MarkerSize',1,'Color',color(2,:)); end
    try; plot(h.dynamics{u},time.samp(1,:),state.num_int(:,u),'Color',color(4,:),'LineWidth',1); end
    xlabel('time (s)');
    h.dynamics{u}.FontSize = 20;
    h.dynamics{u}.Title.Units = 'normalized';
    h.dynamics{u}.YLabel.String = symbols.state{u}(2:end-1);
    h.dynamics{u}.YLabel.Rotation = 0; 
    h.dynamics{u}.YLabel.Units = 'normalized';
    h.dynamics{u}.YLabel.Position(1) = h.dynamics{u}.Title.Position(1)-0.45;
    h.dynamics{u}.YLabel.Position(2) = h.dynamics{u}.Title.Position(2);
   % h.dynamics{u}.XLim = [time.est(1), time.est(end)];

    if any(cellfun(@(x) strcmp(x,symbols.state{u}(2:end-1)),simulation.observed_states))
        u2 = u2+1; %
        try;hold on; plot(h.dynamics{u},time.samp,state.obs(:,u),'*','Color',color,'MarkerSize',10); end
        %try;hold on; plot(time.samp,state_plot_obs(:,u),'*','Color',color(2,:)); end
    end
    
    hold on;
    h.dynamics{u}.XLim(2) = max(time.est(1:idx));
end

text(-0.45,4.2,{['true:          ' simulation.odes],['candidate: ' candidate_odes]},'Units','normalized','FontSize',18,'Interpreter','none')

% Bold Response
    
if length(fig_numbers)==2
figure(fig_numbers(2)); clf
set(fig_numbers(2), 'Position', [0, 200, 1200, 600]);
axis tight

plot_titles_idx = find(cellfun(@(x) strcmp(x(2),'x'),symbols.state));

nPlot_rows = size(bold_response.obs,2); if nPlot_rows > 6; nPlot_rows = 3; end
        
plot_idx = [1:2:nPlot_rows*2];
for i = 1:nPlot_rows
    h.bold{i} = subplot(nPlot_rows,2,plot_idx(i));
    plot(h.bold{i},time.samp,bold_response.obs(:,i),'LineWidth',2,'Color',color(2,:)); hold on;
    try; plot(h.bold{i},time.est,bold_response.prediction.num_int(:,i),'LineWidth',1,'Color',color(4,:)); hold on; end
    h.bold{i}.XLim = [time.est(1), time.est(end)]; %h.bold{i}.YLim = [-3,3];
    h.bold{i}.FontSize = 15; xlabel('time (s)');
    h.bold{i}.YLabel.String = [symbols.state{plot_titles_idx(i)}(2:end-1) ' BOLD response']; h.bold{i}.YLabel.Rotation = 0; h.bold{i}.YLabel.Units = 'normalized';
    h.bold{i}.Title.Units = 'normalized'; h.bold{i}.YLabel.Position(1) = h.bold{i}.Title.Position(1)-0.35;
    h.bold{i}.YLabel.Position(2) = h.bold{i}.Title.Position(2);
    %h.bold{i}.YLim = [-5,5];
end
%plot(h.bold{1},time.samp,2*state.ext_input(:,end),'LineWidth',1,'Color',[0.8,0.8,0.8]); hold on;

% External Input
plot_titles_idx = flipdim(find(cellfun(@(x) strcmp(x(2),'u'),symbols.state)),2);

plot_idx = [2:2:nPlot_rows*2];
for i = 1:sum(cellfun(@(x) strcmp(x(2),'u'),symbols.state))
    hY2 = subplot(nPlot_rows,2,plot_idx(i));
    plot(time.true,state.ext_input(:,i+1),'LineWidth',2,'Color',color(2,:)); hold on;
    hY2.XLim = [state.ext_input(1,1), state.ext_input(end,1)]; hY2.FontSize = 15; xlabel('time (s)','FontSize',15);
    hY2.YLabel.String = symbols.state{plot_titles_idx(i)}(2:end-1); hY2.YLabel.Rotation = 0; hY2.YLabel.Units = 'normalized';
    hY2.Title.Units = 'normalized'; hY2.YLabel.Position(1) = hY2.Title.Position(1)-0.4;
    hY2.YLabel.Position(2) = hY2.Title.Position(2);
end

end

%
color = [[117,112,179]./255; [217,95,2]./255; 0.7,0.7,0.7];

param_plot.true = simulation.ode_param';
param_plot.proxy = zeros(length(simulation.ode_param),1);

if strcmp(simulation.odes,candidate_odes)
    try
        b = bar(h.couplings,[1:length(param_plot.true)],[param_plot.true,param_plot.proxy]);
    catch
        b = bar(h.couplings,[1:length(param_plot.true)+1],[[param_plot.true;0],[param_plot.proxy;0]]);
    end
end

b(1).EdgeColor = 'none'; b(1).FaceAlpha = 1; b(1).FaceColor = color(2,:);
b(2).EdgeColor = 'none'; b(2).FaceAlpha = 1; b(2).FaceColor = color(1,:);

h.couplings.XLim = [0.5,length(param_plot.true)+0.5];
try;h.couplings.YLim = [min(min([param_plot.true',param_plot.proxy],[],1)),max(max([param_plot.true',param_plot.proxy],[],1))];end
h.couplings.FontSize = 20;

figure(fig_numbers(1));

drawnow
end

%%
% <html><h4> Plot results </h4></html>
function plot_results(state,ode_param,bold_response,time,h,fig_numbers,odes_true,candidate_odes,simulation)

plotting.layout = [2,2];                                               % set the number of subplots
plotting.states = find(~cellfun(@(x) isempty(x),h.dynamics));
plotting.states = plotting.states(1:3);
plotting.states = [3,6,9,12,15];


% Plot colors
color = [[117,112,179]./255; [217,95,2]./255; 0.7,0.7,0.7];

% plot results
state.obs_idx = [];

state.obs_ind = find(state.obs_idx);
state_plot_gm = state.proxy.mean; state_plot_gm(:,1:9) = exp(state_plot_gm(:,1:9));
state_plot_num_int = state.num_int_with_gm_param_est; state_plot_num_int(:,1:9) = exp(state_plot_num_int(:,1:9));

state_plot_true = state.true;
state_plot_true(:,1:9) = exp(state_plot_true(:,1:9));
    
try; if strcmp(plot_type,'plot_all'); plotting.states = find(ones(1,size(state_plot_num_int,2))); end; end
for u = plotting.states
    xlim = h.dynamics{u}.XLim; ylim = h.dynamics{u}.YLim;

    %shaded_region = [state_plot_gm(:,u)+1*sqrt(state.proxy.variance(:,u)); flipdim(state_plot_gm(:,u)-1*sqrt(state.proxy.variance(:,u)),1)];
    %f = fill(h.dynamics{u},[time.est'; flipdim(time.est',1)], shaded_region, [222,235,247]/255); set(f,'EdgeColor','None');
    
     %hold on; plot(h.dynamics{u},time.est,state_plot_gm(:,u),'Color',color(1,:),'LineWidth',1); 
     %hold on; plot(h.dynamics{u},time.est,state_plot_num_int(:,u),'Color',[77,175,74]./255,'LineWidth',2); 
     %h.dynamics{u}.YLim = [min(state_plot(:,u)),max(state_plot(:,u))];
     %try;hold on; plot(h.dynamics{u},time.est(1:120),state.true(1:120,u),'Color',color(2,:),'LineWidth',2);end
     idx = 360;
     try;hold on; plot(h.dynamics{u},time.est(1:idx),state_plot_true(1:idx,u),'Color',color(2,:),'LineWidth',2);end
     hold on; plot(h.dynamics{u},time.est(1:idx),state_plot_num_int(1:idx,u),'Color',[0,0,0],'LineWidth',1); 
     %h.dynamics{u}.YLim(2) = 0.6;
     h.dynamics{u}.XLim(2) = max(time.est(1:idx));
end

% Predicted bold response

if length(fig_numbers)==2
figure(fig_numbers(2));

nPlot_rows = size(bold_response.obs,2); if nPlot_rows > 6; nPlot_rows = 3; end
plot_idx = [1:2:nPlot_rows*2];
for i = 1:nPlot_rows
    subplot(nPlot_rows,2,plot_idx(i)); hold on;
    %plot(h.bold{i}time.est,bold_response.prediction.gm(:,i),'LineWidth',2,'Color',color(1,:)); hold on;
    %plot(h.bold{i}time.est,bold_response.prediction.num_int_with_gm_param_est(:,i),'LineWidth',2,'Color',[77,175,74]./255); hold on;
    plot(h.bold{i},time.est,bold_response.prediction.num_int_with_gm_param_est(:,i),'LineWidth',1,'Color',[0,0,0]); hold on;
    try;plot(h.bold{i},time.est,bold_response.prediction.num_int_with_prior_sampled_param(:,i),'LineWidth',2,'Color',[0.8,0.8,0.8]); hold on;end
    %h.bold{i}.YLim = [-3,3];
end

% try
% a = axes;
% t1 = title({odes_true,candidate_odes});
% t1.FontSize = 11;
% a.Visible = 'off'; 
% t1.Visible = 'on'; 
% t1.Interpreter = 'none';
% end

end
% write results
%disp(' '); disp(['writing plots in ' results_directory]);
% if ~exist(results_directory); mkdir(results_directory); end
% 
% set(1,'Units','Inches'); 
% pos = get(1,'Position'); set(1,'PaperPositionMode','Auto','PaperUnits','Inches','PaperSize',[pos(3),pos(4)]);
% print(1,[results_directory '/anticipate_dynamics.pdf'],'-dpdf','-r0')
% 
% set(6,'Units','Inches'); 
% pos = get(6,'Position'); set(6,'PaperPositionMode','Auto','PaperUnits','Inches','PaperSize',[pos(3),pos(4)]);
% print(6,[results_directory '/anticipate_BOLD_responses.pdf'],'-dpdf','-r0')

% ODE param
% Plotting
% state_plot = state.proxy.mean; state_plot(:,1:9) = exp(state_plot(:,1:9));
% for u = plotting.states
%     hold on; plot(h.dynamics{u},time.est,state_plot(:,u),'LineWidth',0.5,'Color',color(3,:)); 
% end

hold on; cla(h.couplings);

param_plot.proxy = ode_param.proxy.mean;
% try
%     param_plot.true = ode_param.true;
%     try
%         b = bar(h.couplings,[1:length(param_plot.proxy)],[param_plot.true',param_plot.proxy]);
%     catch
%         b = bar(h.couplings,[1:length(param_plot.proxy)+1],[[param_plot.true';0],[param_plot.proxy;0]]);
%     end
%     b(1).EdgeColor = 'none'; b(1).FaceAlpha = 1; b(1).FaceColor = color(2,:);
%     b(2).EdgeColor = 'none'; b(2).FaceAlpha = 1; b(2).FaceColor = color(1,:);
% catch
%     b = bar(h.couplings,[1:length(param_plot.proxy)],[param_plot.proxy]);
%     b(1).EdgeColor = 'none'; b(1).FaceAlpha = 1; b(1).FaceColor = color(1,:);
% end

if ~strcmp(odes_true,candidate_odes)
    b = bar(h.couplings,[1:length(param_plot.proxy)],[param_plot.proxy]);
    b(1).EdgeColor = 'none'; b(1).FaceAlpha = 1; b(1).FaceColor = color(1,:);
else
     param_plot.true = simulation.ode_param;
    try
        b = bar(h.couplings,[1:length(param_plot.proxy)],[param_plot.true',param_plot.proxy]);
    catch
        b = bar(h.couplings,[1:length(param_plot.proxy)+1],[[param_plot.true';0],[param_plot.proxy;0]]);
    end
    b(1).EdgeColor = 'none'; b(1).FaceAlpha = 1; b(1).FaceColor = color(2,:);
    b(2).EdgeColor = 'none'; b(2).FaceAlpha = 1; b(2).FaceColor = color(1,:);
end
    
h.couplings.XLim = [0.5,length(param_plot.proxy)+0.5];
try;h.couplings.YLim = [min(min([param_plot.true',param_plot.proxy],[],1)),max(max([param_plot.true',param_plot.proxy],[],1))];end

drawnow

end

##### SOURCE END #####
--></body></html>